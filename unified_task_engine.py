# -*- coding: utf-8 -*-
"""
çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ - å…¨ã¦ã®AIå‡¦ç†ã‚’çµ±åˆã™ã‚‹è¨­å®šé§†å‹•å‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import time
import hashlib
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import yaml
from pathlib import Path

import discord
from discord.ext import commands

from utils import safe_log, send_long_message, analyze_attachment_for_gpt5, get_notion_context_for_message
from enhanced_memory_manager import get_enhanced_memory_manager
from ai_manager import get_ai_manager
from enhanced_cache import get_cache_manager
from notion_utils import (
    NOTION_PAGE_MAP, log_user_message, log_response, get_memory_flag_from_notion,
    find_latest_section_id, append_summary_to_kb
)
from async_optimizer import process_with_parallel_context, multi_ai_council_parallel
from ai_clients import ask_gpt5_mini
from plugin_system import HookType

@dataclass
class TaskConfig:
    """ã‚¿ã‚¹ã‚¯è¨­å®š"""
    task_type: str
    description: str
    use_memory: bool = False
    use_kb: bool = True
    use_summary: bool = True
    context_strategy: str = "cached"
    prompt_template: str = "standard"
    special_handler: Optional[str] = None
    post_processing: List[str] = None
    priority: float = 1.0
    timeout: int = 30
    max_retries: int = 2

@dataclass
class TaskResult:
    """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœ"""
    success: bool
    response: str
    metadata: Dict[str, Any]
    execution_time: float
    error: Optional[str] = None

class TaskConfigLoader:
    """ã‚¿ã‚¹ã‚¯è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self):
        self.config_file = Path(__file__).parent / "config" / "task_configs.yaml"
        self.config_data: Dict[str, Any] = {}
        self.last_modified = 0
        self._load_config()

    def _load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not self.config_file.exists():
                safe_log("âš ï¸ ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ", str(self.config_file))
                self._create_default_config()
                return

            current_modified = self.config_file.stat().st_mtime
            if current_modified <= self.last_modified:
                return  # æ›´æ–°ã•ã‚Œã¦ã„ãªã„

            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config_data = yaml.safe_load(f)

            self.last_modified = current_modified
            safe_log("âœ… ã‚¿ã‚¹ã‚¯è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†: ", f"{len(self.config_data.get('ai_task_mapping', {}))}å€‹ã®AIè¨­å®š")

        except Exception as e:
            safe_log("ğŸš¨ ã‚¿ã‚¹ã‚¯è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: ", e)
            self._create_default_config()

    def _create_default_config(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½œæˆ"""
        self.config_data = {
            "task_types": {
                "standard": {
                    "description": "æ¨™æº–AIã‚¿ã‚¹ã‚¯",
                    "use_memory": False,
                    "use_kb": True,
                    "use_summary": True,
                    "context_strategy": "cached",
                    "prompt_template": "standard"
                }
            },
            "ai_task_mapping": {
                "gpt5": {"task_type": "standard", "priority": 1.0}
            }
        }

    def get_task_config(self, ai_type: str) -> TaskConfig:
        """AIã‚¿ã‚¤ãƒ—ã‹ã‚‰ã‚¿ã‚¹ã‚¯è¨­å®šã‚’å–å¾—"""
        self._load_config()  # å¿…è¦ã«å¿œã˜ã¦å†èª­ã¿è¾¼ã¿

        # AIè¨­å®šã‚’å–å¾—
        ai_config = self.config_data.get("ai_task_mapping", {}).get(ai_type, {})
        task_type = ai_config.get("task_type", "standard")

        # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—è¨­å®šã‚’å–å¾—
        task_type_config = self.config_data.get("task_types", {}).get(task_type, {})

        # TaskConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        return TaskConfig(
            task_type=task_type,
            description=task_type_config.get("description", ""),
            use_memory=task_type_config.get("use_memory", False),
            use_kb=task_type_config.get("use_kb", True),
            use_summary=task_type_config.get("use_summary", True),
            context_strategy=task_type_config.get("context_strategy", "cached"),
            prompt_template=task_type_config.get("prompt_template", "standard"),
            special_handler=task_type_config.get("special_handler"),
            post_processing=task_type_config.get("post_processing", ["log_response"]),
            priority=ai_config.get("priority", 1.0),
            timeout=ai_config.get("timeout", 30),
            max_retries=ai_config.get("max_retries", 2)
        )

    def get_context_strategy(self, strategy_name: str) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥ã‚’å–å¾—"""
        return self.config_data.get("context_strategies", {}).get(strategy_name, {})

    def get_prompt_template(self, template_name: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
        return self.config_data.get("prompt_templates", {}).get(template_name, {}).get("template", "{message_content}")

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥ï¼ˆStrategy Patternï¼‰
class ContextStrategy(ABC):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—æˆ¦ç•¥ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""

    @abstractmethod
    async def get_context(self, bot: commands.Bot, message: discord.Message,
                         config: TaskConfig, page_ids: List[str]) -> Dict[str, Any]:
        pass

class MinimalContextStrategy(ContextStrategy):
    """æœ€å°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥"""

    async def get_context(self, bot: commands.Bot, message: discord.Message,
                         config: TaskConfig, page_ids: List[str]) -> Dict[str, Any]:
        return {"message_content": message.content}

class CachedContextStrategy(ContextStrategy):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥"""

    async def get_context(self, bot: commands.Bot, message: discord.Message,
                         config: TaskConfig, page_ids: List[str]) -> Dict[str, Any]:
        cache_manager = get_cache_manager()
        page_id = page_ids[0] if page_ids else None

        context = {"message_content": message.content}

        if page_id and config.use_kb:
            # ç›´æ¥é–¢æ•°ã‚’å‘¼ã³å‡ºã—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            notion_context = await get_notion_context_for_message(
                bot=bot,
                message=message,
                page_id=page_id,
                query=message.content,
                model_choice="gpt5mini"
            )
            context["notion_context"] = notion_context or ""

        return context

class ParallelMemoryContextStrategy(ContextStrategy):
    """ä¸¦åˆ—ãƒ¡ãƒ¢ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥"""

    async def get_context(self, bot: commands.Bot, message: discord.Message,
                         config: TaskConfig, page_ids: List[str]) -> Dict[str, Any]:
        context = {"message_content": message.content}

        try:
            # ä¸¦åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚’è©¦è¡Œ
            context_data = await process_with_parallel_context(bot, message, page_ids, "unified")
            context["kb_context"] = context_data.get("kb_context", "")

            # ãƒ¡ãƒ¢ãƒªå±¥æ­´ã®å–å¾—
            if config.use_memory:
                memory_manager = get_enhanced_memory_manager()
                is_memory_on = await get_memory_flag_from_notion(str(message.channel.id))

                if is_memory_on:
                    history = memory_manager.get_history("unified", str(message.channel.id))
                    context["memory_history"] = "\n".join([f"{m['role']}: {m['content']}" for m in history]) if history else "ãªã—"
                else:
                    context["memory_history"] = "ãªã—"

        except Exception as e:
            safe_log("âš ï¸ ä¸¦åˆ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: ", e)
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥ã‚’ä½¿ç”¨
            fallback_strategy = CachedContextStrategy()
            context.update(await fallback_strategy.get_context(bot, message, config, page_ids))

        return context

class CouncilOptimizedContextStrategy(ContextStrategy):
    """AIè©•è­°ä¼šç”¨æœ€é©åŒ–æˆ¦ç•¥"""

    async def get_context(self, bot: commands.Bot, message: discord.Message,
                         config: TaskConfig, page_ids: List[str]) -> Dict[str, Any]:
        context = {"message_content": message.content}

        if page_ids:
            # åˆå›è¦ç´„ã®å–å¾—
            initial_summary = await get_notion_context_for_message(bot, message, page_ids[0], message.content, "gpt5mini")
            context["initial_summary"] = initial_summary or ""

        return context

class ContextStrategyFactory:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæˆ¦ç•¥ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"""

    _strategies = {
        "minimal": MinimalContextStrategy(),
        "cached": CachedContextStrategy(),
        "parallel_memory": ParallelMemoryContextStrategy(),
        "council_optimized": CouncilOptimizedContextStrategy()
    }

    @classmethod
    def get_strategy(cls, strategy_name: str) -> ContextStrategy:
        return cls._strategies.get(strategy_name, cls._strategies["cached"])

# å¾Œå‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆCommand Patternï¼‰
class PostProcessor(ABC):
    """å¾Œå‡¦ç†ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""

    @abstractmethod
    async def process(self, bot: commands.Bot, message: discord.Message,
                     response: str, config: TaskConfig, context: Dict[str, Any],
                     page_ids: List[str]) -> str:
        pass

class LogResponseProcessor(PostProcessor):
    """å¿œç­”ãƒ­ã‚°è¨˜éŒ²å‡¦ç†"""

    async def process(self, bot: commands.Bot, message: discord.Message,
                     response: str, config: TaskConfig, context: Dict[str, Any],
                     page_ids: List[str]) -> str:
        if page_ids:
            await log_response(page_ids[0], response, config.description)
        return response

class UpdateMemoryProcessor(PostProcessor):
    """ãƒ¡ãƒ¢ãƒªæ›´æ–°å‡¦ç†"""

    async def process(self, bot: commands.Bot, message: discord.Message,
                     response: str, config: TaskConfig, context: Dict[str, Any],
                     page_ids: List[str]) -> str:
        if config.use_memory and "ã‚¨ãƒ©ãƒ¼" not in response:
            memory_manager = get_enhanced_memory_manager()
            memory_manager.add_interaction(
                ai_type="unified",
                channel_id=str(message.channel.id),
                user_content=message.content,
                ai_response=response,
                metadata={
                    "task_type": config.task_type,
                    "timestamp": time.time()
                }
            )
        return response

class KBSummaryProcessor(PostProcessor):
    """KBè¦ç´„å‡¦ç†"""

    async def process(self, bot: commands.Bot, message: discord.Message,
                     response: str, config: TaskConfig, context: Dict[str, Any],
                     page_ids: List[str]) -> str:
        if config.use_summary and len(page_ids) > 1:
            try:
                cache_manager = get_cache_manager()
                summary_prompt = f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Notion KBç”¨ã«150å­—ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã›ã‚ˆã€‚\n\n{response}"
                summary_hash = hashlib.md5(summary_prompt.encode()).hexdigest()[:12]

                official_summary = await cache_manager.get_ai_response_cached(
                    ai_type="gpt5mini",
                    prompt_hash=summary_hash,
                    fetch_func=ask_gpt5_mini,
                    openai_client=bot.openai_client,
                    prompt=summary_prompt
                )

                if official_summary:
                    kb_page_id = page_ids[1]
                    new_section_id = await find_latest_section_id(kb_page_id)
                    await append_summary_to_kb(kb_page_id, new_section_id, official_summary)

                    return f"{response}\n\n---\n*ã“ã®å›ç­”ã¯KBã« **{new_section_id}** ã¨ã—ã¦è¨˜éŒ²ã•ã‚Œã¾ã—ãŸã€‚*"

            except Exception as e:
                safe_log("âš ï¸ KBè¦ç´„å‡¦ç†ã‚¨ãƒ©ãƒ¼: ", e)

        return response

class PostProcessorFactory:
    """å¾Œå‡¦ç†ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"""

    _processors = {
        "log_response": LogResponseProcessor(),
        "update_memory": UpdateMemoryProcessor(),
        "kb_summary": KBSummaryProcessor()
    }

    @classmethod
    def get_processor(cls, processor_name: str) -> Optional[PostProcessor]:
        return cls._processors.get(processor_name)

# çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³
class UnifiedTaskEngine:
    """çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ - å…¨ã¦ã®AIå‡¦ç†ã‚’çµ±åˆ"""

    def __init__(self, config_manager=None):
        self.config_manager = config_manager
        self.config_loader = TaskConfigLoader()
        self.ai_manager = get_ai_manager()
        self.memory_manager = get_enhanced_memory_manager()
        self.cache_manager = get_cache_manager()

        # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
        from plugin_system import get_plugin_manager
        self.plugin_manager = get_plugin_manager()

        # çµ±è¨ˆ
        self.task_count = 0
        self.error_count = 0
        self.total_execution_time = 0

    async def execute_task(self, bot: commands.Bot, message: discord.Message, ai_type: str) -> TaskResult:
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        start_time = time.time()
        self.task_count += 1

        try:
            # é‡è¤‡å‡¦ç†é˜²æ­¢
            message_id = str(message.id)
            if not self.memory_manager.start_message_processing(message_id):
                return TaskResult(
                    success=False,
                    response="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ—¢ã«å‡¦ç†ä¸­ã¾ãŸã¯å‡¦ç†æ¸ˆã¿ã§ã™",
                    metadata={"duplicate": True},
                    execution_time=0,
                    error="Duplicate message"
                )

            # è¨­å®šèª­ã¿è¾¼ã¿
            config = self.config_loader.get_task_config(ai_type)

            # Phase 2: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ task_execution ãƒ•ãƒƒã‚¯ã§ç‰¹æ®Šå‡¦ç†ãƒã‚§ãƒƒã‚¯
            task_results = await self.plugin_manager.execute_hook(
                HookType.TASK_EXECUTION,
                bot=bot, message=message, ai_type=ai_type, context={}
            )

            # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãŒã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã—ãŸå ´åˆ
            for result in task_results:
                if result.success and result.modified:
                    self.plugin_tasks += 1
                    safe_log(f"ğŸ”Œ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ: ", ai_type)

                    # Phase 3: post_task_execution ãƒ•ãƒƒã‚¯
                    post_results = await self.plugin_manager.execute_hook(
                        HookType.POST_TASK_EXECUTION,
                        bot=bot, message=message, ai_type=ai_type,
                        response=result.data, context={}
                    )

                    return TaskResult(
                        success=True,
                        response=result.data,
                        metadata={
                            "plugin_handled": True,
                            "execution_time": getattr(result, 'execution_time', 0)
                        },
                        execution_time=time.time() - start_time
                    )

            # Notionè¨­å®šç¢ºèªï¼ˆgenius_lightã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            page_ids = []
            if ai_type == "genius_pro":
                page_ids = NOTION_PAGE_MAP.get(str(message.channel.id))
                if not page_ids:
                    return TaskResult(
                        success=False,
                        response="âŒ Notionæœªé€£æº",
                        metadata={"no_notion": True},
                        execution_time=time.time() - start_time,
                        error="No Notion configuration"
                    )
            else:
                page_ids = []

            # æ¨™æº–ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
            result = await self._execute_standard_task(bot, message, ai_type, config, page_ids)

            # å‡¦ç†å®Œäº†
            self.memory_manager.finish_message_processing(message_id, success=result.success)
            result.execution_time = time.time() - start_time

            if result.success:
                self.total_execution_time += result.execution_time
            else:
                self.error_count += 1

            return result

        except Exception as e:
            self.error_count += 1
            safe_log("ğŸš¨ çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼: ", e)
            self.memory_manager.finish_message_processing(message_id, success=False)

            return TaskResult(
                success=False,
                response=f"ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)[:100]}",
                metadata={"exception": str(e)},
                execution_time=time.time() - start_time,
                error=str(e)
            )

    async def _execute_standard_task(self, bot: commands.Bot, message: discord.Message,
                                   ai_type: str, config: TaskConfig, page_ids: List[str]) -> TaskResult:
        """æ¨™æº–ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œ"""

        async with message.channel.typing():
            # 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆæˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            strategy = ContextStrategyFactory.get_strategy(config.context_strategy)
            context = await strategy.get_context(bot, message, config, page_ids)

            # 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            prompt = self._build_prompt(config, context)

            # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ­ã‚°è¨˜éŒ²ï¼ˆgenius_proã®ã¿ï¼‰
            if ai_type == "genius_pro" and page_ids:
                await log_user_message(page_ids[0], message.author.display_name, message.content)

            # 4. AIå®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±åˆï¼‰
            response = await self._execute_ai(ai_type, prompt, config, bot)

            # 5. å¾Œå‡¦ç†ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            final_response = await self._execute_post_processing(
                bot, message, response, config, context, page_ids
            )

            # 6. å¿œç­”é€ä¿¡
            await send_long_message(bot.openai_client, message.channel, final_response)

            return TaskResult(
                success=True,
                response=final_response,
                metadata={
                    "ai_type": ai_type,
                    "task_type": config.task_type,
                    "context_strategy": config.context_strategy,
                    "post_processing": config.post_processing
                },
                execution_time=0  # å¾Œã§è¨­å®šã•ã‚Œã‚‹
            )

    def _build_prompt(self, config: TaskConfig, context: Dict[str, Any]) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        template = self.config_loader.get_prompt_template(config.prompt_template)

        try:
            return template.format(**context)
        except KeyError as e:
            safe_log("âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: ", f"Missing key {e}")
            return context.get("message_content", "")

    async def _execute_ai(self, ai_type: str, prompt: str, config: TaskConfig, bot=None) -> str:
        """AIå®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±åˆï¼‰"""
        try:
            # AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
            if not self.ai_manager.initialized and bot:
                self.ai_manager.initialize(bot)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒƒã‚·ãƒ¥ä½œæˆ
            prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:12]

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å¿œç­”ã‚’è©¦è¡Œå–å¾—
            cache_key = f"{ai_type}:{prompt_hash}"
            cached_response = await self.cache_manager.get_cached(
                "ai_response",
                {"ai_type": ai_type, "prompt_hash": prompt_hash},
                None
            )

            if cached_response:
                safe_log(f"âš¡ AIå¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ ({ai_type}): ", f"ãƒãƒƒã‚·ãƒ¥:{prompt_hash}")
                return cached_response

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼šAIå®Ÿè¡Œ
            response = await self.ai_manager.ask_ai(ai_type, prompt, priority=config.priority)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if response:
                await self.cache_manager.set_cached(
                    "ai_response",
                    {"ai_type": ai_type, "prompt_hash": prompt_hash},
                    response
                )

            return response or f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚{ai_type}ã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚"

        except Exception as e:
            return f"{ai_type}ã‚¨ãƒ©ãƒ¼: {str(e)[:200]}"

    async def _execute_post_processing(self, bot: commands.Bot, message: discord.Message,
                                     response: str, config: TaskConfig, context: Dict[str, Any],
                                     page_ids: List[str]) -> str:
        """å¾Œå‡¦ç†å®Ÿè¡Œ"""
        current_response = response

        for processor_name in (config.post_processing or []):
            processor = PostProcessorFactory.get_processor(processor_name)
            if processor:
                try:
                    current_response = await processor.process(
                        bot, message, current_response, config, context, page_ids
                    )
                except Exception as e:
                    safe_log(f"âš ï¸ å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ ({processor_name}): ", e)

        return current_response

    # _handle_genius_council ã¯ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œæ¸ˆã¿

    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        avg_time = self.total_execution_time / max(self.task_count, 1)
        error_rate = self.error_count / max(self.task_count, 1)

        return {
            "total_tasks": self.task_count,
            "errors": self.error_count,
            "error_rate": f"{error_rate:.1%}",
            "avg_execution_time": f"{avg_time:.2f}s",
            "engine_version": "3.0"
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_unified_task_engine: Optional[UnifiedTaskEngine] = None

def get_unified_task_engine() -> UnifiedTaskEngine:
    """çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _unified_task_engine
    if _unified_task_engine is None:
        _unified_task_engine = UnifiedTaskEngine()
        safe_log("âœ… çµ±ä¸€ã‚¿ã‚¹ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†", "")
    return _unified_task_engine

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=== Unified Task Engine Test ===")

    engine = UnifiedTaskEngine()
    config = engine.config_loader.get_task_config("gpt5")
    print(f"GPT-5è¨­å®š: {config}")

    print("âœ… Unified Task Engine is ready!")