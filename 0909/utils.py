import discord
from discord.ext import commands
import asyncio
import base64
import io
import json
import PyPDF2
from openai import AsyncOpenAI
from mistralai.async_client import MistralAsyncClient

# ai_clients ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ai_clients import ask_lalah, ask_gpt5, ask_gpt4o, ask_gemini_2_5_pro, ask_rekus

# notion_utils ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from notion_utils import get_notion_page_text

# --- ãƒ­ã‚°ãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ ---

def safe_log(prefix: str, obj):
    try:
        s = json.dumps(obj, ensure_ascii=False, indent=2) if isinstance(obj, (dict, list, tuple)) else str(obj)
        print(f"{prefix}{s[:2000]}")
    except Exception as e:
        print(f"{prefix}(log skipped: {e})")

async def send_long_message(openai_client: AsyncOpenAI, target, text: str, is_followup: bool = False, mention: str = ""):
    if not text: text = "ï¼ˆå¿œç­”ãŒç©ºã§ã—ãŸï¼‰"
    full_text = f"{mention}\n{text}" if mention and mention not in text else text

    final_content = full_text
    if len(full_text) > 2000:
        summary_prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã¯Discordã®æ–‡å­—æ•°åˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚å†…å®¹ã®è¦ç‚¹ã‚’æœ€ã‚‚é‡è¦è¦–ã—ã€1800æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n---\n\n{text}"
        try:
            response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": summary_prompt}], max_tokens=1800, temperature=0.2)
            summary = response.choices[0].message.content
            header = f"{mention}\n" if mention else ""
            final_content = f"{header}âš ï¸ å…ƒã®å›ç­”ãŒ2000æ–‡å­—ã‚’è¶…ãˆãŸãŸã‚ã€gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸï¼š\n\n{summary}"
        except Exception as e:
            safe_log("ğŸš¨ send_long_messageã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            header = f"{mention}\n" if mention else ""
            final_content = f"{header}å…ƒã®å›ç­”ã¯é•·ã™ãã¾ã—ãŸãŒã€è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    
    try:
        if isinstance(target, discord.Interaction):
            if is_followup: await target.followup.send(final_content)
            else:
                if not target.response.is_done(): await target.edit_original_response(content=final_content)
                else: await target.followup.send(final_content)
        else: await target.send(final_content)
    except (discord.errors.InteractionResponded, discord.errors.NotFound) as e:
        safe_log(f"âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã«å¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰:", e)
        if hasattr(target, 'channel') and target.channel: await target.channel.send(final_content)

# --- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è§£æ ---

async def analyze_attachment_for_gpt5(openai_client: AsyncOpenAI, attachment: discord.Attachment):
    filename = attachment.filename.lower()
    data = await attachment.read()
    if filename.endswith((".png", ".jpg", ".jpeg", ".gif", ".webp")):
        content = [{"type": "text", "text": "ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚"}, {"type": "image_url", "image_url": {"url": f"data:{attachment.content_type};base64,{base64.b64encode(data).decode()}"}}]
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": content}], max_tokens=1500)
        return f"[gpt-4oç”»åƒè§£æ]\n{response.choices[0].message.content}"
    elif filename.endswith((".py", ".txt", ".md", ".json", ".html", ".css", ".js")):
        return f"[æ·»ä»˜ã‚³ãƒ¼ãƒ‰ {attachment.filename}]\n```\n{data.decode('utf-8', errors='ignore')[:3500]}\n```"
    elif filename.endswith(".pdf"):
        try:
            loop = asyncio.get_event_loop()
            reader = await loop.run_in_executor(None, lambda: PyPDF2.PdfReader(io.BytesIO(data)))
            all_text = await loop.run_in_executor(None, lambda: "\n".join([p.extract_text() or "" for p in reader.pages]))
            return f"[æ·»ä»˜PDF {attachment.filename} æŠœç²‹]\n{all_text[:3500]}"
        except Exception as e: return f"[PDFè§£æã‚¨ãƒ©ãƒ¼: {e}]"
    else: return f"[æœªå¯¾å¿œã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {attachment.filename}]"

# --- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¨Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾— ---

async def summarize_text_chunks(bot: commands.Bot, channel, text: str, query: str, model_choice: str):
    chunk_size = 12000
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    summarizer_map = {
        "gpt": lambda p: ask_gpt4o(bot.openai_client, p),
        "gemini": ask_gemini_2_5_pro, # Geminiã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¸è¦
        "perplexity": lambda p: ask_rekus(bot.perplexity_api_key, p)
    }
    summarizer_func = summarizer_map.get(model_choice, ask_gemini_2_5_pro)

    async def summarize_chunk(chunk):
        prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹é€ åŒ–ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
                  "è¦ç´„ã«ã¯ä»¥ä¸‹ã®ã‚¿ã‚°ã‚’ä»˜ã‘ã¦åˆ†é¡ã—ã¦ãã ã•ã„ï¼š[èƒŒæ™¯æƒ…å ±], [å®šç¾©ãƒ»å‰æ], [äº‹å®ŸçµŒé], [æœªè§£æ±ºèª²é¡Œ], [è£œè¶³æƒ…å ±]\n\n{chunk}")
        try:
            return await summarizer_func(prompt)
        except Exception as e:
            safe_log(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            return None
    tasks = [summarize_chunk(chunk) for chunk in text_chunks]
    chunk_summaries = [s for s in await asyncio.gather(*tasks) if s]
    if not chunk_summaries: return None
    if len(chunk_summaries) == 1: return chunk_summaries[0]
    
    combined = "\n---\n".join(chunk_summaries)
    final_prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¸ã®å›ç­”ã¨ãªã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®è¤‡æ•°ã®è¦ç´„ç¾¤ã‚’ä¸€ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n{combined}")
    return await ask_lalah(bot.mistral_client, final_prompt)

# â–¼â–¼â–¼ã€ä¿®æ­£ã€‘æŠœã‘è½ã¡ã¦ã„ãŸé–¢æ•°ã‚’è¿½åŠ  â–¼â–¼â–¼
async def get_notion_context(bot: commands.Bot, interaction: discord.Interaction, page_id: str, query: str, model_choice: str = "gpt"):
    await interaction.edit_original_response(content="...Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text([page_id])
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await interaction.edit_original_response(content="âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    return await summarize_text_chunks(bot, interaction.channel, notion_text, query, model_choice)

async def get_notion_context_for_message(bot: commands.Bot, message: discord.Message, page_id: str, query: str, model_choice: str):
    notion_text = await get_notion_page_text([page_id])
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    return await summarize_text_chunks(bot, message.channel, notion_text, query, model_choice)
# â–²â–²â–² ã“ã“ã¾ã§è¿½åŠ  â–²â–²â–²

# --- å¿œç­”ã¨è¦ç´„ã®ã‚»ãƒƒãƒˆå–å¾— ---

async def get_full_response_and_summary(openrouter_api_key: str, ai_function, prompt: str, **kwargs):
    full_response = await ai_function(prompt, **kwargs)
    if not full_response or "ã‚¨ãƒ©ãƒ¼" in str(full_response): return full_response, None
    summary_prompt = f"æ¬¡ã®æ–‡ç« ã‚’200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã‹ã¤æ„å‘³ãŒé€šã˜ã‚‹ã‚ˆã†ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{full_response}"
    summary = await ask_gpt5(openrouter_api_key, summary_prompt)
    if "ã‚¨ãƒ©ãƒ¼" in str(summary): return full_response, None
    return full_response, summary