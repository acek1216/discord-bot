# -*- coding: utf-8 -*-
"""
éåŒæœŸå‡¦ç†æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
asyncio.gatherã‚’æ´»ç”¨ã—ãŸä¸¦åˆ—å‡¦ç†ã®æ”¹å–„
"""

import asyncio
import time
from typing import List, Dict, Any, Optional, Callable, Tuple
from dataclasses import dataclass
from utils import safe_log

@dataclass
class AsyncTask:
    """éåŒæœŸã‚¿ã‚¹ã‚¯ã®å®šç¾©"""
    name: str
    coro: Callable
    args: tuple = ()
    kwargs: dict = None
    timeout: Optional[float] = None
    required: bool = True  # å¿…é ˆã‚¿ã‚¹ã‚¯ã‹ã©ã†ã‹

    def __post_init__(self):
        if self.kwargs is None:
            self.kwargs = {}

@dataclass
class AsyncResult:
    """éåŒæœŸã‚¿ã‚¹ã‚¯ã®çµæœ"""
    name: str
    success: bool
    result: Any = None
    error: Optional[Exception] = None
    duration: float = 0.0

class AsyncOptimizer:
    """éåŒæœŸå‡¦ç†æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.total_tasks = 0
        self.total_time_saved = 0.0
        self.execution_count = 0

    async def execute_parallel(self, tasks: List[AsyncTask]) -> Dict[str, AsyncResult]:
        """è¤‡æ•°ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        if not tasks:
            return {}

        start_time = time.time()
        self.execution_count += 1
        self.total_tasks += len(tasks)

        # ã‚¿ã‚¹ã‚¯ã‚’éåŒæœŸå®Ÿè¡Œç”¨ã«æº–å‚™
        async_tasks = []
        task_info = {}

        for task in tasks:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã‚¿ã‚¹ã‚¯ã®ä½œæˆ
            if task.timeout:
                coro = asyncio.wait_for(
                    task.coro(*task.args, **task.kwargs),
                    timeout=task.timeout
                )
            else:
                coro = task.coro(*task.args, **task.kwargs)

            async_task = asyncio.create_task(coro, name=task.name)
            async_tasks.append(async_task)
            task_info[task.name] = task

        # ä¸¦åˆ—å®Ÿè¡Œ
        safe_log(f"ğŸš€ ä¸¦åˆ—å®Ÿè¡Œé–‹å§‹: ", f"{len(tasks)}å€‹ã®ã‚¿ã‚¹ã‚¯")

        results = {}
        try:
            # return_exceptions=Trueã§ä¾‹å¤–ã‚‚çµæœã¨ã—ã¦å–å¾—
            raw_results = await asyncio.gather(*async_tasks, return_exceptions=True)

            # çµæœã®å‡¦ç†
            for i, (task_name, raw_result) in enumerate(zip([t.name for t in tasks], raw_results)):
                task_start = time.time()

                if isinstance(raw_result, Exception):
                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                    task_required = task_info[task_name].required
                    error_msg = str(raw_result)

                    results[task_name] = AsyncResult(
                        name=task_name,
                        success=False,
                        error=raw_result,
                        duration=0.0
                    )

                    if task_required:
                        safe_log(f"ğŸš¨ å¿…é ˆã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: ", f"{task_name} - {error_msg[:100]}")
                    else:
                        safe_log(f"âš ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: ", f"{task_name} - {error_msg[:50]}")
                else:
                    # æˆåŠŸã®å ´åˆ
                    results[task_name] = AsyncResult(
                        name=task_name,
                        success=True,
                        result=raw_result,
                        duration=time.time() - task_start
                    )

        except Exception as e:
            safe_log(f"ğŸš¨ ä¸¦åˆ—å®Ÿè¡Œã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: ", e)
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå€‹åˆ¥å®Ÿè¡Œ
            results = await self._fallback_sequential(tasks)

        end_time = time.time()
        total_duration = end_time - start_time

        # çµ±è¨ˆæ›´æ–°
        estimated_sequential_time = sum(0.5 for _ in tasks)  # æ¨å®šé€æ¬¡å®Ÿè¡Œæ™‚é–“
        time_saved = max(0, estimated_sequential_time - total_duration)
        self.total_time_saved += time_saved

        safe_log(f"âœ… ä¸¦åˆ—å®Ÿè¡Œå®Œäº†: ",
                f"{len(tasks)}ã‚¿ã‚¹ã‚¯ã€{total_duration:.2f}ç§’ã€æ¨å®šçŸ­ç¸®:{time_saved:.2f}ç§’")

        return results

    async def _fallback_sequential(self, tasks: List[AsyncTask]) -> Dict[str, AsyncResult]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé€æ¬¡å®Ÿè¡Œ"""
        safe_log("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é€æ¬¡å®Ÿè¡Œ: ", f"{len(tasks)}ã‚¿ã‚¹ã‚¯")

        results = {}
        for task in tasks:
            start_time = time.time()
            try:
                if task.timeout:
                    result = await asyncio.wait_for(
                        task.coro(*task.args, **task.kwargs),
                        timeout=task.timeout
                    )
                else:
                    result = await task.coro(*task.args, **task.kwargs)

                results[task.name] = AsyncResult(
                    name=task.name,
                    success=True,
                    result=result,
                    duration=time.time() - start_time
                )
            except Exception as e:
                results[task.name] = AsyncResult(
                    name=task.name,
                    success=False,
                    error=e,
                    duration=time.time() - start_time
                )

        return results

    def get_stats(self) -> Dict[str, Any]:
        """æœ€é©åŒ–çµ±è¨ˆã‚’å–å¾—"""
        avg_tasks = self.total_tasks / max(self.execution_count, 1)
        return {
            "execution_count": self.execution_count,
            "total_tasks": self.total_tasks,
            "avg_tasks_per_execution": round(avg_tasks, 1),
            "total_time_saved": round(self.total_time_saved, 2),
            "avg_time_saved": round(self.total_time_saved / max(self.execution_count, 1), 2)
        }

# å…·ä½“çš„ãªæœ€é©åŒ–é–¢æ•°ç¾¤

async def get_notion_contexts_parallel(bot, message, page_ids: List[str], query: str) -> Dict[str, str]:
    """Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸¦åˆ—å–å¾—"""
    from notion_utils import get_notion_page_text
    from utils import get_notion_context_for_message

    if not page_ids:
        return {}

    optimizer = AsyncOptimizer()
    tasks = []

    # è¤‡æ•°ãƒšãƒ¼ã‚¸ã®ä¸¦åˆ—å–å¾—
    for i, page_id in enumerate(page_ids):
        task_name = f"notion_page_{i}"
        if i == 0:
            # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆãƒ­ã‚°ç”¨ï¼‰
            tasks.append(AsyncTask(
                name=task_name,
                coro=get_notion_page_text,
                args=([page_id],),
                timeout=10.0,
                required=True
            ))
        else:
            # KBãƒšãƒ¼ã‚¸ï¼ˆè¦ç´„ä»˜ãï¼‰
            tasks.append(AsyncTask(
                name=f"notion_context_{i}",
                coro=get_notion_context_for_message,
                args=(bot, message, page_id, query, "gpt5mini"),
                timeout=15.0,
                required=False
            ))

    results = await optimizer.execute_parallel(tasks)

    # çµæœã‚’ã¾ã¨ã‚ã‚‹
    contexts = {}
    for task_name, result in results.items():
        if result.success:
            contexts[task_name] = result.result
        else:
            contexts[task_name] = ""

    return contexts

async def analyze_attachment_parallel(bot, attachments) -> List[str]:
    """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—è§£æ"""
    from utils import analyze_attachment_for_gpt5

    if not attachments:
        return []

    optimizer = AsyncOptimizer()
    tasks = []

    for i, attachment in enumerate(attachments[:3]):  # æœ€å¤§3ã¤ã¾ã§
        tasks.append(AsyncTask(
            name=f"attachment_{i}",
            coro=analyze_attachment_for_gpt5,
            args=(bot.openai_client, attachment),
            timeout=20.0,
            required=False
        ))

    results = await optimizer.execute_parallel(tasks)

    # æˆåŠŸã—ãŸè§£æçµæœã®ã¿è¿”ã™
    analyses = []
    for result in results.values():
        if result.success and result.result:
            analyses.append(result.result)

    return analyses

async def multi_ai_council_parallel(bot, prompt: str, ai_types: List[str]) -> Dict[str, str]:
    """è¤‡æ•°AIã«ä¸¦åˆ—ã§åŒã˜è³ªå•"""
    from ai_manager import get_ai_manager

    ai_manager = get_ai_manager()
    if not ai_manager.initialized:
        ai_manager.initialize(bot)

    optimizer = AsyncOptimizer()
    tasks = []

    for ai_type in ai_types:
        if ai_type in ai_manager.get_available_ais():
            tasks.append(AsyncTask(
                name=f"ai_{ai_type}",
                coro=ai_manager.ask_ai,
                args=(ai_type, prompt),
                timeout=30.0,
                required=False
            ))

    results = await optimizer.execute_parallel(tasks)

    # AIåã‚’ã‚­ãƒ¼ã¨ã—ãŸçµæœè¾æ›¸
    ai_responses = {}
    for task_name, result in results.items():
        ai_name = task_name.replace("ai_", "")
        if result.success:
            ai_responses[ai_name] = result.result
        else:
            ai_responses[ai_name] = f"ã‚¨ãƒ©ãƒ¼: {result.error}"

    return ai_responses

async def process_with_parallel_context(bot, message, page_ids: List[str], ai_type: str) -> Dict[str, Any]:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ç”¨ã®æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—å‡¦ç†"""
    optimizer = AsyncOptimizer()
    tasks = []

    # 1. Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
    if page_ids:
        from utils import get_notion_context_for_message

        # KBç”¨ãƒšãƒ¼ã‚¸ï¼ˆè¦ç´„ä»˜ãï¼‰
        if len(page_ids) > 1:
            tasks.append(AsyncTask(
                name="kb_context",
                coro=get_notion_context_for_message,
                args=(bot, message, page_ids[1], message.content, "gpt5mini"),
                timeout=10.0,
                required=False
            ))

        # ãƒ­ã‚°ç”¨ãƒšãƒ¼ã‚¸ï¼ˆç”Ÿãƒ†ã‚­ã‚¹ãƒˆï¼‰
        from notion_utils import get_notion_page_text
        tasks.append(AsyncTask(
            name="log_context",
            coro=get_notion_page_text,
            args=([page_ids[0]],),
            timeout=8.0,
            required=False
        ))

    # 2. æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è§£æ
    if message.attachments:
        tasks.append(AsyncTask(
            name="attachment_analysis",
            coro=analyze_attachment_parallel,
            args=(bot, message.attachments),
            timeout=15.0,
            required=False
        ))

    # 3. ãƒ¡ãƒ¢ãƒªå–å¾—ï¼ˆéåŒæœŸåŒ–å¯èƒ½ãªå ´åˆï¼‰
    from memory_manager import get_memory_manager
    from notion_utils import get_memory_flag_from_notion

    tasks.append(AsyncTask(
        name="memory_flag",
        coro=get_memory_flag_from_notion,
        args=(str(message.channel.id),),
        timeout=5.0,
        required=False
    ))

    # ä¸¦åˆ—å®Ÿè¡Œ
    results = await optimizer.execute_parallel(tasks)

    # çµæœã®æ•´ç†
    context_data = {
        "kb_context": results.get("kb_context", AsyncResult("kb_context", False)).result or "",
        "log_context": results.get("log_context", AsyncResult("log_context", False)).result or "",
        "attachment_analyses": results.get("attachment_analysis", AsyncResult("attachment_analysis", False)).result or [],
        "is_memory_on": results.get("memory_flag", AsyncResult("memory_flag", False)).result or False,
        "optimizer_stats": optimizer.get_stats()
    }

    return context_data

# ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©åŒ–çµ±è¨ˆ
global_optimizer_stats = {
    "total_optimizations": 0,
    "total_time_saved": 0.0
}

def get_global_optimization_stats() -> Dict[str, Any]:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©åŒ–çµ±è¨ˆã‚’å–å¾—"""
    return global_optimizer_stats.copy()

def update_global_stats(time_saved: float):
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã‚’æ›´æ–°"""
    global_optimizer_stats["total_optimizations"] += 1
    global_optimizer_stats["total_time_saved"] += time_saved