import discord
from discord import app_commands
from discord.ext import commands
import asyncio
import os

# --- å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from ai_clients import (
    ask_gpt_base, ask_gemini_base, ask_mistral_base, ask_claude, ask_llama, ask_grok,
    ask_gpt4o, ask_minerva, ask_rekus, ask_gpt5, ask_gpt5_mini, ask_gemini_2_5_pro,
    ask_lalah, ask_o1_pro
)
from notion_utils import NOTION_PAGE_MAP, log_to_notion, log_response, log_user_message, find_latest_section_id, append_summary_to_kb
from utils import (
    safe_log, send_long_message, analyze_attachment_for_gemini,
    get_full_response_and_summary, get_notion_context
)

# ----------------------------------------------------------------
# ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰åˆ©ç”¨ã•ã‚Œã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
# ----------------------------------------------------------------
async def simple_ai_command_runner(bot: commands.Bot, interaction: discord.Interaction, prompt: str, ai_function, bot_name: str):
    await interaction.response.defer()
    user_id = str(interaction.user.id)
    
    memory_map = {
        "GPT": bot.gpt_base_memory, "Gemini": bot.gemini_base_memory,
        "Mistral": bot.mistral_base_memory, "Claude": bot.claude_base_memory,
        "Llama": bot.llama_base_memory, "Grok": bot.grok_base_memory
    }
    
    clean_bot_name = bot_name.split("-")[0].split(" ")[0]
    memory = memory_map.get(clean_bot_name)
    history = memory.get(user_id, []) if memory is not None else []

    try:
        # ã“ã®å‘¼ã³å‡ºã—ã§ 'history' ã¨ã„ã†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã‚’ä½¿ã£ã¦ã„ã‚‹
        reply = await ai_function(user_id, prompt, history=history)

        if memory is not None and "ã‚¨ãƒ©ãƒ¼" not in str(reply):
            new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
            memory[user_id] = new_history[-10:]
        
        await send_long_message(bot.openai_client, interaction, reply, is_followup=True)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

async def advanced_ai_simple_runner(bot: commands.Bot, interaction: discord.Interaction, prompt: str, ai_function, bot_name: str):
    await interaction.response.defer()
    try:
        reply = await ai_function(prompt)
        await send_long_message(bot.openai_client, interaction, reply, is_followup=True)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ----------------------------------------------------------------
# Cogã‚¯ãƒ©ã‚¹ã®å®šç¾©
# ----------------------------------------------------------------
class CommandCog(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        # â–¼â–¼â–¼ã€ä¿®æ­£ç®‡æ‰€ã€‘lambdaã®å¼•æ•°åã‚’ 'h' ã‹ã‚‰ 'history' ã«å¤‰æ›´ â–¼â–¼â–¼
        self.BASE_MODELS_FOR_ALL = {
            "GPT": lambda user_id, prompt, history=None: ask_gpt_base(self.bot.openai_client, user_id, prompt, history),
            "Gemini": lambda user_id, prompt, history=None: ask_gemini_base(user_id, prompt, history),
            "Claude": lambda user_id, prompt, history=None: ask_claude(self.bot.openrouter_api_key, user_id, prompt, history),
            "Llama": lambda user_id, prompt, history=None: ask_llama(self.bot.llama_model, user_id, prompt, history),
            "Grok": lambda user_id, prompt, history=None: ask_grok(self.bot.grok_api_key, user_id, prompt, history)
        }
        async def get_gpt4o_response(p, **kwargs):
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            if not ai_manager.initialized:
                ai_manager.initialize(self.bot)
            return await ai_manager.ask_ai("gpt4o", p, **kwargs)

        async def get_gpt5_response(p, **kwargs):
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            if not ai_manager.initialized:
                ai_manager.initialize(self.bot)
            return await ai_manager.ask_ai("gpt5", p, **kwargs)

        self.ADVANCED_MODELS_FOR_ALL = {
            "gpt-4o": (get_gpt4o_response,
                       lambda af, p, **kwargs: get_full_response_and_summary(self.bot.openrouter_api_key, af, p, **kwargs)),
            "Gemini 2.5 Flash": (ask_minerva,
                                 lambda af, p, **kwargs: get_full_response_and_summary(self.bot.openrouter_api_key, af, p, **kwargs)),
            "Perplexity": (lambda p, **kwargs: ask_rekus(self.bot.perplexity_api_key, p, **kwargs),
                           lambda af, p, **kwargs: get_full_response_and_summary(self.bot.openrouter_api_key, af, p, **kwargs)),
            "Gemini 2.5 Pro": (ask_gemini_2_5_pro,
                               lambda af, p, **kwargs: get_full_response_and_summary(self.bot.openrouter_api_key, af, p, **kwargs)),
            "gpt-5": (get_gpt5_response,
                      lambda af, p, **kwargs: get_full_response_and_summary(self.bot.openrouter_api_key, af, p, **kwargs))
        }

    # (ä»¥é™ã®ã‚³ãƒãƒ³ãƒ‰å®šç¾©ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
# ğŸ—‘ï¸ /gpt ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gpt-chat ã§ä»£æ›¿

# ğŸ—‘ï¸ /gemini ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gemini-room ã§ä»£æ›¿

# ğŸ—‘ï¸ /claude ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #claude-discussion ã§ä»£æ›¿

# ğŸ—‘ï¸ /llama ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #llama-chat ã§ä»£æ›¿

# ğŸ—‘ï¸ /grok ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #grok-ai ã§ä»£æ›¿

# ğŸ—‘ï¸ /gpt-4o ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gpt4o-chat ã§ä»£æ›¿

# ğŸ—‘ï¸ /gemini-2-5-flash ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gemini-flash ã§ä»£æ›¿

# ğŸ—‘ï¸ /perplexity ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: ã‚³ãƒãƒ³ãƒ‰ã®ã¿ã®å‘¼ã³å‡ºã—ã¯éæ¨å¥¨ã€/all ã§ä»£æ›¿

# ğŸ—‘ï¸ /gpt5 ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gpt-premium ã§ä»£æ›¿

# ğŸ—‘ï¸ /gemini-2-5-pro ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gemini-pro ã§ä»£æ›¿

# ğŸ—‘ï¸ /gemini-1-5-pro ã‚³ãƒãƒ³ãƒ‰å‰Šé™¤: å°‚ç”¨ãƒãƒ£ãƒ³ãƒãƒ« #gemini1.5pro-chat ã§ä»£æ›¿

    @app_commands.command(name="notion", description="ç¾åœ¨ã®Notionãƒšãƒ¼ã‚¸ã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã—ã¾ã™ï¼ˆå…¨æ–‡é«˜ç²¾åº¦å‡¦ç†ï¼‰")
    @app_commands.describe(query="Notionãƒšãƒ¼ã‚¸ã«é–¢ã™ã‚‹è³ªå•")
    async def notion_command(self, interaction: discord.Interaction, query: str):
        await interaction.response.defer()
        try:
            # Geniusãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ä½¿ç”¨ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆgenius-proã¯é™¤å¤–ï¼‰
            channel_name = interaction.channel.name.lower()
            if "genius" in channel_name and "genius-pro" not in channel_name and "geniuspro" not in channel_name:
                await interaction.edit_original_response(content="âŒ `/notion`ã‚³ãƒãƒ³ãƒ‰ã¯Geniuséƒ¨å±‹ã§ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚\nğŸ’¡ Geniuséƒ¨å±‹ã§ã¯æ™®é€šã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹ã ã‘ã§è‡ªå‹•å¿œç­”ã—ã¾ã™ã€‚")
                return

            page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not page_ids:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return

            target_page_id = page_ids[0]
            user_name = interaction.user.display_name
            await log_to_notion(target_page_id, [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {user_name} (via /notion):\n{query}"}}]}}])
            
            # å…¨æ–‡å–å¾—ï¼ˆ4000æ–‡å­—åˆ¶é™ãªã—ï¼‰
            await interaction.edit_original_response(content="ğŸ“– Notionãƒšãƒ¼ã‚¸å…¨æ–‡ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            from notion_utils import get_notion_page_text
            full_text = await get_notion_page_text([target_page_id])
            
            if full_text.startswith("ERROR:") or not full_text.strip():
                await interaction.edit_original_response(content="âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            
            # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼šGPT5miniã§å„ãƒãƒ£ãƒ³ã‚¯ã‚’è¦ç´„
            await interaction.edit_original_response(content="âš™ï¸ GPT-5miniã§ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ä¸­...")
            chunk_summaries = []
            chunk_size = 4000
            for i in range(0, len(full_text), chunk_size):
                chunk = full_text[i:i+chunk_size]
                chunk_prompt = f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œ{query}ã€ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æŠ½å‡ºã—è¦ç´„ã—ã¦ãã ã•ã„ã€‚é–¢é€£æƒ…å ±ãŒãªã„å ´åˆã¯ã€Œé–¢é€£æƒ…å ±ãªã—ã€ã¨å›ç­”ã€‚\n\n{chunk}"
                from ai_manager import get_ai_manager
                ai_manager = get_ai_manager()
                if not ai_manager.initialized:
                    ai_manager.initialize(self.bot)
                summary = await ai_manager.ask_ai("gpt5mini", chunk_prompt)
                if "é–¢é€£æƒ…å ±ãªã—" not in summary:
                    chunk_summaries.append(summary)
            
            if not chunk_summaries:
                await interaction.edit_original_response(content="âŒ è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            
            # O1-Proã§çµ±åˆ
            await interaction.edit_original_response(content="ğŸ§  O1-Proã§æƒ…å ±ã‚’çµ±åˆä¸­...")
            integration_material = "\n\n---\n\n".join(chunk_summaries)
            integration_prompt = f"ä»¥ä¸‹ã®è¤‡æ•°ã®æƒ…å ±ã‚’çµ±åˆã—ã€ã€Œ{query}ã€ã«å¯¾ã™ã‚‹ä¸€è²«ã—ãŸå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n{integration_material}"
            integrated_answer = await ask_o1_pro(self.bot.o1_api_key, integration_prompt)
            
            # Gemini 2.5 Proã§æœ€çµ‚å›ç­”
            await interaction.edit_original_response(content="âœ¨ Gemini 2.5 Proã§æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆä¸­...")
            final_prompt = f"ã€çµ±åˆæ¸ˆã¿æƒ…å ±ã€‘\n{integrated_answer}\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nä¸Šè¨˜ã®çµ±åˆæƒ…å ±ã‚’åŸºã«ã€è³ªå•ã«å¯¾ã™ã‚‹æœ€çµ‚çš„ã§å®Œå…¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            final_answer = await ask_gemini_2_5_pro(final_prompt)
            
            await log_response(target_page_id, final_answer, "Notioné«˜ç²¾åº¦å‡¦ç† (/notionã‚³ãƒãƒ³ãƒ‰)")
            await send_long_message(self.bot.openai_client, interaction, f"**ğŸ¯ é«˜ç²¾åº¦å‡¦ç†ã«ã‚ˆã‚‹æœ€çµ‚å›ç­”:**\n{final_answer}", is_followup=False, primary_ai="gpt5mini")

        except Exception as e:
            safe_log("ğŸš¨ /notion ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
            if not interaction.response.is_done():
                await interaction.edit_original_response(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    @app_commands.command(name="minna", description="6ä½“ã®ãƒ™ãƒ¼ã‚¹AIãŒè­°é¡Œã«åŒæ™‚ã«æ„è¦‹ã‚’å‡ºã—ã¾ã™ã€‚")
    @app_commands.describe(prompt="AIã«å°‹ã­ã‚‹è­°é¡Œ")
    async def minna_command(self, interaction: discord.Interaction, prompt: str):
        await interaction.response.defer()
        user_id = str(interaction.user.id)

        # Notionãƒ­ã‚°è¨˜éŒ²
        page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
        if page_ids:
            await log_user_message(page_ids[0], interaction.user.display_name, f"/minna {prompt}")

        await interaction.followup.send("ğŸ”¬ 6ä½“ã®ãƒ™ãƒ¼ã‚¹AIãŒæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
        tasks = {name: func(user_id, prompt, history=[]) for name, func in self.BASE_MODELS_FOR_ALL.items()}
        results = await asyncio.gather(*tasks.values(), return_exceptions=True)
        all_responses = ""
        for (name, result) in zip(tasks.keys(), results):
            display_text = f"ã‚¨ãƒ©ãƒ¼: {result}" if isinstance(result, Exception) else result
            all_responses += f"ğŸ”¹ {name}ã®æ„è¦‹:\n{display_text}\n\n"
            await send_long_message(self.bot.openai_client, interaction, f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{display_text}", is_followup=True)

        # AIå›ç­”ã‚’Notionã«è¨˜éŒ²
        if page_ids:
            await log_response(page_ids[0], all_responses, "6ä½“ãƒ™ãƒ¼ã‚¹AI (/minnaã‚³ãƒãƒ³ãƒ‰)")

    @app_commands.command(name="all", description="9ä½“ã®AIï¼ˆãƒ™ãƒ¼ã‚¹6ä½“+é«˜æ©Ÿèƒ½3ä½“ï¼‰ãŒè­°é¡Œã«åŒæ™‚ã«æ„è¦‹ã‚’å‡ºã—ã¾ã™ã€‚")
    @app_commands.describe(prompt="AIã«å°‹ã­ã‚‹è­°é¡Œ", attachment="è£œè¶³è³‡æ–™ã¨ã—ã¦ç”»åƒã‚’æ·»ä»˜")
    async def all_command(self, interaction: discord.Interaction, prompt: str, attachment: discord.Attachment = None):
        await interaction.response.defer()

        # Notionãƒ­ã‚°è¨˜éŒ²
        page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
        attachment_info = f" (æ·»ä»˜: {attachment.filename})" if attachment else ""
        if page_ids:
            await log_user_message(page_ids[0], interaction.user.display_name, f"/all {prompt}{attachment_info}")

        final_query = prompt
        if attachment:
            await interaction.edit_original_response(content="ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™â€¦")
            final_query += await analyze_attachment_for_gemini(attachment)

        user_id = str(interaction.user.id)
        await interaction.edit_original_response(content="ğŸ”¬ 9ä½“ã®AIãŒåˆæœŸæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")

        tasks = {name: func(user_id, final_query, history=[]) for name, func in self.BASE_MODELS_FOR_ALL.items()}
        adv_models_to_run = {
            "gpt-4o": self.ADVANCED_MODELS_FOR_ALL["gpt-4o"][0],
            "Gemini 2.5 Flash": self.ADVANCED_MODELS_FOR_ALL["Gemini 2.5 Flash"][0],
            "Perplexity": self.ADVANCED_MODELS_FOR_ALL["Perplexity"][0]
        }
        for name, func in adv_models_to_run.items():
            tasks[name] = func(final_query)

        results = await asyncio.gather(*tasks.values(), return_exceptions=True)

        first_name = list(tasks.keys())[0]
        first_result = results[0]
        first_display_text = f"**ğŸ”¹ {first_name}ã®æ„è¦‹:**\n{first_result if not isinstance(first_result, Exception) else f'ã‚¨ãƒ©ãƒ¼: {first_result}'}"
        await interaction.edit_original_response(content=first_display_text[:1900])

        all_responses = first_display_text + "\n\n"
        for name, result in list(zip(tasks.keys(), results))[1:]:
            display_text = f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{result if not isinstance(result, Exception) else f'ã‚¨ãƒ©ãƒ¼: {result}'}"
            all_responses += display_text + "\n\n"
            await send_long_message(self.bot.openai_client, interaction, display_text, is_followup=True)

        # AIå›ç­”ã‚’Notionã«è¨˜éŒ²
        if page_ids:
            await log_response(page_ids[0], all_responses, "9ä½“AI (/allã‚³ãƒãƒ³ãƒ‰)")

    @app_commands.command(name="chain", description="è¤‡æ•°AIãŒãƒªãƒ¬ãƒ¼å½¢å¼ã§æ„è¦‹ã‚’ç¶™ç¶šã—ã¦ã„ãã¾ã™")
    @app_commands.describe(topic="é€£é–ã•ã›ãŸã„è­°é¡Œ")
    async def chain_command(self, interaction: discord.Interaction, topic: str):
        await interaction.response.defer()

        # Notionãƒ­ã‚°è¨˜éŒ²
        page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
        if page_ids:
            await log_user_message(page_ids[0], interaction.user.display_name, f"/chain {topic}")

        ai_order = [
            ("GPT", self.BASE_MODELS_FOR_ALL["GPT"]),
            ("Gemini", self.BASE_MODELS_FOR_ALL["Gemini"]),
            ("Claude", self.BASE_MODELS_FOR_ALL["Claude"]),
            ("Llama", self.BASE_MODELS_FOR_ALL["Llama"]),
            ("Grok", self.BASE_MODELS_FOR_ALL["Grok"])
        ]
        user_id = str(interaction.user.id)
        previous_opinion = f"ã€è­°é¡Œã€‘\n{topic}"
        chain_results = []
        for name, ai_func in ai_order:
            prompt = f"{previous_opinion}\n\nã‚ãªãŸã¯{name}ã§ã™ã€‚å‰ã®AIã®æ„è¦‹ã‚’å‚è€ƒã«ã€ã•ã‚‰ã«æ·±ã‚ã¦ãã ã•ã„ã€‚"
            try:
                opinion = await ai_func(user_id, prompt, history=[])
            except Exception as e:
                opinion = f"{name}ã‚¨ãƒ©ãƒ¼: {e}"
            chain_results.append(f"â—† {name}ã®æ„è¦‹:\n{opinion}")
            previous_opinion = opinion

        all_chain_results = "\n\n".join(chain_results)
        await send_long_message(self.bot.openai_client, interaction, all_chain_results, is_followup=True)

        # AIå›ç­”ã‚’Notionã«è¨˜éŒ²
        if page_ids:
            await log_response(page_ids[0], all_chain_results, "5ä½“AIãƒªãƒ¬ãƒ¼ (/chainã‚³ãƒãƒ³ãƒ‰)")

            # KBç”¨è¦ç´„ä¿å­˜ (2ã¤ç›®ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Œã°)
            if len(page_ids) >= 2:
                try:
                    from ai_manager import get_ai_manager
                    ai_manager = get_ai_manager()
                    if not ai_manager.initialized:
                        ai_manager.initialize(self.bot)

                    summary_prompt = f"ä»¥ä¸‹ã®5ä½“AIãƒªãƒ¬ãƒ¼çµæœã‚’150å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{all_chain_results}"
                    kb_summary = await ai_manager.ask_ai("gpt5mini", summary_prompt)

                    new_section_id = await find_latest_section_id(page_ids[1])
                    await append_summary_to_kb(page_ids[1], new_section_id, kb_summary)
                    safe_log("ğŸ“ /chain KBè¦ç´„ä¿å­˜å®Œäº†: ", new_section_id)
                except Exception as e:
                    safe_log("ğŸš¨ /chain KBè¦ç´„ã‚¨ãƒ©ãƒ¼: ", e)

    @app_commands.command(name="critical", description="Notionæƒ…å ±ã‚’å…ƒã«å…¨AIã§è­°è«–ã—ã€å¤šè§’çš„ãªçµè«–ã‚’å°ãã¾ã™ã€‚")
    @app_commands.describe(topic="è­°è«–ã—ãŸã„è­°é¡Œ")
    async def critical_command(self, interaction: discord.Interaction, topic: str):
        await interaction.response.defer()
        try:
            page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not page_ids:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return
            target_page_id = page_ids[0]

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã‚’Notionã«è¨˜éŒ²
            await log_user_message(target_page_id, interaction.user.display_name, f"/critical {topic}")

            context = await get_notion_context(self.bot, interaction, target_page_id, topic, model_choice="gpt5mini")
            if not context: return

            prompt_with_context = f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{topic}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{context}"
            user_id = str(interaction.user.id)
            tasks = {name: func(user_id, prompt_with_context, history=[]) for name, func in self.BASE_MODELS_FOR_ALL.items()}
            for name, (func, wrapper) in self.ADVANCED_MODELS_FOR_ALL.items():
                if name == "Perplexity": tasks[name] = wrapper(func, topic, notion_context=context)
                else: tasks[name] = wrapper(func, prompt_with_context)

            results = await asyncio.gather(*tasks.values(), return_exceptions=True)

            synthesis_material = "ä»¥ä¸‹ã®AIç¾¤ã®æ„è¦‹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n"
            full_text_results = ""
            for (name, result) in zip(tasks.keys(), results):
                full_response, summary = (result if isinstance(result, tuple) else (result, None))
                display_text = f"ã‚¨ãƒ©ãƒ¼: {result}" if isinstance(result, Exception) else (summary or full_response or result)
                full_text_results += f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{display_text}\n\n"
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{full_response or display_text}\n\n"

            # ä¸¦åˆ—å‡¦ç†: AIè­°è«–è¡¨ç¤ºã¨çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’åŒæ™‚å®Ÿè¡Œ

            # AIè­°è«–çµæœã‚’è¡¨ç¤ºï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
            display_task = asyncio.create_task(
                send_long_message(self.bot.openai_client, interaction, full_text_results, is_followup=False, primary_ai="gpt5")
            )

            # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆä¸¦åˆ—ï¼‰
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            if not ai_manager.initialized:
                ai_manager.initialize(self.bot)

            # ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã¨æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¸¦åˆ—ç”Ÿæˆ
            intermediate_task = asyncio.create_task(
                ai_manager.ask_ai("gpt5", synthesis_material, system_prompt="ä»¥ä¸‹ã®æ„è¦‹ã®è¦ç‚¹ã ã‘ã‚’æŠ½å‡ºã—ã€çŸ­ã„ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            )

            # è¡¨ç¤ºå®Œäº†ã‚’å¾…æ©Ÿ
            await display_task

            # ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆå®Œäº†ã‚’å¾…æ©Ÿã—ã€æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            intermediate_report = await intermediate_task
            final_report = await ask_lalah(self.bot.mistral_client, intermediate_report, system_prompt="ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚æ¸¡ã•ã‚ŒãŸä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’å…ƒã«ã€æœ€çµ‚çš„ãªçµè«–ã‚’500æ–‡å­—ä»¥å†…ã§ãƒ¬ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
            await interaction.followup.send(f"**Mistral Large (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")

            # å…¨AIè­°è«–çµæœã‚’Notionã«è¨˜éŒ²
            all_results = full_text_results + f"æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ:\n{final_report}"
            await log_response(target_page_id, all_results, "AIè­°è«–+çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ (/criticalã‚³ãƒãƒ³ãƒ‰)")

            # KBç”¨è¦ç´„ä¿å­˜ (2ã¤ç›®ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Œã°)
            if len(page_ids) >= 2:
                try:
                    summary_prompt = f"ä»¥ä¸‹ã®AIè­°è«–çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’150å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{final_report}"
                    kb_summary = await ai_manager.ask_ai("gpt5mini", summary_prompt)

                    new_section_id = await find_latest_section_id(page_ids[1])
                    await append_summary_to_kb(page_ids[1], new_section_id, kb_summary)
                    safe_log("ğŸ“ /critical KBè¦ç´„ä¿å­˜å®Œäº†: ", new_section_id)
                except Exception as e:
                    safe_log("ğŸš¨ /critical KBè¦ç´„ã‚¨ãƒ©ãƒ¼: ", e)

        except Exception as e:
            safe_log("ğŸš¨ /critical ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
            await interaction.followup.send(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", ephemeral=True)

    @app_commands.command(name="logical", description="Notionæƒ…å ±ã‚’å…ƒã«AIãŒè¨è«–ã—ã€è«–ç†çš„ãªçµè«–ã‚’å°ãã¾ã™ã€‚")
    @app_commands.describe(topic="è¨è«–ã—ãŸã„è­°é¡Œ")
    async def logical_command(self, interaction: discord.Interaction, topic: str):
        await interaction.response.defer()
        try:
            page_ids = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not page_ids:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return
            target_page_id = page_ids[0]

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã‚’Notionã«è¨˜éŒ²
            await log_user_message(target_page_id, interaction.user.display_name, f"/logical {topic}")

            context = await get_notion_context(self.bot, interaction, target_page_id, topic, model_choice="gpt5mini")
            if not context: return

            prompt_with_context = (f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{topic}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{context}")
            user_id = str(interaction.user.id)

            tasks = {
                "è‚¯å®šè«–è€…(gpt-4o)": self.ADVANCED_MODELS_FOR_ALL["gpt-4o"][1](
                    self.ADVANCED_MODELS_FOR_ALL["gpt-4o"][0], prompt_with_context,
                    system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€è‚¯å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã‚’æ¨é€²ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªè«–æ‹ ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
                "å¦å®šè«–è€…(Perplexity)": self.ADVANCED_MODELS_FOR_ALL["Perplexity"][1](
                    self.ADVANCED_MODELS_FOR_ALL["Perplexity"][0], f"{topic} - å¦å®šçš„ãªè¦–ç‚¹ã§å¤–éƒ¨æƒ…å ±ã‚’çµ±åˆã—ã€åå¯¾è«–ã‚’æç¤º", notion_context=context
                ),
                "ä¸­ç«‹åˆ†æå®˜(Gemini 2.5 Flash)": self.ADVANCED_MODELS_FOR_ALL["Gemini 2.5 Flash"][1](
                    self.ADVANCED_MODELS_FOR_ALL["Gemini 2.5 Flash"][0], prompt_with_context,
                    system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ã€ä¸­ç«‹çš„ãªåˆ†æå®˜ã€‘ã§ã™ã€‚é–¢é€£ã™ã‚‹ç¤¾ä¼šçš„ãƒ»å€«ç†çš„ãªè«–ç‚¹ã‚’ã€æ„Ÿæƒ…ã‚’æ’ã—ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
                "å¤–éƒ¨èª¿æŸ»(Perplexity)": self.ADVANCED_MODELS_FOR_ALL["Perplexity"][1](
                    self.ADVANCED_MODELS_FOR_ALL["Perplexity"][0], topic, notion_context=context
                )
            }
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)

            synthesis_material = "ä»¥ä¸‹ã®æƒ…å ±ã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
            results_text = ""
            for (name, result) in zip(tasks.keys(), results):
                if isinstance(result, Exception):
                    display_text, full_response = (f"ã‚¨ãƒ©ãƒ¼: {result}", f"ã‚¨ãƒ©ãƒ¼: {result}")
                elif name == "å¦å®šè«–è€…(Perplexity)":
                    full_response, summary = result if isinstance(result, tuple) else (result, None)
                    display_text = summary or full_response
                else:
                    full_response, summary = result if isinstance(result, tuple) else (result, None)
                    display_text = summary or full_response
                results_text += f"**{name}:**\n{display_text}\n\n"
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{full_response}\n\n"

            # ä¸¦åˆ—å‡¦ç†: AIè¨è«–è¡¨ç¤ºã¨çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’åŒæ™‚å®Ÿè¡Œ

            # AIè¨è«–çµæœã‚’è¡¨ç¤ºï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
            display_task = asyncio.create_task(
                send_long_message(self.bot.openai_client, interaction, results_text, is_followup=False, primary_ai="gpt5mini")
            )

            # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆä¸¦åˆ—ï¼‰
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            if not ai_manager.initialized:
                ai_manager.initialize(self.bot)

            report_task = asyncio.create_task(
                ai_manager.ask_ai(
                    "gpt5mini", synthesis_material,
                    system_prompt="ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚æ¸¡ã•ã‚ŒãŸæƒ…å ±ã‚’å®¢è¦³çš„ã«çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
                )
            )

            # ä¸¡æ–¹ã®å®Œäº†ã‚’å¾…æ©Ÿ
            await display_task
            final_report = await report_task
            await interaction.followup.send(f"** GPT-5mini (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")

            # AIè¨è«–çµæœã‚’Notionã«è¨˜éŒ²
            all_results = results_text + f"æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ:\n{final_report}"
            await log_response(target_page_id, all_results, "AIè¨è«–+çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ (/logicalã‚³ãƒãƒ³ãƒ‰)")

            # KBç”¨è¦ç´„ä¿å­˜ (2ã¤ç›®ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Œã°)
            if len(page_ids) >= 2:
                try:
                    summary_prompt = f"ä»¥ä¸‹ã®AIè¨è«–çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’150å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{final_report}"
                    kb_summary = await ai_manager.ask_ai("gpt5mini", summary_prompt)

                    new_section_id = await find_latest_section_id(page_ids[1])
                    await append_summary_to_kb(page_ids[1], new_section_id, kb_summary)
                    safe_log("ğŸ“ /logical KBè¦ç´„ä¿å­˜å®Œäº†: ", new_section_id)
                except Exception as e:
                    safe_log("ğŸš¨ /logical KBè¦ç´„ã‚¨ãƒ©ãƒ¼: ", e)

        except Exception as e:
            safe_log("ğŸš¨ /logical ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
            if not interaction.response.is_done():
                await interaction.followup.send(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", ephemeral=True)

    @app_commands.command(name="sync", description="ç®¡ç†è€…å°‚ç”¨ï¼šã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚µãƒ¼ãƒãƒ¼ã«åŒæœŸã—ã¾ã™ã€‚")
    async def sync_command(self, interaction: discord.Interaction):
        if str(interaction.user.id) != self.bot.ADMIN_USER_ID:
            await interaction.response.send_message("ã“ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", ephemeral=True)
            return
        await interaction.response.defer(ephemeral=True)
        if not self.bot.GUILD_ID:
            await interaction.followup.send("âŒ GUILD_IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åŒæœŸã§ãã¾ã›ã‚“ã€‚", ephemeral=True)
            return
        try:
            guild_obj = discord.Object(id=int(self.bot.GUILD_ID))
            synced_commands = await self.bot.tree.sync(guild=guild_obj)
            await interaction.followup.send(f"âœ… ã‚³ãƒãƒ³ãƒ‰ã®åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚åŒæœŸæ•°: {len(synced_commands)}ä»¶", ephemeral=True)
        except Exception as e:
            await interaction.followup.send(f"âŒ åŒæœŸä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n```{e}```", ephemeral=True)


async def setup(bot: commands.Bot):
    await bot.add_cog(CommandCog(bot))