# -*- coding: utf-8 -*-
"""
æ‹¡å¼µã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
Notionã€AIå¿œç­”ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚’çµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§é«˜é€ŸåŒ–
å¿œç­”é€Ÿåº¦30%å‘ä¸Šã‚’ç›®æ¨™ã¨ã—ãŸæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import time
import threading
import hashlib
import asyncio
import json
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from collections import OrderedDict
from utils import safe_log

@dataclass
class EnhancedCacheEntry:
    """æ‹¡å¼µã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒª"""
    data: Any
    timestamp: float = field(default_factory=time.time)
    hit_count: int = 0
    last_accessed: float = field(default_factory=time.time)
    cache_type: str = "generic"  # notion, context, ai_response
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class CachePerformanceStats:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ"""
    hit_count: int = 0
    miss_count: int = 0
    total_entries: int = 0
    memory_usage_mb: float = 0.0
    hit_rate: float = 0.0
    avg_response_time_saved: float = 0.0
    cache_types: Dict[str, int] = field(default_factory=dict)

class EnhancedCacheManager:
    """çµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""

    def __init__(
        self,
        notion_ttl: Optional[int] = None,
        context_ttl: Optional[int] = None,
        ai_response_ttl: Optional[int] = None,
        max_entries: Optional[int] = None,
        use_config: bool = True
    ):
        """
        Args:
            notion_ttl: Notionã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰
            context_ttl: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰
            ai_response_ttl: AIå¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰
            max_entries: æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªæ•°
            use_config: å¤–éƒ¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        # å¤–éƒ¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
        if use_config:
            try:
                from config_manager import get_config_manager
                config_manager = get_config_manager()
                cache_config = config_manager.get_cache_config()

                # å¼•æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
                notion_ttl = notion_ttl if notion_ttl is not None else cache_config.notion_ttl
                context_ttl = context_ttl if context_ttl is not None else cache_config.context_ttl
                ai_response_ttl = ai_response_ttl if ai_response_ttl is not None else cache_config.ai_response_ttl
                max_entries = max_entries if max_entries is not None else cache_config.max_entries

                safe_log("ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®šã‚’å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿", "")
            except ImportError:
                # config_managerãŒä½¿ç”¨ã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                safe_log("âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨", "")
                notion_ttl = notion_ttl if notion_ttl is not None else 300
                context_ttl = context_ttl if context_ttl is not None else 180
                ai_response_ttl = ai_response_ttl if ai_response_ttl is not None else 900
                max_entries = max_entries if max_entries is not None else 500
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            notion_ttl = notion_ttl if notion_ttl is not None else 300
            context_ttl = context_ttl if context_ttl is not None else 180
            ai_response_ttl = ai_response_ttl if ai_response_ttl is not None else 900
            max_entries = max_entries if max_entries is not None else 500

        self.ttl_settings = {
            "notion": notion_ttl,
            "context": context_ttl,
            "ai_response": ai_response_ttl,
            "generic": 300
        }
        self.max_entries = max_entries
        self.cache: OrderedDict[str, EnhancedCacheEntry] = OrderedDict()
        self.lock = threading.RLock()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.stats = CachePerformanceStats()
        self.total_response_time_saved = 0.0

        # è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self.last_cleanup = time.time()
        self.cleanup_interval = 60

    def _generate_cache_key(
        self,
        cache_type: str,
        key_data: Union[str, List[str], Dict[str, Any]]
    ) -> str:
        """æ±ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
        if isinstance(key_data, str):
            base_key = key_data
        elif isinstance(key_data, list):
            base_key = "|".join(sorted(str(item) for item in key_data))
        elif isinstance(key_data, dict):
            base_key = json.dumps(key_data, sort_keys=True)
        else:
            base_key = str(key_data)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¿ã‚¤ãƒ—ã¨ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ã‚’çµ„ã¿åˆã‚ã›
        full_key = f"{cache_type}:{base_key}"
        return hashlib.sha256(full_key.encode()).hexdigest()[:16]  # çŸ­ç¸®

    def _is_expired(self, entry: EnhancedCacheEntry) -> bool:
        """ã‚¨ãƒ³ãƒˆãƒªã®æœŸé™åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯"""
        ttl = self.ttl_settings.get(entry.cache_type, self.ttl_settings["generic"])
        return (time.time() - entry.timestamp) > ttl

    def _cleanup_expired(self) -> int:
        """æœŸé™åˆ‡ã‚Œã‚¨ãƒ³ãƒˆãƒªã®è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        with self.lock:
            current_time = time.time()

            if current_time - self.last_cleanup < self.cleanup_interval:
                return 0

            expired_keys = [
                key for key, entry in self.cache.items()
                if self._is_expired(entry)
            ]

            for key in expired_keys:
                del self.cache[key]

            self.last_cleanup = current_time

            if expired_keys:
                safe_log(f"ğŸ§¹ æ‹¡å¼µã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: ", f"{len(expired_keys)}ä»¶å‰Šé™¤")

            return len(expired_keys)

    def _evict_lru(self) -> None:
        """LRUæ–¹å¼ã§ã®é ˜åŸŸç¢ºä¿"""
        with self.lock:
            while len(self.cache) >= self.max_entries:
                oldest_key, _ = self.cache.popitem(last=False)

    async def get_cached(
        self,
        cache_type: str,
        key_data: Union[str, List[str], Dict[str, Any]],
        fetch_func=None,
        **fetch_kwargs
    ) -> Optional[Any]:
        """æ±ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        cache_key = self._generate_cache_key(cache_type, key_data)
        start_time = time.time()

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
        self._cleanup_expired()

        with self.lock:
            if cache_key in self.cache:
                entry = self.cache[cache_key]

                if not self._is_expired(entry):
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ
                    entry.hit_count += 1
                    entry.last_accessed = time.time()
                    self.stats.hit_count += 1

                    # LRUã®ãŸã‚æœ€å¾Œã«ç§»å‹•
                    self.cache.move_to_end(cache_key)

                    response_time_saved = time.time() - start_time
                    self.total_response_time_saved += response_time_saved

                    safe_log(f"âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ ({cache_type}): ", f"ã‚­ãƒ¼:{cache_key[:8]}... ç¯€ç´„:{response_time_saved:.3f}s")
                    return entry.data
                else:
                    # æœŸé™åˆ‡ã‚Œã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                    del self.cache[cache_key]

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
            self.stats.miss_count += 1

            if fetch_func:
                # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                if asyncio.iscoroutinefunction(fetch_func):
                    data = await fetch_func(**fetch_kwargs)
                else:
                    data = fetch_func(**fetch_kwargs)

                await self.set_cached(cache_type, key_data, data)
                return data

            return None

    async def set_cached(
        self,
        cache_type: str,
        key_data: Union[str, List[str], Dict[str, Any]],
        data: Any,
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        cache_key = self._generate_cache_key(cache_type, key_data)

        with self.lock:
            # é ˜åŸŸç¢ºä¿
            self._evict_lru()

            entry = EnhancedCacheEntry(
                data=data,
                cache_type=cache_type,
                metadata=metadata or {}
            )

            self.cache[cache_key] = entry
            self.stats.total_entries = len(self.cache)

            # çµ±è¨ˆæ›´æ–°
            if cache_type not in self.stats.cache_types:
                self.stats.cache_types[cache_type] = 0
            self.stats.cache_types[cache_type] += 1

    async def get_notion_cached(
        self,
        page_ids: List[str],
        fetch_func,
        **kwargs
    ) -> Any:
        """Notionå°‚ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        return await self.get_cached(
            "notion",
            page_ids,
            fetch_func,
            **kwargs
        )

    async def get_context_cached(
        self,
        page_id: str,
        query: str,
        engine: str,
        fetch_func,
        **kwargs
    ) -> Any:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å°‚ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        key_data = {
            "page_id": page_id,
            "query_hash": hashlib.md5(query.encode()).hexdigest()[:8],
            "engine": engine
        }

        return await self.get_cached(
            "context",
            key_data,
            fetch_func,
            **kwargs
        )

    async def get_ai_response_cached(
        self,
        ai_type: str,
        prompt_hash: str,
        fetch_func,
        **kwargs
    ) -> Any:
        """AIå¿œç­”å°‚ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        key_data = {
            "ai_type": ai_type,
            "prompt_hash": prompt_hash
        }

        return await self.get_cached(
            "ai_response",
            key_data,
            fetch_func,
            **kwargs
        )

    def invalidate_cache(self, cache_type: Optional[str] = None) -> int:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–"""
        with self.lock:
            if cache_type:
                # ç‰¹å®šã‚¿ã‚¤ãƒ—ã®ã¿å‰Šé™¤
                keys_to_delete = [
                    key for key, entry in self.cache.items()
                    if entry.cache_type == cache_type
                ]
                for key in keys_to_delete:
                    del self.cache[key]
                return len(keys_to_delete)
            else:
                # å…¨å‰Šé™¤
                count = len(self.cache)
                self.cache.clear()
                return count

    def get_performance_stats(self) -> CachePerformanceStats:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å–å¾—"""
        with self.lock:
            total_requests = self.stats.hit_count + self.stats.miss_count
            self.stats.hit_rate = (
                self.stats.hit_count / total_requests * 100
                if total_requests > 0 else 0.0
            )
            self.stats.avg_response_time_saved = (
                self.total_response_time_saved / self.stats.hit_count
                if self.stats.hit_count > 0 else 0.0
            )
            self.stats.total_entries = len(self.cache)

            return self.stats

    def get_detailed_stats(self) -> Dict[str, Any]:
        """è©³ç´°çµ±è¨ˆæƒ…å ±"""
        stats = self.get_performance_stats()

        return {
            "cache_performance": {
                "hit_rate": f"{stats.hit_rate:.1f}%",
                "total_hits": stats.hit_count,
                "total_misses": stats.miss_count,
                "avg_time_saved_per_hit": f"{stats.avg_response_time_saved:.3f}s",
                "total_time_saved": f"{self.total_response_time_saved:.3f}s"
            },
            "cache_entries": {
                "total": stats.total_entries,
                "max_capacity": self.max_entries,
                "utilization": f"{(stats.total_entries / self.max_entries * 100):.1f}%",
                "by_type": stats.cache_types
            },
            "configuration": {
                "ttl_settings": self.ttl_settings,
                "cleanup_interval": f"{self.cleanup_interval}s"
            }
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_cache_manager: Optional[EnhancedCacheManager] = None

def get_cache_manager() -> EnhancedCacheManager:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å–å¾—"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = EnhancedCacheManager()
        safe_log("âœ… æ‹¡å¼µã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†", "")
    return _cache_manager