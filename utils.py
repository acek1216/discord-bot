import discord
from discord.ext import commands
import asyncio
import base64
import io
import json
import PyPDF2
import zipfile
import tempfile
import os
from openai import AsyncOpenAI
from mistralai.async_client import MistralAsyncClient

# ai_clients ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ai_clients import ask_lalah, ask_gpt5, ask_gpt5_mini, ask_gpt4o, ask_gemini_2_5_pro, ask_rekus, ask_minerva

# notion_utils ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from notion_utils import get_notion_page_text

# --- ãƒ­ã‚°ãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ ---

def safe_log(prefix: str, obj):
    try:
        s = json.dumps(obj, ensure_ascii=False, indent=2) if isinstance(obj, (dict, list, tuple)) else str(obj)
        print(f"{prefix}{s[:2000]}")
    except Exception as e:
        print(f"{prefix}(log skipped: {e})")

async def send_long_message(openai_client: AsyncOpenAI, target, text: str, is_followup: bool = False, mention: str = "", primary_ai: str = "gpt5"):
    if not text: text = "ï¼ˆå¿œç­”ãŒç©ºã§ã—ãŸï¼‰"
    full_text = f"{mention}\n{text}" if mention and mention not in text else text

    final_content = full_text
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šé•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
    if len(full_text) > 2000:
        safe_log(f"ğŸ” é•·ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°ï¼ˆ{len(full_text)}æ–‡å­—ï¼‰:", full_text[:3000])
        summary_prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã¯Discordã®æ–‡å­—æ•°åˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚å†…å®¹ã®è¦ç‚¹ã‚’æœ€ã‚‚é‡è¦è¦–ã—ã€1800æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n---\n\n{text}"

        # AIã®é¸æŠãƒ­ã‚¸ãƒƒã‚¯ï¼šé€šå¸¸æ™‚ã¯ primary_aiã€2000å­—è¶…éæ™‚ã¯ gpt-4o
        if primary_ai == "gpt5":
            summarizer_name = "gpt5ãŒè¦ç´„ã—ã¾ã—ãŸ"
        else:
            summarizer_name = "gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸ"

        try:
            # çµ±ä¸€AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’çµ±ä¸€
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            if ai_manager.initialized:
                summary = await ai_manager.ask_ai("gpt4o", summary_prompt, system_prompt="ã‚ãªãŸã¯è¦ç´„å°‚ç”¨AIã§ã™ã€‚ç°¡æ½”ã§æ­£ç¢ºãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
                summarizer_name = "gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸ"
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç›´æ¥OpenAI APIã‚’ä½¿ç”¨
                try:
                    response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": summary_prompt}], max_tokens=2000, temperature=0.2)
                except Exception as e:
                    if "max_tokens" in str(e) and "max_completion_tokens" in str(e):
                        response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": summary_prompt}], max_completion_tokens=2000, temperature=0.2)
                    else:
                        raise e
                summary = response.choices[0].message.content
                summarizer_name = "gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸ"

            header = f"{mention}\n" if mention else ""
            final_content = f"{header}{summary}"
        except Exception as e:
            safe_log("ğŸš¨ send_long_messageã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            header = f"{mention}\n" if mention else ""
            final_content = f"{header}å…ƒã®å›ç­”ã¯é•·ã™ãã¾ã—ãŸãŒã€è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    
    try:
        if isinstance(target, discord.Interaction):
            if is_followup: await target.followup.send(final_content)
            else:
                if not target.response.is_done(): await target.edit_original_response(content=final_content)
                else: await target.followup.send(final_content)
        else: await target.send(final_content)
    except (discord.errors.InteractionResponded, discord.errors.NotFound) as e:
        safe_log(f"âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã«å¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰:", e)
        if hasattr(target, 'channel') and target.channel: await target.channel.send(final_content)

# --- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è§£æ ---

async def analyze_attachment_for_gpt5(attachment: discord.Attachment):
    """GPT-5ç”¨ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–¢æ•°"""
    filename = attachment.filename.lower()
    data = await attachment.read()

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ‹¡å¼µï¼‰
    if filename.endswith((".png", ".jpg", ".jpeg", ".gif", ".webp", ".bmp", ".tiff", ".svg")):
        try:
            # GPT-5ã§ç”»åƒè§£æ
            from ai_clients import ask_gpt5
            prompt = "ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦è©³ã—ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚"

            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            import base64
            image_data = base64.b64encode(data).decode()

            # GPT-5ç”¨ã®ç”»åƒãƒ‘ãƒ¼ãƒˆä½œæˆ
            response = await ask_gpt5(prompt, image_data=image_data, image_mime_type=attachment.content_type)
            return f"[GPT-5ç”»åƒè§£æ]\n{response}"
        except Exception as e:
            safe_log("ğŸš¨ GPT-5ç”»åƒè§£æã‚¨ãƒ©ãƒ¼: ", e)
            return f"[ç”»åƒè§£æã‚¨ãƒ©ãƒ¼] {filename}: {str(e)[:100]}"

    # ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«ã¤ã„ã¦ã¯æ—¢å­˜ã®analyze_attachment_for_geminiã¨åŒã˜å‡¦ç†
    return await analyze_attachment_for_gemini(attachment)

async def analyze_attachment_for_gemini(attachment: discord.Attachment):
    filename = attachment.filename.lower()
    data = await attachment.read()

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ‹¡å¼µï¼‰
    if filename.endswith((".png", ".jpg", ".jpeg", ".gif", ".webp", ".bmp", ".tiff", ".svg")):
        try:
            # Gemini 1.5 Proã§ç”»åƒè§£æ
            from ai_clients import ask_minerva
            prompt = "ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦è©³ã—ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚"

            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            import base64
            image_data = base64.b64encode(data).decode()

            # Gemini Flashç”¨ã®ç”»åƒãƒ‘ãƒ¼ãƒˆä½œæˆ
            image_part = {
                "mime_type": attachment.content_type,
                "data": image_data
            }

            response = await ask_minerva(prompt, attachment_parts=[image_part])
            return f"[Gemini 1.5 Proç”»åƒè§£æ]\n{response}"
        except Exception as e:
            safe_log("ğŸš¨ Geminiç”»åƒè§£æã‚¨ãƒ©ãƒ¼: ", e)
            return f"[ç”»åƒè§£æã‚¨ãƒ©ãƒ¼] {filename}: {str(e)[:100]}"

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ‹¡å¼µãƒ»æ–‡å­—æ•°åˆ¶é™ç·©å’Œï¼‰
    elif filename.endswith((".py", ".txt", ".md", ".json", ".html", ".css", ".js", ".ts", ".tsx", ".jsx", ".php", ".rb", ".go", ".rs", ".cpp", ".c", ".h", ".java", ".xml", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".conf")):
        try:
            # è¤‡æ•°ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’è©¦è¡Œ
            for encoding in ['utf-8', 'shift_jis', 'cp932', 'iso-2022-jp', 'euc-jp']:
                try:
                    text_content = data.decode(encoding)
                    break
                except UnicodeDecodeError:
                    continue
            else:
                text_content = data.decode('utf-8', errors='ignore')

            # æ–‡å­—æ•°åˆ¶é™ã‚’10000æ–‡å­—ã«æ‹¡å¼µ
            return f"[æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« {attachment.filename}]\n```\n{text_content[:10000]}\n```"
        except Exception as e:
            return f"[ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}]"

    # PDFï¼ˆOCRå¯¾å¿œæ¤œè¨ï¼‰
    elif filename.endswith(".pdf"):
        try:
            loop = asyncio.get_event_loop()
            reader = await loop.run_in_executor(None, lambda: PyPDF2.PdfReader(io.BytesIO(data)))
            all_text = await loop.run_in_executor(None, lambda: "\n".join([p.extract_text() or "" for p in reader.pages]))
            if not all_text.strip():
                return f"[PDF {attachment.filename}]\nâ€»ç”»åƒãƒ™ãƒ¼ã‚¹ã®PDFã®ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚OCRæ©Ÿèƒ½ã®å®Ÿè£…ãŒå¿…è¦ã§ã™ã€‚"
            return f"[æ·»ä»˜PDF {attachment.filename}]\n{all_text[:10000]}"
        except Exception as e:
            return f"[PDFè§£æã‚¨ãƒ©ãƒ¼: {e}]"

    # åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ–°è¦å¯¾å¿œï¼‰
    elif filename.endswith((".zip", ".rar", ".7z")):
        if filename.endswith(".zip"):
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    zip_path = os.path.join(temp_dir, "temp.zip")
                    with open(zip_path, 'wb') as f:
                        f.write(data)

                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                        file_list = zip_ref.namelist()[:20]  # æœ€åˆã®20ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
                        content_summary = f"[ZIPåœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ« {attachment.filename}]\n"
                        content_summary += f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(zip_ref.namelist())}\n"
                        content_summary += "ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«:\n" + "\n".join(file_list)

                        # å°ã•ãªãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å†…å®¹ã‚‚è¡¨ç¤º
                        for file_name in file_list[:5]:
                            if file_name.lower().endswith(('.txt', '.md', '.json', '.py')) and not file_name.endswith('/'):
                                try:
                                    file_data = zip_ref.read(file_name)
                                    if len(file_data) < 1000:
                                        file_content = file_data.decode('utf-8', errors='ignore')
                                        content_summary += f"\n\n[{file_name}ã®å†…å®¹]\n{file_content}"
                                except:
                                    pass

                        return content_summary
            except Exception as e:
                return f"[ZIPè§£æã‚¨ãƒ©ãƒ¼: {e}]"
        else:
            return f"[åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ« {attachment.filename}]\nâ€»ZIPä»¥å¤–ã®åœ§ç¸®å½¢å¼ã¯ç¾åœ¨æœªå¯¾å¿œã§ã™ã€‚"

    # Officeæ–‡æ›¸ï¼ˆåŸºæœ¬æƒ…å ±ã®ã¿ï¼‰
    elif filename.endswith((".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt")):
        return f"[Officeæ–‡æ›¸ {attachment.filename}]\nâ€»Officeæ–‡æ›¸ã®è§£ææ©Ÿèƒ½ã¯ç¾åœ¨æœªå®Ÿè£…ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ ãŒå¿…è¦ã§ã™ã€‚"

    # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«
    else:
        file_size = len(data)
        return f"[ãƒ•ã‚¡ã‚¤ãƒ« {attachment.filename}]\nã‚µã‚¤ã‚º: {file_size:,} bytes\nâ€»ã“ã®å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç¾åœ¨è§£æå¯¾è±¡å¤–ã§ã™ãŒã€åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚"

# --- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¨Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾— ---

async def summarize_text_chunks(bot: commands.Bot, channel, text: str, query: str, model_choice: str):
    # è¦ç´„å‰ã«åŒ¿ååŒ–å‡¦ç†ï¼ˆGeminiå®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾ç­–ï¼‰
    import re
    if 'å‰å·' in text or 'è‹±ä½‘' in text:
        # äººåã‚’åŒ¿ååŒ–
        text = text.replace('å‰å·æ°', 'å¯¾è±¡è€…').replace('å‰å·è‹±ä½‘æ°', 'å¯¾è±¡è€…').replace('å‰å·è‹±ä½‘', 'å¯¾è±¡è€…').replace('å‰å·', 'å¯¾è±¡è€…')
        text = text.replace('è‹±ä½‘æ°', 'å¯¾è±¡è€…').replace('è‹±ä½‘', 'å¯¾è±¡è€…')
        text = re.sub(r'A[a-zA-Z\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]+æ°?', 'å¯¾è±¡è€…', text)
    
    # å•é¡Œã¨ãªã‚Šã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¸­æ€§çš„ãªè¡¨ç¾ã«ç½®ãæ›ãˆ
    safety_replacements = {
        'çŸ¥èƒ½çŠ¯': 'æˆ¦ç•¥çš„äººç‰©',
        'è¨ˆç”»çš„ã«': 'æˆ¦ç•¥çš„ã«',
        'çŠ¯ç½ª': 'è¡Œç‚º',
        'é•æ³•': 'å•é¡Œè¡Œç‚º',
        'å±é™º': 'ãƒªã‚¹ã‚¯',
        'æ”»æ’ƒ': 'å¯¾æŠ—',
        'çŠ¯äºº': 'å¯¾è±¡è€…',
        'æ‚ªè³ª': 'å•é¡Œ',
        'è©æ¬º': 'ç–‘å•è¡Œç‚º'
    }
    
    for problematic, neutral in safety_replacements.items():
        if problematic in text:
            text = text.replace(problematic, neutral)
    
    chunk_size = 12000
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    summarizer_map = {
        "gpt": lambda p: ask_gpt4o(bot.openai_client, p),
        "gpt5mini": lambda p: ask_gpt5_mini(bot.openai_client, p),
        "gemini": ask_gemini_2_5_pro, # Geminiã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¸è¦
        "gemini_flash": ask_minerva, # Gemini 2.5 Flash
        "perplexity": lambda p: ask_rekus(bot.perplexity_api_key, p)
    }
    summarizer_func = summarizer_map.get(model_choice, ask_gemini_2_5_pro)

    async def summarize_chunk(chunk):
        prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹é€ åŒ–ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
                  f"è¦ç´„ã«ã¯ä»¥ä¸‹ã®ã‚¿ã‚°ã‚’ä»˜ã‘ã¦åˆ†é¡ã—ã¦ãã ã•ã„ï¼š[èƒŒæ™¯æƒ…å ±], [å®šç¾©ãƒ»å‰æ], [äº‹å®ŸçµŒé], [æœªè§£æ±ºèª²é¡Œ], [è£œè¶³æƒ…å ±]\n\n{chunk}")
        try:
            return await summarizer_func(prompt)
        except Exception as e:
            safe_log(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            return None
    tasks = [summarize_chunk(chunk) for chunk in text_chunks]
    chunk_summaries = [s for s in await asyncio.gather(*tasks) if s]
    if not chunk_summaries: return None
    if len(chunk_summaries) == 1: return chunk_summaries[0]
    
    combined = "\n---\n".join(chunk_summaries)
    final_prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¸ã®å›ç­”ã¨ãªã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®è¤‡æ•°ã®è¦ç´„ç¾¤ã‚’ä¸€ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n{combined}")
    return await ask_lalah(bot.mistral_client, final_prompt)

# â–¼â–¼â–¼ã€ä¿®æ­£ã€‘æŠœã‘è½ã¡ã¦ã„ãŸé–¢æ•°ã‚’è¿½åŠ  â–¼â–¼â–¼
async def get_notion_context(bot: commands.Bot, interaction: discord.Interaction, page_id: str, query: str, model_choice: str = "gpt"):
    await interaction.edit_original_response(content="...Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text([page_id])
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await interaction.edit_original_response(content="âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    # 4000æ–‡å­—åˆ¶é™ã‚’é©ç”¨
    notion_text = notion_text[-4000:]
    return await summarize_text_chunks(bot, interaction.channel, notion_text, query, model_choice)

async def get_notion_context_for_message(bot: commands.Bot, message: discord.Message, page_id: str, query: str, model_choice: str):
    from utils import safe_log
    safe_log(f"ğŸ” Notionå–å¾—é–‹å§‹: ", f"ãƒšãƒ¼ã‚¸ID={page_id}, ã‚¯ã‚¨ãƒª={query[:50]}...")
    notion_text = await get_notion_page_text([page_id])
    safe_log(f"ğŸ” Notionå–å¾—çµæœ: ", f"ãƒ†ã‚­ã‚¹ãƒˆé•·={len(notion_text)}, ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯={notion_text.startswith('ERROR:')}")
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await message.channel.send(f"âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°: {notion_text[:100]}")
        return None
    # 4000æ–‡å­—åˆ¶é™ã‚’é©ç”¨
    notion_text = notion_text[-4000:]
    return await summarize_text_chunks(bot, message.channel, notion_text, query, model_choice)
# â–²â–²â–² ã“ã“ã¾ã§è¿½åŠ  â–²â–²â–²

# --- å¿œç­”ã¨è¦ç´„ã®ã‚»ãƒƒãƒˆå–å¾— ---

async def get_full_response_and_summary(openrouter_api_key: str, ai_function, prompt: str, **kwargs):
    full_response = await ai_function(prompt, **kwargs)
    if not full_response or "ã‚¨ãƒ©ãƒ¼" in str(full_response): return full_response, None
    summary_prompt = f"æ¬¡ã®æ–‡ç« ã‚’150æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã‹ã¤æ„å‘³ãŒé€šã˜ã‚‹ã‚ˆã†ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{full_response}"
    summary = await ask_gpt5(openrouter_api_key, summary_prompt)  # ã“ã®é–¢æ•°ã¯ç¾åœ¨æœªä½¿ç”¨ã®ãŸã‚ä¸€æ—¦ä¿ç•™
    if "ã‚¨ãƒ©ãƒ¼" in str(summary): return full_response, None
    return full_response, summary