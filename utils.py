# utils.py

import discord
import asyncio
import base64
import io
import json
import PyPDF2
from openai import AsyncOpenAI

# ai_clients.py ã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ai_clients import (
    ask_gpt_base, ask_gemini_base, ask_mistral_base, ask_claude,
    ask_llama, ask_grok, ask_gpt5, ask_gpt4o, ask_minerva, ask_rekus,
    ask_gemini_pro_for_summary, ask_rekus_for_summary, ask_lalah,
    ask_gemini_2_5_pro
)
# notion_utils.py ã‹ã‚‰ã‚‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from notion_utils import get_notion_page_text

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
openai_client: AsyncOpenAI = None

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šé–¢æ•° ---
def set_openai_client(client: AsyncOpenAI):
    global openai_client
    openai_client = client

# --- ãƒ­ã‚°ãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ ---
def safe_log(prefix: str, obj):
    try:
        s = json.dumps(obj, ensure_ascii=False, indent=2) if isinstance(obj, (dict, list, tuple)) else str(obj)
        print(f"{prefix}{s[:2000]}")
    except Exception as e:
        print(f"{prefix}(log skipped: {e})")

async def send_long_message(target, text: str, is_followup: bool = False, mention: str = ""):
    if not text: text = "ï¼ˆå¿œç­”ãŒç©ºã§ã—ãŸï¼‰"
    full_text = f"{mention}\n{text}" if mention and mention not in text else text

    if len(full_text) > 2000:
        summary_prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã¯Discordã®æ–‡å­—æ•°åˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚å†…å®¹ã®è¦ç‚¹ã‚’æœ€ã‚‚é‡è¦è¦–ã—ã€1800æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n---\n\n{text}"
        try:
            response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": summary_prompt}], max_tokens=1800, temperature=0.2)
            summary = response.choices[0].message.content
            final_content = f"{mention}\nâš ï¸ å…ƒã®å›ç­”ãŒ2000æ–‡å­—ã‚’è¶…ãˆãŸãŸã‚ã€gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸï¼š\n\n{summary}" if mention else f"âš ï¸ å…ƒã®å›ç­”ãŒ2000æ–‡å­—ã‚’è¶…ãˆãŸãŸã‚ã€gpt-4oãŒè¦ç´„ã—ã¾ã—ãŸï¼š\n\n{summary}"
        except Exception as e:
            safe_log("ğŸš¨ è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            final_content = f"{mention}\nå…ƒã®å›ç­”ã¯é•·ã™ãã¾ã—ãŸãŒã€è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚" if mention else "å…ƒã®å›ç­”ã¯é•·ã™ãã¾ã—ãŸãŒã€è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    else:
        final_content = full_text

    if isinstance(target, discord.Interaction):
        try:
            if is_followup: await target.followup.send(final_content)
            else: await target.edit_original_response(content=final_content)
        except (discord.errors.InteractionResponded, discord.errors.NotFound):
            if target.channel: await target.channel.send(final_content)
    else: # channel object
        await target.send(final_content)

# --- ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
async def simple_ai_command_runner(interaction: discord.Interaction, prompt: str, ai_function, bot_name: str, memory_map: dict):
    await interaction.response.defer()
    user_id = str(interaction.user.id)
    clean_bot_name = bot_name.split("-")[0].split(" ")[0]
    memory = memory_map.get(clean_bot_name)
    history = memory.get(user_id, []) if memory is not None else []
    try:
        reply = await ai_function(user_id, prompt, history=history)
        if memory is not None and "ã‚¨ãƒ©ãƒ¼" not in str(reply):
            new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
            memory[user_id] = new_history[-10:]
        await interaction.followup.send(reply)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

async def advanced_ai_simple_runner(interaction: discord.Interaction, prompt: str, ai_function, bot_name: str):
    await interaction.response.defer()
    try:
        reply = await ai_function(prompt)
        await send_long_message(interaction, reply, is_followup=True)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

async def get_full_response_and_summary(ai_function, prompt, **kwargs):
    full_response = await ai_function(prompt, **kwargs)
    if not full_response or "ã‚¨ãƒ©ãƒ¼" in str(full_response): return full_response, None
    summary_prompt = f"æ¬¡ã®æ–‡ç« ã‚’200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{full_response}"
    summary = await ask_gpt5(summary_prompt)
    if "ã‚¨ãƒ©ãƒ¼" in str(summary): return full_response, None
    return full_response, summary

# --- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è§£æ ---
async def analyze_attachment_for_gpt5(attachment: discord.Attachment):
    filename = attachment.filename.lower()
    data = await attachment.read()
    if filename.endswith((".png", ".jpg", ".jpeg", ".gif", ".webp")):
        content = [{"type": "text", "text": "ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
                   {"type": "image_url", "image_url": {"url": f"data:{attachment.content_type};base64,{base64.b64encode(data).decode()}"}}]
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": content}], max_tokens=1500)
        return f"[gpt-4oç”»åƒè§£æ]\n{response.choices[0].message.content}"
    elif filename.endswith((".py", ".txt", ".md", ".json", ".html", ".css", ".js")):
        return f"[æ·»ä»˜ã‚³ãƒ¼ãƒ‰ {attachment.filename}]\n```\n{data.decode('utf-8', errors='ignore')[:3500]}\n```"
    elif filename.endswith(".pdf"):
        try:
            reader = PyPDF2.PdfReader(io.BytesIO(data))
            return f"[æ·»ä»˜PDF {attachment.filename} æŠœç²‹]\n{'\n'.join([p.extract_text() or '' for p in reader.pages])[:3500]}"
        except Exception as e: return f"[PDFè§£æã‚¨ãƒ©ãƒ¼: {e}]"
    else: return f"[æœªå¯¾å¿œã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {attachment.filename}]"

# --- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ ---
async def summarize_text_chunks_for_message(channel, text: str, query: str, summarizer_func):
    chunk_size = 12000
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]
    async def summarize_chunk(chunk):
        prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã€ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹é€ åŒ–ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
                  "è¦ç´„ã«ã¯ä»¥ä¸‹ã®ã‚¿ã‚°ã‚’ä»˜ã‘ã¦åˆ†é¡ã—ã¦ãã ã•ã„ï¼š[èƒŒæ™¯æƒ…å ±], [å®šç¾©ãƒ»å‰æ], [äº‹å®ŸçµŒé], [æœªè§£æ±ºèª²é¡Œ], [è£œè¶³æƒ…å ±]\n\n{chunk}")
        try:
            return await summarizer_func(prompt)
        except Exception as e:
            safe_log(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
            return None
    tasks = [summarize_chunk(chunk) for chunk in text_chunks]
    chunk_summaries = [s for s in await asyncio.gather(*tasks) if s]
    if not chunk_summaries: return None
    if len(chunk_summaries) == 1: return chunk_summaries[0]
    combined = "\n---\n".join(chunk_summaries)
    final_prompt = (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¸ã®å›ç­”ã¨ãªã‚‹ã‚ˆã†ã«ã€ä»¥ä¸‹ã®è¤‡æ•°ã®è¦ç´„ç¾¤ã‚’ä¸€ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n{combined}")
    return await ask_lalah(final_prompt) # æœ€çµ‚çµ±åˆã¯Mistral Large (lalah)

async def get_notion_context_for_message(message: discord.Message, page_id: str, query: str, model_choice: str):
    notion_text = await get_notion_page_text([page_id])
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    summarizer_map = {"gpt": ask_gpt4o, "gemini": ask_gemini_pro_for_summary, "perplexity": ask_rekus_for_summary}
    summarizer = summarizer_map.get(model_choice, ask_gemini_2_5_pro)
    return await summarize_text_chunks_for_message(message.channel, notion_text, query, summarizer)

async def get_notion_context(interaction: discord.Interaction, page_id: str, query: str, model_choice: str = "gpt"):
    await interaction.edit_original_response(content="...Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text([page_id])
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await interaction.edit_original_response(content="âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    summarizer_map = {"gpt": ask_gpt4o, "gemini": ask_gemini_pro_for_summary}
    summarizer = summarizer_map.get(model_choice, ask_gpt4o)
    return await summarize_text_chunks_for_message(interaction.channel, notion_text, query, summarizer)

# --- AIãƒ¢ãƒ‡ãƒ«å®šç¾© (å…±é€š) ---
BASE_MODELS_FOR_ALL = {"GPT": ask_gpt_base, "Gemini": ask_gemini_base, "Mistral": ask_mistral_base, "Claude": ask_claude, "Llama": ask_llama, "Grok": ask_grok}
ADVANCED_MODELS_FOR_ALL = {"gpt-4o": (ask_gpt4o, get_full_response_and_summary), "Gemini 2.5 Pro": (ask_gemini_2_5_pro, get_full_response_and_summary), "Perplexity": (ask_rekus, get_full_response_and_summary)}
