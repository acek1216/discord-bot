# -*- coding: utf-8 -*-
"""
AIè¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ - YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰AIè¨­å®šã‚’èª­ã¿è¾¼ã‚€
"""

import yaml
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from pathlib import Path
import threading

from utils import safe_log

@dataclass
class AIModelConfig:
    """YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€AIè¨­å®š"""
    name: str
    description: str
    client_type: str  # "openai", "gemini", "external_api", "vertex_ai", "mistral"
    model: str
    max_tokens: int = 1000
    temperature: float = 0.7
    timeout: float = 30.0
    retry_count: int = 2
    system_prompt: Optional[str] = None
    supports_memory: bool = False
    supports_attachments: bool = False
    rate_limit_service: str = "default"
    api_function: Optional[str] = None  # å¤–éƒ¨APIç”¨ã®é–¢æ•°å

@dataclass
class SpecialConfigs:
    """ç‰¹æ®Šè¨­å®š"""
    summary_engines: Dict[str, str] = field(default_factory=dict)
    council_ais: List[str] = field(default_factory=list)
    default_context_engine: str = "gpt5mini"

class AIConfigLoader:
    """AIè¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return

        self._ai_configs: Dict[str, AIModelConfig] = {}
        self._special_configs: SpecialConfigs = SpecialConfigs()
        self._config_file_path = Path(__file__).parent / "config" / "ai_models.yaml"
        self._last_modified = 0
        self._initialized = True

        # åˆå›èª­ã¿è¾¼ã¿
        self.load_configs()

    def load_configs(self, force_reload: bool = False) -> None:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not self._config_file_path.exists():
                raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self._config_file_path}")

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯
            current_modified = os.path.getmtime(self._config_file_path)
            if not force_reload and current_modified <= self._last_modified:
                return  # æ›´æ–°ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

            with open(self._config_file_path, 'r', encoding='utf-8') as f:
                config_data = yaml.safe_load(f)

            self._parse_ai_models(config_data.get('ai_models', {}))
            self._parse_special_configs(config_data.get('special_configs', {}))

            self._last_modified = current_modified
            safe_log("âœ… AIè¨­å®šèª­ã¿è¾¼ã¿å®Œäº†: ", f"{len(self._ai_configs)}å€‹ã®AIãƒ¢ãƒ‡ãƒ«è¨­å®š")

        except Exception as e:
            safe_log("ğŸš¨ AIè¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: ", e)
            if not self._ai_configs:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€ä½é™ã®è¨­å®š
                self._create_fallback_configs()
                safe_log("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’é©ç”¨", "")

    def _parse_ai_models(self, ai_models_data: Dict[str, Any]) -> None:
        """AIãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹"""
        self._ai_configs.clear()

        for ai_type, config_dict in ai_models_data.items():
            try:
                # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
                required_fields = ['name', 'description', 'client_type', 'model']
                missing_fields = [field for field in required_fields if field not in config_dict]

                if missing_fields:
                    safe_log(f"âš ï¸ AIè¨­å®šã‚¨ãƒ©ãƒ¼ ({ai_type}): ", f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {missing_fields}")
                    continue

                # AIModelConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                ai_config = AIModelConfig(**config_dict)
                self._ai_configs[ai_type] = ai_config

            except TypeError as e:
                safe_log(f"âš ï¸ AIè¨­å®šãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ ({ai_type}): ", e)
            except Exception as e:
                safe_log(f"ğŸš¨ äºˆæœŸã—ãªã„è¨­å®šã‚¨ãƒ©ãƒ¼ ({ai_type}): ", e)

    def _parse_special_configs(self, special_configs_data: Dict[str, Any]) -> None:
        """ç‰¹æ®Šè¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹"""
        self._special_configs = SpecialConfigs(
            summary_engines=special_configs_data.get('summary_engines', {}),
            council_ais=special_configs_data.get('council_ais', []),
            default_context_engine=special_configs_data.get('default_context_engine', 'gpt5mini')
        )

    def _create_fallback_configs(self) -> None:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æœ€ä½é™è¨­å®š"""
        fallback_configs = {
            "gpt5": AIModelConfig(
                name="GPT-5",
                description="ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š",
                client_type="openai",
                model="gpt-5",
                max_tokens=1000,
                system_prompt="ã‚ãªãŸã¯GPT-5ã§ã™ã€‚"
            ),
            "gemini": AIModelConfig(
                name="Gemini",
                description="ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š",
                client_type="gemini",
                model="gemini-2.5-pro",
                max_tokens=1000,
                system_prompt="ã‚ãªãŸã¯Geminiã§ã™ã€‚"
            )
        }

        self._ai_configs = fallback_configs
        safe_log("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šé©ç”¨: ", f"{len(fallback_configs)}å€‹ã®AIè¨­å®š")

    def get_ai_config(self, ai_type: str) -> Optional[AIModelConfig]:
        """ç‰¹å®šã®AIè¨­å®šã‚’å–å¾—"""
        self.load_configs()  # å¿…è¦ã«å¿œã˜ã¦å†èª­ã¿è¾¼ã¿
        return self._ai_configs.get(ai_type)

    def get_all_ai_configs(self) -> Dict[str, AIModelConfig]:
        """å…¨AIè¨­å®šã‚’å–å¾—"""
        self.load_configs()  # å¿…è¦ã«å¿œã˜ã¦å†èª­ã¿è¾¼ã¿
        return self._ai_configs.copy()

    def get_special_configs(self) -> SpecialConfigs:
        """ç‰¹æ®Šè¨­å®šã‚’å–å¾—"""
        self.load_configs()  # å¿…è¦ã«å¿œã˜ã¦å†èª­ã¿è¾¼ã¿
        return self._special_configs

    def get_available_ai_types(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªAIã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        self.load_configs()
        return list(self._ai_configs.keys())

    def is_ai_type_available(self, ai_type: str) -> bool:
        """æŒ‡å®šã•ã‚ŒãŸAIã‚¿ã‚¤ãƒ—ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return ai_type in self.get_available_ai_types()

    def reload_config(self) -> None:
        """è¨­å®šã‚’å¼·åˆ¶çš„ã«å†èª­ã¿è¾¼ã¿"""
        self.load_configs(force_reload=True)
        safe_log("ğŸ”„ AIè¨­å®šå¼·åˆ¶ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†", "")

    def get_config_summary(self) -> Dict[str, Any]:
        """è¨­å®šã‚µãƒãƒªãƒ¼ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        self.load_configs()

        return {
            "total_ai_models": len(self._ai_configs),
            "ai_types": list(self._ai_configs.keys()),
            "summary_engines": self._special_configs.summary_engines,
            "council_ais": self._special_configs.council_ais,
            "default_context_engine": self._special_configs.default_context_engine,
            "config_file_path": str(self._config_file_path),
            "last_modified": self._last_modified
        }

    def validate_config(self) -> Dict[str, Any]:
        """è¨­å®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        self.load_configs()

        issues = []
        warnings = []

        # AIè¨­å®šã®æ¤œè¨¼
        for ai_type, config in self._ai_configs.items():
            if not config.name or not config.name.strip():
                issues.append(f"AI '{ai_type}' ã®åå‰ãŒç©ºã§ã™")

            if config.max_tokens <= 0:
                issues.append(f"AI '{ai_type}' ã®max_tokensãŒç„¡åŠ¹ã§ã™: {config.max_tokens}")

            if config.temperature < 0 or config.temperature > 2:
                warnings.append(f"AI '{ai_type}' ã®temperatureãŒæ¨å¥¨ç¯„å›²å¤–ã§ã™: {config.temperature}")

            if config.timeout <= 0:
                issues.append(f"AI '{ai_type}' ã®timeoutãŒç„¡åŠ¹ã§ã™: {config.timeout}")

        # ç‰¹æ®Šè¨­å®šã®æ¤œè¨¼
        council_ais = self._special_configs.council_ais
        for council_ai in council_ais:
            if council_ai not in self._ai_configs:
                issues.append(f"Council AI '{council_ai}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        return {
            "valid": len(issues) == 0,
            "issues": issues,
            "warnings": warnings,
            "total_checks": len(self._ai_configs) + len(council_ais)
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—ç”¨ã®é–¢æ•°
def get_ai_config_loader() -> AIConfigLoader:
    """AIè¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return AIConfigLoader()

# ä¾¿åˆ©é–¢æ•°
def get_ai_config(ai_type: str) -> Optional[AIModelConfig]:
    """AIè¨­å®šã‚’å–å¾—ã™ã‚‹ä¾¿åˆ©é–¢æ•°"""
    return get_ai_config_loader().get_ai_config(ai_type)

def get_all_ai_configs() -> Dict[str, AIModelConfig]:
    """å…¨AIè¨­å®šã‚’å–å¾—ã™ã‚‹ä¾¿åˆ©é–¢æ•°"""
    return get_ai_config_loader().get_all_ai_configs()

def get_special_configs() -> SpecialConfigs:
    """ç‰¹æ®Šè¨­å®šã‚’å–å¾—ã™ã‚‹ä¾¿åˆ©é–¢æ•°"""
    return get_ai_config_loader().get_special_configs()

def reload_ai_configs() -> None:
    """AIè¨­å®šã‚’å†èª­ã¿è¾¼ã¿ã™ã‚‹ä¾¿åˆ©é–¢æ•°"""
    get_ai_config_loader().reload_config()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=== AI Config Loader Test ===")

    loader = AIConfigLoader()

    # è¨­å®šã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = loader.get_config_summary()
    print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {summary['config_file_path']}")
    print(f"AIãƒ¢ãƒ‡ãƒ«æ•°: {summary['total_ai_models']}")
    print(f"AIã‚¿ã‚¤ãƒ—: {', '.join(summary['ai_types'])}")

    # æ¤œè¨¼å®Ÿè¡Œ
    validation_result = loader.validate_config()
    print(f"\næ¤œè¨¼çµæœ: {'âœ… OK' if validation_result['valid'] else 'âŒ ã‚¨ãƒ©ãƒ¼ã‚ã‚Š'}")

    if validation_result['issues']:
        print("å•é¡Œ:")
        for issue in validation_result['issues']:
            print(f"  - {issue}")

    if validation_result['warnings']:
        print("è­¦å‘Š:")
        for warning in validation_result['warnings']:
            print(f"  - {warning}")

    # å€‹åˆ¥è¨­å®šãƒ†ã‚¹ãƒˆ
    print(f"\n=== è¨­å®šãƒ†ã‚¹ãƒˆ ===")
    for ai_type in ["gpt5", "gemini", "nonexistent"]:
        config = loader.get_ai_config(ai_type)
        if config:
            print(f"{ai_type}: {config.name} ({config.client_type})")
        else:
            print(f"{ai_type}: è¨­å®šãªã—")