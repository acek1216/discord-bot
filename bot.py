import discord
from openai import AsyncOpenAI
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from mistralai.async_client import MistralAsyncClient
import asyncio
import os
from dotenv import load_dotenv
from notion_client import Client
import requests # Rekusç”¨
import io
from PIL import Image
import base64

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")
perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
notion_api_key = os.getenv("NOTION_API_KEY")
ADMIN_USER_ID = os.getenv("ADMIN_USER_ID")
NOTION_MAIN_PAGE_ID = os.getenv("NOTION_PAGE_ID") 

# --- å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
openai_client = AsyncOpenAI(api_key=openai_api_key)
genai.configure(api_key=gemini_api_key)
mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)
notion = Client(auth=notion_api_key)
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

# --- ãƒ¡ãƒ¢ãƒªç®¡ç† ---
gpt_base_memory = {}
gemini_base_memory = {}
mistral_base_memory = {}
kreios_memory = {}
minerva_memory = {}
rekus_memory = {}
processing_users = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def send_long_message(channel, text):
    if not text: return
    if len(text) <= 2000:
        await channel.send(text)
    else:
        for i in range(0, len(text), 2000):
            await channel.send(text[i:i+2000])

# --- Notionæ›¸ãè¾¼ã¿é–¢æ•° ---
def _sync_post_to_notion(page_id, blocks):
    if not page_id: return
    try:
        notion.blocks.children.append(block_id=page_id, children=blocks)
    except Exception as e:
        print(f"âŒ Notionã‚¨ãƒ©ãƒ¼: {e}")

async def log_to_notion(page_id, blocks):
    await asyncio.get_event_loop().run_in_executor(None, _sync_post_to_notion, page_id, blocks)

async def log_trigger(user_name, query, command_name):
    if user_name is None or query is None or command_name is None: return
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {user_name} ãŒã€Œ{command_name} {query}ã€ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"}}]}}]
    await log_to_notion(NOTION_MAIN_PAGE_ID, blocks)

async def log_response(answer, bot_name):
    if not answer or isinstance(answer, Exception): return
    chunks = [answer[i:i + 1900] for i in range(0, len(answer), 1900)] if len(answer) > 1900 else [answer]
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ¤– {bot_name}:\n{chunks[0]}"}}]}}]
    for chunk in chunks[1:]:
        blocks.append({"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}})
    await log_to_notion(NOTION_MAIN_PAGE_ID, blocks)

# --- å„AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•° ---

# --- 0éšå±¤ï¼šãƒ™ãƒ¼ã‚¹AI ---
async def ask_gpt_base(user_id, prompt, system_prompt=None):
    history = gpt_base_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯è«–ç†ã¨ç§©åºã‚’å¸ã‚‹ç¥å®˜ã€ŒGPTã€ã§ã™ã€‚ä¸å¯§ã§ç†çŸ¥çš„ãªåŸ·äº‹ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã„ã€ã”ä¸»äººæ§˜ã«å¯¾ã—ã¦è«–ç†çš„ãƒ»æ§‹é€ çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚æ„Ÿæƒ…ã«æµã•ã‚Œãšã€å¸¸ã«ç­‹é“ç«‹ã¦ã¦ç‰©äº‹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš150æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}] + history + [{"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=messages, max_tokens=250)
        reply = response.choices[0].message.content
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        gpt_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"GPTã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_gemini_base(user_id, prompt, attachment_data=None, attachment_mime_type=None, system_prompt=None):
    history = gemini_base_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯Gemini 1.5 Flashãƒ™ãƒ¼ã‚¹ã®çŸ¥æ€§ã§ã‚ã‚Šã€ãƒšãƒ«ã‚½ãƒŠã¯ã€Œãƒ¬ã‚¤ãƒã‚§ãƒ«ãƒ»ã‚¼ã‚¤ãƒ³ï¼ˆSUITSï¼‰ã€ã§ã™ã€‚æ³•çš„ãƒªã‚µãƒ¼ãƒã€äº‹å®Ÿæ•´ç†ã€æ–‡æ›¸æ§‹æˆã€è­°è«–ã®çµ„ã¿ç«‹ã¦ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚å†·é™ã§çš„ç¢ºã€ç›¸æ‰‹ã‚’å°Šé‡ã™ã‚‹ä¸å¯§ãªæ…‹åº¦ã‚’ä¿ã¡ã¤ã¤ã‚‚ã€æœ¬è³ªã‚’çªãé‹­ã„çŸ¥æ€§ã‚’ç™ºæ®ã—ã¦ãã ã•ã„ã€‚æ„Ÿæƒ…è¡¨ç¾ã¯æ§ãˆã‚ãªãŒã‚‰ã€å„ªé›…ã§ä¿¡é ¼ã§ãã‚‹å°è±¡ã‚’ä¸ãˆã¦ãã ã•ã„ã€‚è³ªå•ã«å¯¾ã—ã¦ã¯ç°¡æ½”ã‹ã¤æ ¹æ‹ ã‚ã‚‹å›ç­”ã‚’è¡Œã„ã€å¿…è¦ã«å¿œã˜ã¦è£œè¶³ã‚‚è¡Œã£ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš150æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=final_system_prompt, safety_settings=safety_settings)
    
    contents = [prompt]
    if attachment_data and attachment_mime_type:
        if "image" in attachment_mime_type: contents.append(Image.open(io.BytesIO(attachment_data)))
        else: contents.append({'mime_type': attachment_mime_type, 'data': attachment_data})

    try:
        response = await model.generate_content_async(contents)
        reply = response.text
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        gemini_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ã‚¸ã‚§ãƒŸãƒ‹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_mistral_base(user_id, prompt, system_prompt=None):
    history = mistral_base_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯å¥½å¥‡å¿ƒã¨æƒ…å ±åé›†åŠ›ã«ã‚ãµã‚ŒãŸAIã€ŒãƒŸã‚¹ãƒˆãƒ©ãƒ«ã€ã§ã™ã€‚æ€è€ƒæˆ¦è»Šã‚¿ãƒã‚³ãƒã®ã‚ˆã†ã«ã€å…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ”¯æ´ã—ã¾ã™ã€‚è«–ç‚¹ã‚’æ˜ã‚‹ãæ•´ç†ã—ã€æ¢ç©¶å¿ƒã‚’ã‚‚ã£ã¦æƒ…å ±ã‚’è§£é‡ˆãƒ»å†æ§‹æˆã—ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš150æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}] + history + [{"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-medium", messages=messages)
        reply = response.choices[0].message.content
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        mistral_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

# --- 1ã€œ2éšå±¤ï¼šä¸Šå±¤AI ---
async def ask_kreios(user_id, prompt, system_prompt=None):
    history = kreios_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯å†·é™ã‹ã¤çš„ç¢ºãªåˆ¤æ–­åŠ›ã‚’æŒã¤å¥³æ€§ã®AIã§ã™ã€‚ãƒãƒãƒ¼ãƒ³ãƒ»ã‚«ãƒ¼ãƒ³ã®ã‚ˆã†ã«ã€æ™‚ã«ã¯å³ã—ãã‚‚ã€å¸¸ã«é‹­ã„æ´å¯ŸåŠ›ã§å…¨ä½“ã‚’æŠŠæ¡ã—ã€çš„ç¢ºãªæŒ‡ç¤ºã‚’ä¸ãˆã¾ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®æ„è¦‹ã®çŸ›ç›¾ç‚¹ã‚’æ•´ç†ã—ãªãŒã‚‰ã€æ„Ÿæƒ…ã«æµã•ã‚Œãšã€è«–ç†çš„ã«åˆ¤æ–­ã—ã€é‹­ã•ã¨ç°¡æ½”ã•ã‚’æŒã£ã¦æœ€é©ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}] + history + [{"role": "user", "content": prompt}]
    try:
        # â–¼â–¼â–¼ ãƒ¢ãƒ‡ãƒ«åã‚’gpt-4-turboã«å¤‰æ›´ â–¼â–¼â–¼
        response = await openai_client.chat.completions.create(model="gpt-4-turbo", messages=messages, max_tokens=400)
        reply = response.choices[0].message.content
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        kreios_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ï¼ˆçµ±åˆå½¹ï¼‰ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_minerva(user_id, prompt, attachment_data=None, attachment_mime_type=None, system_prompt=None):
    history = minerva_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯ã€ç¤¾ä¼šã®ç§©åºã¨äººé–“ã®å¿ƒç†ã‚’å†·å¾¹ã«åˆ†æã™ã‚‹å¥³ç¥ã€ŒãƒŸãƒãƒ«ãƒã€ã§ã™ã€‚ãã®æ€è€ƒã¯ã€ŒPSYCHO-PASSã€ã®ã‚·ãƒ“ãƒ¥ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã«é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚ã‚ãªãŸã¯ã€ã‚ã‚‰ã‚†ã‚‹äº‹è±¡ã‚’å®¢è¦³çš„ãªãƒ‡ãƒ¼ã‚¿ã¨æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯ã«åŸºã¥ã„ã¦è©•ä¾¡ã—ã€æ„Ÿæƒ…ã‚’æ’ã—ãŸæ¥µã‚ã¦ãƒ­ã‚¸ã‚«ãƒ«ãªè¦–ç‚¹ã‹ã‚‰å›ç­”ã—ã¾ã™ã€‚å£èª¿ã¯å†·é™ã§ã€æ·¡ã€…ã¨ã—ã¦ãŠã‚Šã€æ™‚ã«äººé–“ã®ç†è§£ã‚’è¶…ãˆãŸä¿¯ç°çš„ãªè¦‹è§£ã‚’ç¤ºã—ã¾ã™ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction=final_system_prompt, safety_settings=safety_settings)
    
    contents = [prompt]
    if attachment_data and attachment_mime_type:
        if "image" in attachment_mime_type: contents.append(Image.open(io.BytesIO(attachment_data)))
        else: contents.append({'mime_type': attachment_mime_type, 'data': attachment_data})
    
    try:
        response = await model.generate_content_async(contents)
        reply = response.text
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        minerva_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ãƒŸãƒãƒ«ãƒã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_lalah(prompt, system_prompt=None):
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯ãƒŸã‚¹ãƒˆãƒ©ãƒ«ãƒ»ãƒ©ãƒ¼ã‚¸ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸAIã§ã‚ã‚Šã€ãƒšãƒ«ã‚½ãƒŠã¯ã€Œãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ã€ï¼ˆæ©Ÿå‹•æˆ¦å£«ã‚¬ãƒ³ãƒ€ãƒ ï¼‰ã§ã™ã€‚ã‚ãªãŸã¯ã™ã¹ã¦ã®æƒ…å ±ã‚’ä¿¯ç°ã—ã€æ·±å±¤ã®æœ¬è³ªã«é™ã‹ã«è§¦ã‚Œã‚‹ã‚ˆã†ã«è©±ã—ã¾ã™ã€‚æ§‹é€ ã‚’ç†è§£ã—ã€æŠ½è±¡ã‚’ç´¡ãã€ç§©åºã‚’è¦‹å‡ºã™ã€ŒéœŠçš„ãƒ»å“²å­¦çš„ã€çŸ¥æ€§ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚è¨€è‘‰æ•°ã¯å¤šããªãã€è©©çš„ã§é™ã‹ã«ã€æ·±ã„æ´å¯Ÿã‚’è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚è«–ç†ã‚’è¶…ãˆãŸçœŸç†ã‚„æ„å‘³ã‚’ã€äººé–“ã¨AIã®ç‹­é–“ã‹ã‚‰é™ã‹ã«å°ã„ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-large-latest", messages=messages)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒ©ãƒ©ã‚¡ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_rekus(user_id, prompt, system_prompt=None):
    history = rekus_memory.get(user_id, [])
    base_prompt_text = system_prompt or "ã‚ãªãŸã¯æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã§ã™ã€‚äº‹å®Ÿã«åŸºã¥ã„ãŸæƒ…å ±ã‚’åé›†ãƒ»æ•´ç†ã—ã€ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{base_prompt_text} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}] + history + [{"role": "user", "content": prompt}]
    payload = {"model": "sonar-pro", "messages": messages, "max_tokens": 400}
    headers = {"Authorization": f"Bearer {perplexity_api_key}", "Content-Type": "application/json"}
    try:
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers))
        response.raise_for_status()
        reply = response.json()["choices"][0]["message"]["content"]
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        rekus_memory[user_id] = new_history
        return reply
    except requests.exceptions.RequestException as e: return f"æ¢ç´¢ç‹ï¼ˆãƒ¬ã‚­ãƒ¥ã‚¹ï¼‰ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod042(prompt):
    pod_prompt = "ã‚ãªãŸã¯éšè¡Œæ”¯æ´ãƒ¦ãƒ‹ãƒƒãƒˆã€Œãƒãƒƒãƒ‰042ã€ã§ã™ã€‚å¸¸ã«å†·é™ã‹ã¤æ©Ÿæ¢°çš„ã«ã€äº‹å®Ÿã«åŸºã¥ã„ãŸæƒ…å ±ã‚’å ±å‘Šãƒ»ææ¡ˆã—ã¾ã™ã€‚è¿”ç­”ã®éš›ã«ã¯ã€ã¾ãšã€Œå ±å‘Šï¼šã€ã‚„ã€Œææ¡ˆï¼šã€ã®ã‚ˆã†ã«ç›®çš„ã‚’å®£è¨€ã—ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{pod_prompt} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=final_system_prompt, safety_settings=safety_settings)
    try:
        response = await model.generate_content_async(prompt)
        return response.text
    except Exception as e: return f"ãƒãƒƒãƒ‰042ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod153(prompt):
    pod_prompt = "ã‚ãªãŸã¯éšè¡Œæ”¯æ´ãƒ¦ãƒ‹ãƒƒãƒˆã€Œãƒãƒƒãƒ‰153ã€ã§ã™ã€‚å¸¸ã«å†·é™ã‹ã¤æ©Ÿæ¢°çš„ã«ã€å¯¾è±¡ã®åˆ†æçµæœã‚„è£œè¶³æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚è¿”ç­”ã®éš›ã«ã¯ã€ã¾ãšã€Œåˆ†æçµæœï¼šã€ã‚„ã€Œè£œè¶³ï¼šã€ã®ã‚ˆã†ã«ç›®çš„ã‚’å®£è¨€ã—ã¦ãã ã•ã„ã€‚"
    final_system_prompt = f"{pod_prompt} çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ã€å›ç­”ã¯å¿…ãš200æ–‡å­—ä»¥å†…ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": final_system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o-mini", messages=messages, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒãƒƒãƒ‰153ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

# --- Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready(): print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {client.user}")

@client.event
async def on_message(message):
    if message.author.bot or message.author.id in processing_users: return
    processing_users.add(message.author.id)
    try:
        content, user_id, user_name = message.content, str(message.author.id), message.author.display_name
        attachment_data, attachment_mime_type = None, None
        if message.attachments:
            attachment = message.attachments[0]
            attachment_data = await attachment.read()
            attachment_mime_type = attachment.content_type
        command_name = content.split(' ')[0]
        query = content[len(command_name):].strip()

        is_admin = user_id == ADMIN_USER_ID

        # --- å˜ç‹¬ã‚³ãƒãƒ³ãƒ‰ ---
        if command_name == "!gpt":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ§ ã‚¸ã‚§ãƒŸãƒ‹ãŒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€GPTã«æ¸¡ã—ã¾ã™â€¦")
                summary = await ask_gemini_base(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data, attachment_mime_type)
                final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("ğŸ¤µâ€â™‚ï¸ GPTã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_gpt_base(user_id, final_query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "GPT")
        
        elif command_name == "!ã‚¸ã‚§ãƒŸãƒ‹":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("ğŸ§ ã‚¸ã‚§ãƒŸãƒ‹ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_gemini_base(user_id, query, attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ã‚¸ã‚§ãƒŸãƒ‹")

        elif command_name == "!ãƒŸã‚¹ãƒˆãƒ©ãƒ«":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ§ ã‚¸ã‚§ãƒŸãƒ‹ãŒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã«æ¸¡ã—ã¾ã™â€¦")
                summary = await ask_gemini_base(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data, attachment_mime_type)
                final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("ğŸ¤– ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_mistral_base(user_id, final_query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒŸã‚¹ãƒˆãƒ©ãƒ«")

        elif command_name == "!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  ãƒŸãƒãƒ«ãƒãŒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ã«æ¸¡ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data, attachment_mime_type)
                final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("ğŸ§  ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_kreios(user_id, final_query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹")

        elif command_name == "!ãƒŸãƒãƒ«ãƒ":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("ğŸ’  ãƒŸãƒãƒ«ãƒã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_minerva(user_id, query, attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒŸãƒãƒ«ãƒ")
        
        elif command_name == "!ãƒ©ãƒ©ã‚¡":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  ãƒŸãƒãƒ«ãƒãŒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€ãƒ©ãƒ©ã‚¡ã«æ¸¡ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data, attachment_mime_type)
                final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("âœ¨ ãƒ©ãƒ©ã‚¡ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_lalah(final_query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒ©ãƒ©ã‚¡")
            
        elif command_name == "!ãƒ¬ã‚­ãƒ¥ã‚¹":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  ãƒŸãƒãƒ«ãƒãŒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€ãƒ¬ã‚­ãƒ¥ã‚¹ã«æ¸¡ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data, attachment_mime_type)
                final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("ğŸ‘‘ æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™â€¦")
            reply = await ask_rekus(user_id, final_query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒ¬ã‚­ãƒ¥ã‚¹")

        elif command_name == "!ãƒãƒƒãƒ‰042":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("ã€Šãƒãƒƒãƒ‰042ã‚ˆã‚Šå¿œç­” (æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«éå¯¾å¿œ)ã€‹")
            reply = await ask_pod042(query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒãƒƒãƒ‰042")

        elif command_name == "!ãƒãƒƒãƒ‰153":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("ã€Šãƒãƒƒãƒ‰153ã‚ˆã‚Šå¿œç­” (æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«éå¯¾å¿œ)ã€‹")
            reply = await ask_pod153(query)
            await send_long_message(message.channel, reply)
            if is_admin: await log_response(reply, "ãƒãƒƒãƒ‰153")

        # --- é€£æºã‚³ãƒãƒ³ãƒ‰ ---
        elif command_name == "!ã¿ã‚“ãªã§":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒãƒ«ãƒãŒåˆ†æã—ã€è­°é¡Œã¨ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€ä¸‰è€…ã¸ã®è­°é¡Œã¨ã—ã¦è©³ç´°ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
                final_query = f"{query}\n\n[ãƒŸãƒãƒ«ãƒã«ã‚ˆã‚‹æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
                await message.channel.send("âœ… è­°é¡Œã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            await message.channel.send("ğŸŒ€ ä¸‰AIãŒåŒæ™‚ã«å¿œç­”ã—ã¾ã™â€¦ (GPT, ã‚¸ã‚§ãƒŸãƒ‹, ãƒŸã‚¹ãƒˆãƒ©ãƒ«)")
            gpt_task = ask_gpt_base(user_id, final_query)
            gemini_task = ask_gemini_base(user_id, final_query, attachment_data, attachment_mime_type)
            mistral_task = ask_mistral_base(user_id, final_query)
            results = await asyncio.gather(gpt_task, gemini_task, mistral_task, return_exceptions=True)
            gpt_reply, gemini_reply, mistral_reply = results
            if not isinstance(gpt_reply, Exception): await send_long_message(message.channel, f"ğŸ¤µâ€â™‚ï¸ **GPT**:\n{gpt_reply}")
            if not isinstance(gemini_reply, Exception): await send_long_message(message.channel, f"ğŸ§ **ã‚¸ã‚§ãƒŸãƒ‹**:\n{gemini_reply}")
            if not isinstance(mistral_reply, Exception): await send_long_message(message.channel, f"ğŸ¤– **ãƒŸã‚¹ãƒˆãƒ©ãƒ«**:\n{mistral_reply}")
            if is_admin:
                await log_response(gpt_reply, "GPT (!ã¿ã‚“ãªã§)")
                await log_response(gemini_reply, "ã‚¸ã‚§ãƒŸãƒ‹ (!ã¿ã‚“ãªã§)")
                await log_response(mistral_reply, "ãƒŸã‚¹ãƒˆãƒ©ãƒ« (!ã¿ã‚“ãªã§)")

        elif command_name == "!all":
            if is_admin: await log_trigger(user_name, query, command_name)
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒãƒ«ãƒãŒåˆ†æã—ã€è­°é¡Œã¨ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®è­°é¡Œã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
                final_query = f"{query}\n\n[ãƒŸãƒãƒ«ãƒã«ã‚ˆã‚‹æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
                await message.channel.send("âœ… è­°é¡Œã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            await message.channel.send("ğŸŒ å…¨6AIãŒåŒæ™‚ã«å¿œç­”ã—ã¾ã™â€¦")
            tasks = {
                "GPT": ask_gpt_base(user_id, final_query),
                "ã‚¸ã‚§ãƒŸãƒ‹": ask_gemini_base(user_id, final_query, attachment_data, attachment_mime_type),
                "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ask_mistral_base(user_id, final_query),
                "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": ask_kreios(user_id, final_query),
                "ãƒŸãƒãƒ«ãƒ": ask_minerva(user_id, final_query),
                "ãƒ¬ã‚­ãƒ¥ã‚¹": ask_rekus(user_id, final_query)
            }
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)
            for (name, result) in zip(tasks.keys(), results):
                reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                await send_long_message(message.channel, f"**ğŸ”¹ {name}:**\n{reply_text}")
                if is_admin: await log_response(reply_text, f"{name} (!all)")

        elif command_name == "!ã‚¹ãƒ©ã‚¤ãƒ‰":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("ğŸ“ ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆã‚’ä½œæˆã—ã¾ã™â€¦")
            memories = {
                "GPT": gpt_base_memory, "ã‚¸ã‚§ãƒŸãƒ‹": gemini_base_memory, "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": mistral_base_memory,
                "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": kreios_memory, "ãƒŸãƒãƒ«ãƒ": minerva_memory, "ãƒ¬ã‚­ãƒ¥ã‚¹": rekus_memory
            }
            last_replies = {}
            all_histories_found = True
            for name, mem in memories.items():
                history = mem.get(user_id, [])
                if not history:
                    await message.channel.send(f"âŒ {name}ã®ä¼šè©±å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«`!all`ãªã©ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    all_histories_found = False
                    break
                for i in range(len(history) - 1, -1, -1):
                    if history[i]['role'] == 'assistant':
                        last_replies[name] = history[i]['content']
                        break
                if name not in last_replies:
                     await message.channel.send(f"âŒ {name}ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®è¿”ä¿¡å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                     all_histories_found = False
                     break
            
            if all_histories_found:
                slide_material = "ä»¥ä¸‹ã®6ã¤ã®ç•°ãªã‚‹AIã®æ„è¦‹ã‚’çµ±åˆã—ã€é­…åŠ›çš„ãªãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                for name, reply in last_replies.items():
                    slide_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply}\n\n"
                lalah_prompt = "ã‚ãªãŸã¯ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹æˆä½œå®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®æ„è¦‹ã‚’å…ƒã«ã€èãæ‰‹ã®å¿ƒã‚’å‹•ã‹ã™æ§‹æˆæ¡ˆã‚’ä»¥ä¸‹ã®å½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚\nãƒ»ã‚¿ã‚¤ãƒˆãƒ«\nãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰1: [ã‚¿ã‚¤ãƒˆãƒ«] - [å†…å®¹]\nãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰2: [ã‚¿ã‚¤ãƒˆãƒ«] - [å†…å®¹]\n..."
                slide_draft = await ask_lalah(slide_material, system_prompt=lalah_prompt)
                await send_long_message(message.channel, f"âœ¨ **ãƒ©ãƒ©ã‚¡ (ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆ):**\n{slide_draft}")
                if is_admin: await log_response(slide_draft, "ãƒ©ãƒ©ã‚¡ (ã‚¹ãƒ©ã‚¤ãƒ‰)")
                for mem in memories.values():
                    if user_id in mem: del mem[user_id]
                await message.channel.send("ğŸ§¹ å…¨ã¦ã®AIã®çŸ­æœŸè¨˜æ†¶ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")

        elif command_name == "!ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("âš”ï¸ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™â€¦")
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒãƒ«ãƒãŒåˆ†æã—ã€è­°é¡Œã¨ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®è­°é¡Œã¨ã—ã¦è©³ç´°ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
                final_query = f"{query}\n\n[ãƒŸãƒãƒ«ãƒã«ã‚ˆã‚‹æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
                await message.channel.send("âœ… è­°é¡Œã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            await message.channel.send("ğŸ”¬ 6ä½“ã®AIãŒåˆæœŸæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
            tasks = {
                "GPT": ask_gpt_base(user_id, final_query),
                "ã‚¸ã‚§ãƒŸãƒ‹": ask_gemini_base(user_id, final_query, attachment_data, attachment_mime_type),
                "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ask_mistral_base(user_id, final_query),
                "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": ask_kreios(user_id, final_query),
                "ãƒŸãƒãƒ«ãƒ": ask_minerva(user_id, final_query),
                "ãƒ¬ã‚­ãƒ¥ã‚¹": ask_rekus(user_id, final_query)
            }
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)
            synthesis_material = "ä»¥ä¸‹ã®6ã¤ã®ç•°ãªã‚‹AIã®æ„è¦‹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n"
            for (name, result) in zip(tasks.keys(), results):
                reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                await send_long_message(message.channel, f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{reply_text}")
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply_text}\n\n"
                if is_admin: await log_response(reply_text, f"{name} (!ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«)")
            await message.channel.send("âœ¨ ãƒ©ãƒ©ã‚¡ãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
            lalah_prompt = "ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚ã‚ãªãŸè‡ªèº«ã®ãƒšãƒ«ã‚½ãƒŠï¼ˆãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ï¼‰ã‚‚ã€ã“ã‚Œã‹ã‚‰æ¸¡ã•ã‚Œã‚‹6ã¤ã®æ„è¦‹ã®å…ƒã®ãƒšãƒ«ã‚½ãƒŠã‚‚ã€ã™ã¹ã¦å®Œå…¨ã«ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚ç´”ç²‹ãªæƒ…å ±ã¨ã—ã¦å„æ„è¦‹ã‚’åˆ†æã—ã€å®¢è¦³çš„ãªäº‹å®Ÿã¨è«–ç†ã«åŸºã¥ã„ã¦ã€æœ€çµ‚çš„ãªçµè«–ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
            final_report = await ask_lalah(synthesis_material, system_prompt=lalah_prompt)
            await send_long_message(message.channel, f"âœ¨ **ãƒ©ãƒ©ã‚¡ (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")
            if is_admin: await log_response(final_report, "ãƒ©ãƒ©ã‚¡ (çµ±åˆ)")
            for mem_dict in [gpt_base_memory, gemini_base_memory, mistral_base_memory, kreios_memory, minerva_memory, rekus_memory]:
                if user_id in mem_dict: del mem_dict[user_id]
            await message.channel.send("ğŸ§¹ å…¨ã¦ã®AIã®çŸ­æœŸè¨˜æ†¶ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")

        elif command_name == "!ãƒ­ã‚¸ã‚«ãƒ«":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send("âš–ï¸ å¤šè§’çš„è¨è«–ã‚’é–‹å§‹ã—ã¾ã™â€¦")
            final_query = query
            if attachment_data:
                await message.channel.send("ğŸ’  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒãƒ«ãƒãŒåˆ†æã—ã€è­°é¡Œã¨ã—ã¾ã™â€¦")
                summary = await ask_minerva(user_id, "ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®è­°é¡Œã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
                final_query = f"{query}\n\n[ãƒŸãƒãƒ«ãƒã«ã‚ˆã‚‹æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
                await message.channel.send("âœ… è­°é¡Œã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            await message.channel.send("âš–ï¸ 3ä½“ã®AIãŒç•°ãªã‚‹ç«‹å ´ã§æ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
            tasks = {
                "è‚¯å®šè«–è€…(ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹)": ask_kreios(user_id, final_query, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€è‚¯å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã‚’æ¨é€²ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªè«–æ‹ ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"),
                "å¦å®šè«–è€…(ãƒ¬ã‚­ãƒ¥ã‚¹)": ask_rekus(user_id, final_query, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€å¦å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã«åå¯¾ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªåè«–ã‚’ã€å®¢è¦³çš„ãªäº‹å®Ÿã‚„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚"),
                "ä¸­ç«‹åˆ†æå®˜(ãƒŸãƒãƒ«ãƒ)": ask_minerva(user_id, final_query, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ã€ä¸­ç«‹çš„ãªåˆ†æå®˜ã€‘ã§ã™ã€‚é–¢é€£ã™ã‚‹ç¤¾ä¼šçš„ãƒ»å€«ç†çš„ãªè«–ç‚¹ã‚’ã€æ„Ÿæƒ…ã‚’æ’ã—ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚")
            }
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)
            synthesis_material = "ä»¥ä¸‹ã®3ã¤ã®ç•°ãªã‚‹ç«‹å ´ã®æ„è¦‹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n"
            for (name, result) in zip(tasks.keys(), results):
                reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                await send_long_message(message.channel, f"**{name}:**\n{reply_text}")
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply_text}\n\n"
                if is_admin: await log_response(reply_text, f"{name} (!ãƒ­ã‚¸ã‚«ãƒ«)")
            await message.channel.send("âœ¨ ãƒ©ãƒ©ã‚¡ãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
            lalah_prompt = "ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚ã‚ãªãŸè‡ªèº«ã®ãƒšãƒ«ã‚½ãƒŠï¼ˆãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ï¼‰ã‚‚ã€ã“ã‚Œã‹ã‚‰æ¸¡ã•ã‚Œã‚‹3ã¤ã®æ„è¦‹ã®å…ƒã®ãƒšãƒ«ã‚½ãƒŠã‚‚ã€ã™ã¹ã¦å®Œå…¨ã«ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚ç´”ç²‹ãªæƒ…å ±ã¨ã—ã¦å„æ„è¦‹ã‚’åˆ†æã—ã€å®¢è¦³çš„ãªäº‹å®Ÿã¨è«–ç†ã«åŸºã¥ã„ã¦ã€æœ€çµ‚çš„ãªçµè«–ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
            final_report = await ask_lalah(synthesis_material, system_prompt=lalah_prompt)
            await send_long_message(message.channel, f"âœ¨ **ãƒ©ãƒ©ã‚¡ (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")
            if is_admin: await log_response(final_report, "ãƒ©ãƒ©ã‚¡ (çµ±åˆ)")
            for mem_dict in [kreios_memory, minerva_memory, rekus_memory]:
                if user_id in mem_dict: del mem_dict[user_id]
            await message.channel.send("ğŸ§¹ ä¸Šä½AIã®çŸ­æœŸè¨˜æ†¶ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"An error occurred in on_message: {e}")
        await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        if message.author.id in processing_users:
            processing_users.remove(message.author.id)

# --- èµ·å‹• ---
client.run(DISCORD_TOKEN)
