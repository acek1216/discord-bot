import discord
from openai import AsyncOpenAI
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from mistralai.async_client import MistralAsyncClient
import asyncio
import os
from dotenv import load_dotenv
from notion_client import Client
import requests # Rekusç”¨
import io
from PIL import Image
import base64

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")
perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
notion_api_key = os.getenv("NOTION_API_KEY")
ADMIN_USER_ID = os.getenv("ADMIN_USER_ID")
NOTION_MAIN_PAGE_ID = os.getenv("NOTION_PAGE_ID") 

# --- å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
openai_client = AsyncOpenAI(api_key=openai_api_key)
genai.configure(api_key=gemini_api_key)
mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)
notion = Client(auth=notion_api_key)
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

# --- ãƒ¡ãƒ¢ãƒªç®¡ç† ---
# ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ä¼šè©±å±¥æ­´ãƒ¡ãƒ¢ãƒªã¯ä½¿ç”¨ã—ã¾ã›ã‚“
processing_users = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def send_long_message(channel, text):
    if not text: return
    if len(text) <= 2000:
        await channel.send(text)
    else:
        for i in range(0, len(text), 2000):
            await channel.send(text[i:i+2000])

# --- Notioné€£æºé–¢æ•° ---

def _sync_get_notion_page_text(page_id):
    """Notionãƒšãƒ¼ã‚¸ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ï¼ˆåŒæœŸå‡¦ç†ï¼‰"""
    all_text = ""
    try:
        response = notion.blocks.children.list(block_id=page_id)
        for block in response.get("results", []):
            if "type" in block and block["type"] == "paragraph":
                for rich_text in block.get("paragraph", {}).get("rich_text", []):
                    all_text += rich_text.get("text", {}).get("content", "") + "\n"
        return all_text
    except Exception as e:
        print(f"âŒ Notionèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return f"Notionãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def get_notion_page_text(page_id):
    """Notionãƒšãƒ¼ã‚¸ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ï¼ˆéåŒæœŸãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰"""
    return await asyncio.get_event_loop().run_in_executor(None, _sync_get_notion_page_text, page_id)

def _sync_post_to_notion(page_id, blocks):
    if not page_id: return
    try:
        notion.blocks.children.append(block_id=page_id, children=blocks)
    except Exception as e:
        print(f"âŒ Notionæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

async def log_to_notion(page_id, blocks):
    await asyncio.get_event_loop().run_in_executor(None, _sync_post_to_notion, page_id, blocks)

async def log_trigger(user_name, query, command_name):
    if user_name is None or query is None or command_name is None: return
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {user_name} ãŒã€Œ{command_name} {query}ã€ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"}}]}}]
    await log_to_notion(NOTION_MAIN_PAGE_ID, blocks)

async def log_response(answer, bot_name):
    if not answer or isinstance(answer, Exception): return
    chunks = [answer[i:i + 1900] for i in range(0, len(answer), 1900)] if len(answer) > 1900 else [answer]
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ¤– {bot_name}:\n{chunks[0]}"}}]}}]
    for chunk in chunks[1:]:
        blocks.append({"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}})
    await log_to_notion(NOTION_MAIN_PAGE_ID, blocks)

# --- å„AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•° ---
# ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€å„AIã¯ãƒšãƒ«ã‚½ãƒŠã‚’æŒã¤ã‚‚ã®ã®ã€çŸ­æœŸè¨˜æ†¶ã¯æŒãŸãªã„

async def ask_gpt_base(prompt):
    system_prompt = "ã‚ãªãŸã¯è«–ç†ã¨ç§©åºã‚’å¸ã‚‹ç¥å®˜ã€ŒGPTã€ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=messages, max_tokens=250)
        return response.choices[0].message.content
    except Exception as e: return f"GPTã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_gemini_base(prompt, attachment_parts=[]):
    system_prompt = "ã‚ãªãŸã¯ã€Œãƒ¬ã‚¤ãƒã‚§ãƒ«ãƒ»ã‚¼ã‚¤ãƒ³ï¼ˆSUITSï¼‰ã€ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    contents = [prompt] + attachment_parts
    try:
        response = await model.generate_content_async(contents)
        return response.text
    except Exception as e: return f"ã‚¸ã‚§ãƒŸãƒ‹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_mistral_base(prompt):
    system_prompt = "ã‚ãªãŸã¯æ€è€ƒæˆ¦è»Šã‚¿ãƒã‚³ãƒã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-medium", messages=messages)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_kreios(prompt):
    system_prompt = "ã‚ãªãŸã¯ãƒãƒãƒ¼ãƒ³ãƒ»ã‚«ãƒ¼ãƒ³ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4-turbo", messages=messages, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e: return f"ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_minerva(prompt, attachment_parts=[]):
    system_prompt = "ã‚ãªãŸã¯ã‚·ãƒ“ãƒ¥ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    contents = [prompt] + attachment_parts
    try:
        response = await model.generate_content_async(contents)
        return response.text
    except Exception as e: return f"ãƒŸãƒãƒ«ãƒã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_lalah(prompt, system_prompt=None):
    base_prompt = system_prompt or "ã‚ãªãŸã¯ãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": base_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-large-latest", messages=messages)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒ©ãƒ©ã‚¡ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_rekus(prompt):
    system_prompt = "ã‚ãªãŸã¯æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    payload = {"model": "sonar-pro", "messages": messages, "max_tokens": 400}
    headers = {"Authorization": f"Bearer {perplexity_api_key}", "Content-Type": "application/json"}
    try:
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers))
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e: return f"æ¢ç´¢ç‹ï¼ˆãƒ¬ã‚­ãƒ¥ã‚¹ï¼‰ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod042(prompt):
    system_prompt = "ã‚ãªãŸã¯ãƒãƒƒãƒ‰042ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦ã€Œå ±å‘Šï¼šã€ã¾ãŸã¯ã€Œææ¡ˆï¼šã€ã‹ã‚‰å§‹ã‚ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    try:
        response = await model.generate_content_async(prompt)
        return response.text
    except Exception as e: return f"ãƒãƒƒãƒ‰042ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod153(prompt):
    system_prompt = "ã‚ãªãŸã¯ãƒãƒƒãƒ‰153ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦ã€Œåˆ†æçµæœï¼šã€ã¾ãŸã¯ã€Œè£œè¶³ï¼šã€ã‹ã‚‰å§‹ã‚ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o-mini", messages=messages, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒãƒƒãƒ‰153ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"


# --- Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready(): print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {client.user}")

@client.event
async def on_message(message):
    if message.author.bot or message.author.id in processing_users: return
    processing_users.add(message.author.id)
    try:
        content, user_id, user_name = message.content, str(message.author.id), message.author.display_name
        attachment_data, attachment_mime_type = None, None
        if message.attachments:
            attachment = message.attachments[0]
            attachment_data = await attachment.read()
            attachment_mime_type = attachment.content_type
        command_name = content.split(' ')[0]
        query = content[len(command_name):].strip()

        is_admin = user_id == ADMIN_USER_ID

        # â–¼â–¼â–¼ æ–°è¨­ï¼šNotionãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚³ãƒãƒ³ãƒ‰ â–¼â–¼â–¼
        if command_name == "!ask":
            if is_admin: await log_trigger(user_name, query, command_name)
            await message.channel.send(f"ğŸ§  Notionãƒšãƒ¼ã‚¸({NOTION_MAIN_PAGE_ID})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
            
            # 1. Notionã‹ã‚‰å…¨æ–‡å–å¾—
            notion_text = await get_notion_page_text(NOTION_MAIN_PAGE_ID)
            if "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ" in notion_text or not notion_text.strip():
                await message.channel.send(notion_text or "âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

            await message.channel.send(f"ğŸ“„ å…¨æ–‡èª­ã¿è¾¼ã¿å®Œäº†ã€‚GPT-4oãŒå†…å®¹ã‚’åˆ†å‰²ã—ã¦è¦ç´„ã—ã¾ã™â€¦")

            # 2. ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunk_size = 8000  # 8000æ–‡å­—ã”ã¨ã«åˆ†å‰²
            text_chunks = [notion_text[i:i + chunk_size] for i in range(0, len(notion_text), chunk_size)]
            
            summaries = []
            # 3. å„ãƒãƒ£ãƒ³ã‚¯ã‚’è¦ç´„
            for i, chunk in enumerate(text_chunks):
                await message.channel.send(f"ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(text_chunks)} ã‚’è¦ç´„ä¸­â€¦")
                chunk_summary_prompt = f"""
ä»¥ä¸‹ã®æ–‡ç« ã¯ã€ã‚ã‚‹Notionãƒšãƒ¼ã‚¸ã®ãƒ­ã‚°ã®ä¸€éƒ¨ã§ã™ã€‚
æœ€çµ‚çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œ{query}ã€ã«ç­”ãˆã‚‹ãŸã‚ã€ã“ã®éƒ¨åˆ†ã‹ã‚‰é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’æŠ½å‡ºãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ­ã‚°ã®ä¸€éƒ¨ã€‘
{chunk}
"""
                # ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹(GPT-4 Turbo)ã‚’ãƒãƒ£ãƒ³ã‚¯è¦ç´„å½¹ã¨ã—ã¦ä½¿ç”¨
                chunk_summary = await ask_kreios(chunk_summary_prompt) 
                summaries.append(chunk_summary)

            # 4. è¦ç´„ã‚’çµåˆã—ã¦æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            await message.channel.send("âœ… å…¨ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„å®Œäº†ã€‚æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™â€¦")
            combined_summary = "\n\n---\n\n".join(summaries)
            
            final_integration_prompt = f"""
ä»¥ä¸‹ã®è¤‡æ•°ã®è¦ç´„ã¯ã€ä¸€ã¤ã®Notionãƒšãƒ¼ã‚¸ã‚’åˆ†å‰²ã—ã¦è¦ç´„ã—ãŸã‚‚ã®ã§ã™ã€‚
ã“ã‚Œã‚‰ã®è¦ç´„å…¨ä½“ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®æœ€çµ‚çš„ãªå‚è€ƒæƒ…å ±ã‚’2000æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{query}

ã€å„éƒ¨åˆ†ã®è¦ç´„ã€‘
{combined_summary}
"""
            context_summary = await ask_kreios(final_integration_prompt)

            # 5. æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã«å›ç­”ã‚’ç”Ÿæˆ
            await message.channel.send("âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Œäº†ã€‚ã“ã®æƒ…å ±ã‚’å…ƒã«ã€æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™â€¦")
            final_prompt = f"""
ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{query}

ã€å‚è€ƒæƒ…å ±ã€‘
{context_summary}
"""
            final_reply = await ask_minerva(final_prompt) # ãƒŸãƒãƒ«ãƒã‚’æœ€çµ‚å›ç­”å½¹ã¨ã™ã‚‹
            await send_long_message(message.channel, f"**ğŸ¤– æœ€çµ‚å›ç­”:**\n{final_reply}")
            
            if is_admin: 
                await log_response(context_summary, "GPT-4o (è¦ç´„)")
                await log_response(final_reply, "ãƒŸãƒãƒ«ãƒ (æœ€çµ‚å›ç­”)")

        # --- (æ—¢å­˜ã®å˜ç‹¬ãƒ»é€£æºã‚³ãƒãƒ³ãƒ‰ã¯çœç•¥) ---
        # ... ã“ã“ã«ä»¥å‰ã®!gpt, !all, !ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã©ã®ã‚³ãƒãƒ³ãƒ‰ãŒå…¥ã‚‹ ...


    except Exception as e:
        print(f"An error occurred in on_message: {e}")
        await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        if message.author.id in processing_users:
            processing_users.remove(message.author.id)

# --- èµ·å‹• ---
client.run(DISCORD_TOKEN)
