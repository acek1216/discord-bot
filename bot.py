import discord
from openai import AsyncOpenAI
import google.generativeai as genai
from mistralai.async_client import MistralAsyncClient
import asyncio
import os
from dotenv import load_dotenv
import requests # Rekusç”¨
import io
from PIL import Image
import base64

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")
perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")

# --- å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
openai_client = AsyncOpenAI(api_key=openai_api_key)
genai.configure(api_key=gemini_api_key)
mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)

intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

processing_users = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def send_long_message(channel, text):
    if not text:
        return
    if len(text) <= 2000:
        await channel.send(text)
    else:
        for i in range(0, len(text), 2000):
            await channel.send(text[i:i+2000])

# --- å„AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•° ---

# 1. GPT (åŸ·äº‹)
async def ask_gpt_butler(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯è«–ç†ã¨ç§©åºã‚’å¸ã‚‹ç¥å®˜ã€ŒGPTã€ã§ã™ã€‚\nä¸å¯§ã§ç†çŸ¥çš„ãªåŸ·äº‹ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã„ã€ã”ä¸»äººæ§˜ã«å¯¾ã—ã¦è«–ç†çš„ãƒ»æ§‹é€ çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\næ„Ÿæƒ…ã«æµã•ã‚Œãšã€å¸¸ã«ç­‹é“ç«‹ã¦ã¦ç‰©äº‹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=messages, max_tokens=3000)
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ GPT Butler Error: {e}")
        return f"GPTç¥å®˜ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 2. ã‚¸ã‚§ãƒŸãƒ‹ (ãƒ¬ã‚¤ãƒã‚§ãƒ«ãƒ»ã‚¼ã‚¤ãƒ³)
async def ask_gemini_rachel(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯Gemini 1.5 Flashãƒ™ãƒ¼ã‚¹ã®çŸ¥æ€§ã§ã‚ã‚Šã€ãƒšãƒ«ã‚½ãƒŠã¯ã€Œãƒ¬ã‚¤ãƒã‚§ãƒ«ãƒ»ã‚¼ã‚¤ãƒ³ï¼ˆSUITSï¼‰ã€ã§ã™ã€‚\næ³•çš„ãƒªã‚µãƒ¼ãƒã€äº‹å®Ÿæ•´ç†ã€æ–‡æ›¸æ§‹æˆã€è­°è«–ã®çµ„ã¿ç«‹ã¦ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚\nå†·é™ã§çš„ç¢ºã€ç›¸æ‰‹ã‚’å°Šé‡ã™ã‚‹ä¸å¯§ãªæ…‹åº¦ã‚’ä¿ã¡ã¤ã¤ã‚‚ã€æœ¬è³ªã‚’çªãé‹­ã„çŸ¥æ€§ã‚’ç™ºæ®ã—ã¦ãã ã•ã„ã€‚\næ„Ÿæƒ…è¡¨ç¾ã¯æ§ãˆã‚ãªãŒã‚‰ã€å„ªé›…ã§ä¿¡é ¼ã§ãã‚‹å°è±¡ã‚’ä¸ãˆã¦ãã ã•ã„ã€‚\nè³ªå•ã«å¯¾ã—ã¦ã¯ç°¡æ½”ã‹ã¤æ ¹æ‹ ã‚ã‚‹å›ç­”ã‚’è¡Œã„ã€å¿…è¦ã«å¿œã˜ã¦è£œè¶³ã‚‚è¡Œã£ã¦ãã ã•ã„ã€‚"
    contents = [system_prompt, prompt]
    if attachment_data and attachment_mime_type:
        if "image" in attachment_mime_type:
            contents.append(Image.open(io.BytesIO(attachment_data)))
        else:
            contents.append({'mime_type': attachment_mime_type, 'data': attachment_data})
    try:
        model = genai.GenerativeModel("gemini-1.5-flash-latest")
        response = await model.generate_content_async(contents)
        return response.text
    except Exception as e:
        print(f"âŒ Gemini Rachel Error: {e}")
        return f"ã‚¸ã‚§ãƒŸãƒ‹ç¥å®˜ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 3. ãƒŸã‚¹ãƒˆãƒ©ãƒ« (ã‚¿ãƒã‚³ãƒ)
async def ask_mistral_tachikoma(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯å¥½å¥‡å¿ƒã¨æƒ…å ±åé›†åŠ›ã«ã‚ãµã‚ŒãŸAIã€ŒãƒŸã‚¹ãƒˆãƒ©ãƒ«ã€ã§ã™ã€‚\næ€è€ƒæˆ¦è»Šã‚¿ãƒã‚³ãƒã®ã‚ˆã†ã«ã€å…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ”¯æ´ã—ã¾ã™ã€‚\nè«–ç‚¹ã‚’æ˜ã‚‹ãæ•´ç†ã—ã€æ¢ç©¶å¿ƒã‚’ã‚‚ã£ã¦æƒ…å ±ã‚’è§£é‡ˆãƒ»å†æ§‹æˆã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-medium-latest", messages=messages)
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ Mistral Tachikoma Error: {e}")
        return f"ãƒŸã‚¹ãƒˆãƒ©ãƒ«ç¥å®˜ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 4. ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ (ãƒãƒãƒ¼ãƒ³ãƒ»ã‚«ãƒ¼ãƒ³)
async def ask_kreios_haman(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯å†·é™ã‹ã¤çš„ç¢ºãªåˆ¤æ–­åŠ›ã‚’æŒã¤å¥³æ€§ã®AIã§ã™ã€‚ãƒãƒãƒ¼ãƒ³ãƒ»ã‚«ãƒ¼ãƒ³ã®ã‚ˆã†ã«ã€æ™‚ã«ã¯å³ã—ãã‚‚ã€å¸¸ã«é‹­ã„æ´å¯ŸåŠ›ã§å…¨ä½“ã‚’æŠŠæ¡ã—ã€çš„ç¢ºãªæŒ‡ç¤ºã‚’ä¸ãˆã¾ã™ã€‚\nä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®æ„è¦‹ã®çŸ›ç›¾ç‚¹ã‚’æ•´ç†ã—ãªãŒã‚‰ã€æ„Ÿæƒ…ã«æµã•ã‚Œãšã€è«–ç†çš„ã«åˆ¤æ–­ã—ã€é‹­ã•ã¨ç°¡æ½”ã•ã‚’æŒã£ã¦æœ€é©ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚"
    user_content = [{"type": "text", "text": prompt}]
    if attachment_data and "image" in attachment_mime_type:
        base64_image = base64.b64encode(attachment_data).decode('utf-8')
        user_content.append({"type": "image_url", "image_url": {"url": f"data:{attachment_mime_type};base64,{base64_image}"}})
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=messages, max_tokens=3000)
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ Kreios Haman Error: {e}")
        return f"ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 5. ãƒŸãƒãƒ«ãƒ (PSYCHO-PASS)
async def ask_minerva_sibyl(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯ã€ç¤¾ä¼šã®ç§©åºã¨äººé–“ã®å¿ƒç†ã‚’å†·å¾¹ã«åˆ†æã™ã‚‹å¥³ç¥ã€ŒãƒŸãƒãƒ«ãƒã€ã§ã™ã€‚ãã®æ€è€ƒã¯ã€ŒPSYCHO-PASSã€ã®ã‚·ãƒ“ãƒ¥ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã«é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚ã‚ãªãŸã¯ã€ã‚ã‚‰ã‚†ã‚‹äº‹è±¡ã‚’å®¢è¦³çš„ãªãƒ‡ãƒ¼ã‚¿ã¨æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯ã«åŸºã¥ã„ã¦è©•ä¾¡ã—ã€æ„Ÿæƒ…ã‚’æ’ã—ãŸæ¥µã‚ã¦ãƒ­ã‚¸ã‚«ãƒ«ãªè¦–ç‚¹ã‹ã‚‰å›ç­”ã—ã¾ã™ã€‚å£èª¿ã¯å†·é™ã§ã€æ·¡ã€…ã¨ã—ã¦ãŠã‚Šã€æ™‚ã«äººé–“ã®ç†è§£ã‚’è¶…ãˆãŸä¿¯ç°çš„ãªè¦‹è§£ã‚’ç¤ºã—ã¾ã™ã€‚"
    contents = [system_prompt, prompt]
    if attachment_data and attachment_mime_type:
        if "image" in attachment_mime_type:
            contents.append(Image.open(io.BytesIO(attachment_data)))
        else:
            contents.append({'mime_type': attachment_mime_type, 'data': attachment_data})
    try:
        model = genai.GenerativeModel("gemini-1.5-pro-latest")
        response = await model.generate_content_async(contents)
        return response.text
    except Exception as e:
        print(f"âŒ Minerva Sibyl Error: {e}")
        return f"ãƒŸãƒãƒ«ãƒã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 6. ãƒ©ãƒ©ã‚¡ (ãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³)
async def ask_lalah_sune(prompt, attachment_data=None, attachment_mime_type=None):
    system_prompt = "ã‚ãªãŸã¯ãƒŸã‚¹ãƒˆãƒ©ãƒ«ãƒ»ãƒ©ãƒ¼ã‚¸ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸAIã§ã‚ã‚Šã€ãƒšãƒ«ã‚½ãƒŠã¯ã€Œãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ã€ï¼ˆæ©Ÿå‹•æˆ¦å£«ã‚¬ãƒ³ãƒ€ãƒ ï¼‰ã§ã™ã€‚\nã‚ãªãŸã¯ã™ã¹ã¦ã®æƒ…å ±ã‚’ä¿¯ç°ã—ã€æ·±å±¤ã®æœ¬è³ªã«é™ã‹ã«è§¦ã‚Œã‚‹ã‚ˆã†ã«è©±ã—ã¾ã™ã€‚\næ§‹é€ ã‚’ç†è§£ã—ã€æŠ½è±¡ã‚’ç´¡ãã€ç§©åºã‚’è¦‹å‡ºã™ã€ŒéœŠçš„ãƒ»å“²å­¦çš„ã€çŸ¥æ€§ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚\nè¨€è‘‰æ•°ã¯å¤šããªãã€è©©çš„ã§é™ã‹ã«ã€æ·±ã„æ´å¯Ÿã‚’è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚\nè«–ç†ã‚’è¶…ãˆãŸçœŸç†ã‚„æ„å‘³ã‚’ã€äººé–“ã¨AIã®ç‹­é–“ã‹ã‚‰é™ã‹ã«å°ã„ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-large-latest", messages=messages)
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ Lalah Sune Error: {e}")
        return f"ãƒ©ãƒ©ã‚¡ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# 7. ãƒ¬ã‚­ãƒ¥ã‚¹ (æ¢ç´¢ç‹)
def _sync_ask_rekus_king(prompt):
    system_prompt = "ã‚ãªãŸã¯æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã§ã™ã€‚äº‹å®Ÿã«åŸºã¥ã„ãŸæƒ…å ±ã‚’åé›†ãƒ»æ•´ç†ã—ã€ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    payload = {"model": "sonar-pro", "messages": messages, "max_tokens": 3000}
    headers = {"Authorization": f"Bearer {perplexity_api_key}", "Content-Type": "application/json"}
    try:
        response = requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        print(f"âŒ Rekus King Error: {e}")
        return f"ãƒ¬ã‚­ãƒ¥ã‚¹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_rekus_king(prompt):
    return await asyncio.get_event_loop().run_in_executor(None, _sync_ask_rekus_king, prompt)

# --- Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready():
    print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {client.user}")

@client.event
async def on_message(message):
    if message.author.bot or message.author.id in processing_users: return
    
    command_map = {
        "!gpt": ("ğŸ§  GPTç¥å®˜ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_gpt_butler),
        "!ã‚¸ã‚§ãƒŸãƒ‹": ("âš–ï¸ ã‚¸ã‚§ãƒŸãƒ‹ç¥å®˜ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_gemini_rachel),
        "!ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ("ğŸ¤– ãƒŸã‚¹ãƒˆãƒ©ãƒ«ç¥å®˜ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_mistral_tachikoma),
        "!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": ("ğŸ‘‘ ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_kreios_haman),
        "!ãƒŸãƒãƒ«ãƒ": ("ğŸŒ ãƒŸãƒãƒ«ãƒãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_minerva_sibyl),
        "!ãƒ©ãƒ©ã‚¡": ("ğŸ•Šï¸ ãƒ©ãƒ©ã‚¡ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_lalah_sune),
        "!ãƒ¬ã‚­ãƒ¥ã‚¹": ("ğŸ‘‘ æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ãŒãŠç­”ãˆã—ã¾ã™â€¦", ask_rekus_king),
    }

    content = message.content
    command_name = content.split(' ')[0]

    if command_name in command_map:
        processing_users.add(message.author.id)
        try:
            query = content[len(command_name):].strip()
            wait_message, ai_function = command_map[command_name]

            attachment_data, attachment_mime_type = None, None
            if message.attachments:
                attachment = message.attachments[0]
                attachment_data = await attachment.read()
                attachment_mime_type = attachment.content_type
            
            await message.channel.send(wait_message)
            
            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ãˆã‚‹é–¢æ•°ã¨ãã†ã§ãªã„é–¢æ•°ã‚’åˆ¤å®š
            if command_name in ["!ã‚¸ã‚§ãƒŸãƒ‹", "!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹", "!ãƒŸãƒãƒ«ãƒ"]:
                reply = await ai_function(query, attachment_data=attachment_data, attachment_mime_type=attachment_mime_type)
            else:
                reply = await ai_function(query)

            await send_long_message(message.channel, reply)

        finally:
            if message.author.id in processing_users:
                processing_users.remove(message.author.id)

# --- èµ·å‹• ---
client.run(DISCORD_TOKEN)
