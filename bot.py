# --- æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
import asyncio
import base64
import io
import json
import os
import sys

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from fastapi import FastAPI
import uvicorn
import discord
from discord import app_commands
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import google.generativeai as genai
from mistralai.async_client import MistralAsyncClient
from notion_client import Client
from openai import AsyncOpenAI
import requests
import vertexai
from vertexai.generative_models import GenerativeModel
import PyPDF2

# --- utilsã®importã‚’ã“ã“ã«è¿½åŠ  ---
from utils import safe_log, send_long_message

# --- ã‚µãƒ¼ãƒãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æº–å‚™ ---
app = FastAPI()

# --- UTF-8 å‡ºåŠ›ã‚¬ãƒ¼ãƒ‰ (ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å…ˆé ­éƒ¨åˆ†) ---
os.environ.setdefault("LANG", "C.UTF-8")
os.environ.setdefault("LC_ALL", "C.UTF-8")
os.environ.setdefault("PYTHONIOENCODING", "UTF-8")
try:
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")
except Exception:
    if hasattr(sys.stdout, "buffer"):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    if hasattr(sys.stderr, "buffer"):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° (APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ) ---
openai_client: AsyncOpenAI = None
mistral_client: MistralAsyncClient = None
notion: Client = None
llama_model_for_vertex: GenerativeModel = None

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã¨å¿…é ˆãƒã‚§ãƒƒã‚¯ ---
def get_env_variable(var_name: str, is_secret: bool = True) -> str:
    """ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ã€‚"""
    value = os.getenv(var_name)
    if not value:
        print(f"ğŸš¨ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° '{var_name}' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    if is_secret:
        print(f"ğŸ”‘ ç’°å¢ƒå¤‰æ•° '{var_name}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (Value: ...{value[-4:]})")
    else:
        print(f"âœ… ç’°å¢ƒå¤‰æ•° '{var_name}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (Value: {value})")
    return value

DISCORD_TOKEN = get_env_variable("DISCORD_BOT_TOKEN")
OPENAI_API_KEY = get_env_variable("OPENAI_API_KEY")
GEMINI_API_KEY = get_env_variable("GEMINI_API_KEY")
PERPLEXITY_API_KEY = get_env_variable("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = get_env_variable("MISTRAL_API_KEY")
NOTION_API_KEY = get_env_variable("NOTION_API_KEY")
GROK_API_KEY = get_env_variable("GROK_API_KEY")
ADMIN_USER_ID = get_env_variable("ADMIN_USER_ID", is_secret=False)
NOTION_MAIN_PAGE_ID = get_env_variable("NOTION_PAGE_ID", is_secret=False)
OPENROUTER_API_KEY = get_env_variable("CLOUD_API_KEY").strip()
GUILD_ID = os.getenv("GUILD_ID", "").strip()

# Notionã‚¹ãƒ¬ãƒƒãƒ‰IDã¨ãƒšãƒ¼ã‚¸IDã®å¯¾å¿œè¡¨ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
NOTION_PAGE_MAP_STRING = os.getenv("NOTION_PAGE_MAP_STRING", "")
NOTION_PAGE_MAP = {}
if NOTION_PAGE_MAP_STRING:
    try:
        pairs = NOTION_PAGE_MAP_STRING.split(',')
        for pair in pairs:
            if ':' in pair:
                thread_id, page_id = pair.split(':', 1)
                NOTION_PAGE_MAP[thread_id.strip()] = page_id.strip()
    except Exception as e:
        print(f"âš ï¸ NOTION_PAGE_MAP_STRINGã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- Discord Bot ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æº–å‚™ ---
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)
tree = app_commands.CommandTree(client)

# --- ãƒ¡ãƒ¢ãƒªç®¡ç† ---
gpt_base_memory = {}
gemini_base_memory = {}
mistral_base_memory = {}
claude_base_memory = {}
llama_base_memory = {}
grok_base_memory = {}
gpt_thread_memory = {}
gemini_thread_memory = {}
perplexity_thread_memory = {} 
processing_users = set()
processing_channels = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def ask_gemini_pro_for_summary(prompt: str) -> str:
    """Gemini 1.5 Proã‚’ä½¿ã£ã¦è¦ç´„ã‚’è¡Œã†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    try:
        model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction="ã‚ãªãŸã¯æ§‹é€ åŒ–è¦ç´„AIã§ã™ã€‚", safety_settings=safety_settings)
        response = await model.generate_content_async(prompt)
        return response.text
    except Exception as e:
        return f"Gemini 1.5 Proã§ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_rekus_for_summary(prompt: str) -> str:
    """Perplexity Sonarã‚’ä½¿ã£ã¦è¦ç´„ã‚’è¡Œã†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    system_prompt = "ã‚ãªãŸã¯æ§‹é€ åŒ–è¦ç´„AIã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚°ï¼ˆ[èƒŒæ™¯æƒ…å ±]ãªã©ï¼‰ã‚’ä»˜ã‘ã¦åˆ†é¡ãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
    try:
        summary_text = await ask_rekus(prompt, system_prompt=system_prompt, notion_context=None)
        if "Perplexityã‚¨ãƒ©ãƒ¼" in summary_text:
            return f"Perplexityã§ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {summary_text}"
        return summary_text
    except Exception as e:
        return f"Perplexityã§ã®è¦ç´„ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def analyze_attachment_for_gpt5(attachment: discord.Attachment):
    """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¨®é¡ã«å¿œã˜ã¦gpt-4oã‚„ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§è§£æã™ã‚‹"""
    filename = attachment.filename.lower()
    data = await attachment.read()

    if filename.endswith((".png", ".jpg", ".jpeg", ".gif", ".webp")):
        content = [
            {"type": "text", "text": "ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€å¾Œç¶šã®AIã¸ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"type": "image_url", "image_url": {"url": f"data:{attachment.content_type};base64,{base64.b64encode(data).decode()}"}}
        ]
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": content}], max_tokens=1500)
        return f"[gpt-4oç”»åƒè§£æ]\n{response.choices[0].message.content}"
    elif filename.endswith((".py", ".txt", ".md", ".json", ".html", ".css", ".js")):
        text = data.decode("utf-8", errors="ignore")
        return f"[æ·»ä»˜ã‚³ãƒ¼ãƒ‰ {attachment.filename}]\n```\n{text[:3500]}\n```"
    elif filename.endswith(".pdf"):
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(data))
            all_text = "\n".join([p.extract_text() or "" for p in pdf_reader.pages])
            return f"[æ·»ä»˜PDF {attachment.filename} æŠœç²‹]\n{all_text[:3500]}"
        except Exception as e:
            return f"[PDFè§£æã‚¨ãƒ©ãƒ¼: {e}]"
    else:
        return f"[æœªå¯¾å¿œã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {attachment.filename}]"

async def run_genius_channel_task(message, prompt, target_page_id):
    """ "genius" ãƒãƒ£ãƒ³ãƒãƒ«å°‚ç”¨ã®AIè©•è­°ä¼šã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ """
    thread_id = str(message.channel.id)
    try:
        # 1. Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ï¼ˆå…±é€šãƒãƒ£ãƒ³ã‚¯è¦ç´„ãƒ­ã‚¸ãƒƒã‚¯ã«çµ±ä¸€ï¼‰
        await message.channel.send("ğŸ“œ Notionãƒšãƒ¼ã‚¸ã‚’è¦ç´„ã—ã¦ã„ã¾ã™...")

        notion_raw_text = await get_notion_page_text(target_page_id)
        if notion_raw_text.startswith("ERROR:") or not notion_raw_text.strip():
            await message.channel.send("âš ï¸ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è­°é¡Œã®ã¿ã§é€²è¡Œã—ã¾ã™ã€‚")
            notion_raw_text = "å‚ç…§ãªã—"

        # å…±é€šãƒãƒ£ãƒ³ã‚¯è¦ç´„é–¢æ•°ã‚’å‘¼ã³å‡ºã—ï¼ˆå…¨ãƒ«ãƒ¼ãƒ çµ±ä¸€ï¼‰
        initial_summary = await summarize_text_chunks_for_message(
            channel=message.channel,
            text=notion_raw_text,
            query=prompt,
            model_choice="gpt"   # â† ã“ã“ã¯å¥½ã¿ã§ "gemini" ã‚„ "perplexity" ã«åˆ‡æ›¿å¯èƒ½
        )

        if not initial_summary:
            await message.channel.send("âŒ åˆå›è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        await send_long_message(message.channel, f"** åˆå›è¦ç´„:**\n{initial_summary}")

        if "ã‚¨ãƒ©ãƒ¼" in str(initial_summary):
            await message.channel.send(f"âš ï¸ åˆå›è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {initial_summary}")
            return

        await send_long_message(message.channel, f"** Mistral Largeã«ã‚ˆã‚‹è«–ç‚¹ã‚µãƒãƒªãƒ¼:**\n{initial_summary}")
        
        # 2. AIè©•è­°ä¼šã«ã‚ˆã‚‹ä¸¦åˆ—åˆ†æ
        await message.channel.send(" AIè©•è­°ä¼šï¼ˆGPT-5, Perplexity, Gemini 2.5 Proï¼‰ãŒä¸¦åˆ—ã§åˆ†æã‚’é–‹å§‹...")

        full_prompt_for_council = f"ã€è«–ç‚¹ã‚µãƒãƒªãƒ¼ã€‘\n{initial_summary}\n\nä¸Šè¨˜ã®ã‚µãƒãƒªãƒ¼ã‚’è¸ã¾ãˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®è­°é¡Œã€Œ{prompt}ã€ã«ã¤ã„ã¦ã€ã‚ãªãŸã®å½¹å‰²ã«åŸºã¥ã„ãŸåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"

        # å„AIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–‡å­—æ•°åˆ¶é™ã‚’è¿½åŠ 
        tasks = {
            "GPT-5": ask_gpt5(full_prompt_for_council, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ç¬¬ä¸€ç·šã®ç ”ç©¶è€…ã§ã™ã€‚æœ€ã‚‚å…ˆé€²çš„ã§é‹­ã„è¦–ç‚¹ã‹ã‚‰ã€è¦ç‚¹ã‚’800å­—ç¨‹åº¦ã«çµã£ã¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"),
            "Perplexity": ask_rekus(full_prompt_for_council, system_prompt="ã‚ãªãŸã¯å¤–éƒ¨èª¿æŸ»ã®å°‚é–€å®¶ã§ã™ã€‚é–¢é€£æƒ…å ±ã‚„æœ€æ–°ã®å‹•å‘ã‚’èª¿æŸ»ã—ã€å®¢è¦³çš„ãªäº‹å®Ÿã«åŸºã¥ã„ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’800å­—ç¨‹åº¦ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"),
            "Gemini 2.5 Pro": ask_gemini_2_5_pro(full_prompt_for_council, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ãƒªã‚¹ã‚¯ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚æ½œåœ¨çš„ãªå•é¡Œç‚¹ã‚„å€«ç†çš„èª²é¡Œã‚’ä¸­å¿ƒã«ã€æ‰¹åˆ¤çš„ãªè¦–ç‚¹ã‹ã‚‰ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’800å­—ç¨‹åº¦ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        }
        
        results = await asyncio.gather(*tasks.values(), return_exceptions=True)
        
        # 3. å„ãƒ¬ãƒãƒ¼ãƒˆã‚’æŠ•ç¨¿
        synthesis_material = "ä»¥ä¸‹ã®3ã¤ã®å°‚é–€å®¶ãƒ¬ãƒãƒ¼ãƒˆã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
        council_reports = {}
        for (name, result) in zip(tasks.keys(), results):
            report_text = f"ã‚¨ãƒ©ãƒ¼: {result}" if isinstance(result, Exception) else result
            await send_long_message(message.channel, f"**åˆ†æãƒ¬ãƒãƒ¼ãƒˆ by {name}:**\n{report_text}")
            synthesis_material += f"--- [{name}ã®ãƒ¬ãƒãƒ¼ãƒˆ] ---\n{report_text}\n\n"
            council_reports[name] = report_text
    
        # 4. çµ±åˆAI (Claude 3.5) ã«ã‚ˆã‚‹æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        await message.channel.send(" çµ±åˆAIï¼ˆClaude 3.5 Sonnetï¼‰ãŒå…¨ãƒ¬ãƒãƒ¼ãƒˆã‚’çµ±åˆã—ã€æœ€çµ‚çµè«–ã‚’ç”Ÿæˆã—ã¾ã™...")
        final_report = await ask_claude("genius_user", synthesis_material, history=[])
        
        await send_long_message(message.channel, f"** æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ by Claude 3.5 Sonnet:**\n{final_report}")

        # 5. Notionã¸ã®å…¨ãƒ­ã‚°æ›¸ãè¾¼ã¿
        is_admin = str(message.author.id) == ADMIN_USER_ID
        if is_admin and target_page_id:
            await log_response(target_page_id, initial_summary, "Mistral Large (åˆå›è¦ç´„)")
            if not isinstance(council_reports.get("GPT-5"), Exception):
                await log_response(target_page_id, council_reports.get("GPT-5"), "GPT-5 (è©•è­°ä¼š)")
            if not isinstance(council_reports.get("Perplexity"), Exception):
                await log_response(target_page_id, council_reports.get("Perplexity"), "Perplexity (è©•è­°ä¼š)")
            if not isinstance(council_reports.get("Gemini 2.5 Pro"), Exception):
                await log_response(target_page_id, council_reports.get("Gemini 2.5 Pro"), "Gemini 2.5 Pro (è©•è­°ä¼š)")
            if not isinstance(final_report, Exception):
                await log_response(target_page_id, final_report, "Claude 3.5 Sonnet (æœ€çµ‚çµ±åˆ)")

    except Exception as e:
        safe_log("ğŸš¨ geniusãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚¿ã‚¹ã‚¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
        await message.channel.send(f"åˆ†æã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        # å‡¦ç†ãŒæˆåŠŸã—ã¦ã‚‚å¤±æ•—ã—ã¦ã‚‚ã€å¿…ãšæœ€å¾Œã«ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã™ã‚‹
        if thread_id in processing_channels:
            processing_channels.remove(thread_id)
        print(f"âœ… geniusãƒãƒ£ãƒ³ãƒãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã€ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã—ã¾ã—ãŸ (Channel ID: {thread_id})")

async def summarize_text_chunks_for_message(channel, text: str, query: str, model_choice: str):
    """[on_message/interactionç”¨] ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã€æŒ‡å®šãƒ¢ãƒ‡ãƒ«ã§ä¸¦åˆ—è¦ç´„ã—ã€å¿…è¦ãªã‚‰Mistral Largeã§çµ±åˆã™ã‚‹"""
    chunk_size = 12000
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    model_name_map = {
        "gpt": "gpt-4o",
        "gemini": "Gemini 1.5 Pro",
        "perplexity": "Perplexity Sonar",
        "gemini_2_5_pro": "Gemini 2.5 Pro",
        "gemini-2.5-pro": "Gemini 2.5 Pro",
    }
    model_name = model_name_map.get(model_choice, "ä¸æ˜ãªãƒ¢ãƒ‡ãƒ«")
    await channel.send(f" ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†ã€‚{model_name}ã«ã‚ˆã‚‹ãƒãƒ£ãƒ³ã‚¯æ¯ã®ä¸¦åˆ—è¦ç´„ã‚’é–‹å§‹â€¦ (å…¨{len(text_chunks)}ãƒãƒ£ãƒ³ã‚¯)")

    async def summarize_chunk(chunk, index):
        prompt = (
            "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã€å¿…ãšä»¥ä¸‹ã®ã‚¿ã‚°ã‚’ä»˜ã‘ã¦åˆ†é¡ã—ã¦ãã ã•ã„ï¼š\n"
            "[èƒŒæ™¯æƒ…å ±]\n[å®šç¾©ãƒ»å‰æ]\n[äº‹å®ŸçµŒé]\n[æœªè§£æ±ºèª²é¡Œ]\n[è£œè¶³æƒ…å ±]\n"
            "ã‚¿ã‚°ã¯çœç•¥å¯ã§ã™ãŒã€å­˜åœ¨ã™ã‚‹å ´åˆã¯å¿…ãšä¸Šè¨˜ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚\n"
            f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n"
            f"ã€ãƒ†ã‚­ã‚¹ãƒˆã€‘\n{chunk}"
        )
        try:
            if model_choice == "gpt":
                resp = await openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "system", "content": "ã‚ãªãŸã¯æ§‹é€ åŒ–è¦ç´„AIã§ã™ã€‚"},
                              {"role": "user", "content": prompt}],
                    max_tokens=2048,
                    temperature=0.2
                )
                summary_text = resp.choices[0].message.content
            elif model_choice == "gemini":
                summary_text = await ask_gemini_pro_for_summary(prompt)
            elif model_choice in ("gemini_2_5_pro", "gemini-2.5-pro"):
                summary_text = await ask_gemini_2_5_pro(prompt)  # â† åç§°ã‚’å®Ÿåœ¨é–¢æ•°ã«çµ±ä¸€
            elif model_choice == "perplexity":
                summary_text = await ask_rekus_for_summary(prompt)
            else:
                summary_text = ""

            if not summary_text or "ã‚¨ãƒ©ãƒ¼" in str(summary_text):
                await channel.send(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {index+1} ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ç©ºçµæœã€‚")
                return None
            return summary_text
        except Exception as e:
            await channel.send(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {index+1} ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    tasks = [summarize_chunk(chunk, i) for i, chunk in enumerate(text_chunks)]
    chunk_summaries_results = await asyncio.gather(*tasks)
    chunk_summaries = [s for s in chunk_summaries_results if s is not None]

    if not chunk_summaries:
        await channel.send("âŒ å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return None

    # âœ… 1ãƒãƒ£ãƒ³ã‚¯ãªã‚‰äºŒé‡åœ§ç¸®ã‚’é¿ã‘ã¦å³æ¡ç”¨ï¼ˆå…¨ãƒ«ãƒ¼ãƒ å…±é€šï¼‰
    if len(chunk_summaries) == 1:
        await channel.send(" 1ãƒãƒ£ãƒ³ã‚¯ã ã‘ã ã£ãŸã®ã§ã€Mistralçµ±åˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦è¦ç´„ã‚’æ¡ç”¨ã—ã¾ã™ã€‚")
        return chunk_summaries[0]

    # 2ãƒãƒ£ãƒ³ã‚¯ä»¥ä¸Šã®ã¿ Mistral Large ã§çµ±åˆ
    await channel.send(" å…¨ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„å®Œäº†ã€‚Mistral LargeãŒçµ±åˆãƒ»åˆ†æã—ã¾ã™â€¦")
    combined = "\n---\n".join(chunk_summaries)
    final_prompt = (
        "ä»¥ä¸‹ã®ã€ã‚¿ã‚°ä»˜ã‘ã•ã‚ŒãŸè¤‡æ•°ã®è¦ç´„ç¾¤ã‚’ã€ä¸€ã¤ã®æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆã—ã¦ãã ã•ã„ã€‚\n"
        "å„ã‚¿ã‚°ï¼ˆ[èƒŒæ™¯æƒ…å ±]ã€[äº‹å®ŸçµŒé]ãªã©ï¼‰ã”ã¨ã«å†…å®¹ã‚’ã¾ã¨ã‚ç›´ã—ã€æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nã€ã‚¿ã‚°ä»˜ãè¦ç´„ç¾¤ã€‘\n{combined}"
    )
    try:
        final_summary = await ask_lalah(final_prompt)
        if "ã‚¨ãƒ©ãƒ¼" in str(final_summary):
            await channel.send(f"âš ï¸ Mistral Largeã«ã‚ˆã‚‹æœ€çµ‚çµ±åˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {final_summary}")
            return None
        return final_summary
    except Exception as e:
        await channel.send(f"âŒ Mistral Largeã«ã‚ˆã‚‹æœ€çµ‚çµ±åˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

    
async def get_notion_context_for_message(message: discord.Message, page_id: str, query: str, model_choice: str):
    """on_messageç”¨ã®Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—é–¢æ•°"""
    await message.channel.send("...Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text(page_id)
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    return await summarize_text_chunks_for_message(message.channel, notion_text, query, model_choice)

async def get_notion_context(interaction: discord.Interaction, page_id: str, query: str, model_choice: str = "gpt"):
    """ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ç”¨ã®Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—é–¢æ•°"""
    await interaction.edit_original_response(content="...Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text(page_id)
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await interaction.edit_original_response(content="âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    return await summarize_text_chunks_for_message(interaction.channel, notion_text, query, model_choice)

# bot.py ãƒ•ã‚¡ã‚¤ãƒ«ã® _sync_get_notion_page_text é–¢æ•°ã‚’ä»¥ä¸‹ã«å·®ã—æ›¿ãˆã¦ãã ã•ã„

def _sync_get_notion_page_text(page_id):
    """
    Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã€‚
    è¤‡æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã—ã€ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚‚å‡ºåŠ›ã™ã‚‹æ”¹è‰¯ç‰ˆã€‚
    """
    all_text_blocks = []
    next_cursor = None
    print(f" Notionãƒšãƒ¼ã‚¸(ID: {page_id})ã®èª­ã¿è¾¼ã¿ã‚’é–‹å§‹ã—ã¾ã™...")
    while True:
        try:
            response = notion.blocks.children.list(
                block_id=page_id,
                start_cursor=next_cursor,
                page_size=100
            )
            results = response.get("results", [])
            if not results and not all_text_blocks:
                print("âš ï¸ Notionã‹ã‚‰ãƒ–ãƒ­ãƒƒã‚¯ãŒ1ä»¶ã‚‚è¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã®æ¨©é™ã‚„IDã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

            for block in results:
                block_type = block.get("type")
                text_content = ""
                
                # å¯¾å¿œã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‚’å¤§å¹…ã«å¢—ã‚„ã™
                if block_type in ["paragraph", "heading_1", "heading_2", "heading_3", "bulleted_list_item", "numbered_list_item", "quote", "callout"]:
                    rich_text_list = block.get(block_type, {}).get("rich_text", [])
                    if rich_text_list:
                        text_content = "".join([rich_text.get("plain_text", "") for rich_text in rich_text_list])

                if text_content:
                    all_text_blocks.append(text_content)

            if response.get("has_more"):
                next_cursor = response.get("next_cursor")
            else:
                break
        except Exception as e:
            print(f"âŒ Notion APIã‹ã‚‰ã®èª­ã¿è¾¼ã¿ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return f"ERROR: Notion API Error - {e}"

    print(f" Notionãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿å®Œäº†ã€‚åˆè¨ˆ {len(all_text_blocks)} ãƒ–ãƒ­ãƒƒã‚¯åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
    return "\n".join(all_text_blocks)

async def get_notion_page_text(page_id):
    return await asyncio.get_event_loop().run_in_executor(None, _sync_get_notion_page_text, page_id)

async def log_to_notion(page_id, blocks):
    if not page_id: return
    try:
        await asyncio.get_event_loop().run_in_executor(None, lambda: notion.blocks.children.append(block_id=page_id, children=blocks))
    except Exception as e:
        print(f"âŒ Notionæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

async def log_response(page_id, answer, bot_name):
    if not page_id or not answer or isinstance(answer, Exception): return
    chunks = [answer[i:i + 1900] for i in range(0, len(answer), 1900)] if len(answer) > 1900 else [answer]
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ¤– {bot_name}:\n{chunks[0]}"}}]}}]
    for chunk in chunks[1:]:
        blocks.append({"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}})
    await log_to_notion(page_id, blocks)

async def get_memory_flag_from_notion(thread_id: str) -> bool:
    page_id = NOTION_PAGE_MAP.get(thread_id)
    if not page_id: return False
    try:
        response = await asyncio.get_event_loop().run_in_executor(None, lambda: notion.blocks.children.list(block_id=page_id, page_size=1))
        results = response.get("results", [])
        if not results: return False
        first_block = results[0]
        if first_block.get("type") == "paragraph":
            rich_text_list = first_block.get("paragraph", {}).get("rich_text", [])
            if rich_text_list:
                content = rich_text_list[0].get("text", {}).get("content", "")
                if "[è¨˜æ†¶] ON" in content: return True
    except Exception as e:
        print(f"âŒ Notionã‹ã‚‰è¨˜æ†¶ãƒ•ãƒ©ã‚°ã®èª­ã¿å–ã‚Šä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    return False

from ai_clients import (
    ask_gpt5, ask_gpt4o, ask_gemini_base, ask_minerva, ask_claude, 
    ask_mistral_base, ask_grok, ask_gemini_2_5_pro, ask_rekus, ask_llama,
    ask_gpt_base, ask_lalah, set_llama_model
)

async def get_full_response_and_summary(ai_function, prompt, **kwargs):
    full_response = await ai_function(prompt, **kwargs)
    if not full_response or "ã‚¨ãƒ©ãƒ¼" in str(full_response): return full_response, None
    summary_prompt = f"æ¬¡ã®æ–‡ç« ã‚’200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã‹ã¤æ„å‘³ãŒé€šã˜ã‚‹ã‚ˆã†ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{full_response}"
    summary = await ask_gpt5(summary_prompt)
    if "ã‚¨ãƒ©ãƒ¼" in str(summary): return full_response, None
    return full_response, summary

async def run_long_gpt5_task(message, prompt, full_prompt, is_admin, target_page_id, thread_id):
    user_mention = message.author.mention
    try:
        if is_admin and target_page_id:
            log_blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {message.author.display_name}:\n{prompt}"}}]}}]
            await log_to_notion(target_page_id, log_blocks)
        reply = await ask_gpt5(full_prompt)
        channel = client.get_channel(message.channel.id)
        if not channel: return
        await send_long_message(channel, reply, mention=f"{user_mention}\nãŠå¾…ãŸã›ã—ã¾ã—ãŸã€‚gpt-5ã®å›ç­”ã§ã™ã€‚")
        is_memory_on = await get_memory_flag_from_notion(thread_id)
        if is_memory_on:
            history = gpt_thread_memory.get(thread_id, [])
            history.extend([{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}])
            gpt_thread_memory[thread_id] = history[-10:]
        if is_admin and target_page_id:
            await log_response(target_page_id, reply, "gpt-5 (å°‚ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰)")
    except Exception as e:
        safe_log(f"ğŸš¨ gpt-5ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
        channel = client.get_channel(message.channel.id)
        if channel: await channel.send(f"{user_mention} gpt-5ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

async def simple_ai_command_runner(interaction: discord.Interaction, prompt: str, ai_function, bot_name: str, use_memory: bool = True):
    await interaction.response.defer()
    user_id = str(interaction.user.id)
    
    # ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’åå‰ã‹ã‚‰å‹•çš„ã«é¸æŠ
    memory_map = {
        "GPT": gpt_base_memory,
        "Gemini": gemini_base_memory,
        "Mistral": mistral_base_memory,
        "Claude": claude_base_memory,
        "Llama": llama_base_memory,
        "Grok": grok_base_memory
    }
    # bot_nameã‹ã‚‰ãƒã‚¤ãƒ•ãƒ³ãªã©ã‚’å–ã‚Šé™¤ã„ã¦ä¸€è‡´ã•ã›ã‚‹
    clean_bot_name = bot_name.split("-")[0].split(" ")[0]
    memory = memory_map.get(clean_bot_name)

    history = None
    if use_memory and memory is not None:
        history = memory.get(user_id, [])

    try:
        # historyã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™
        reply = await ai_function(user_id, prompt, history=history)

        if use_memory and memory is not None and "ã‚¨ãƒ©ãƒ¼" not in str(reply):
            new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
            if len(new_history) > 10: new_history = new_history[-10:]
            memory[user_id] = new_history

        await interaction.followup.send(reply)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

async def advanced_ai_simple_runner(interaction: discord.Interaction, prompt: str, ai_function, bot_name: str):
    await interaction.response.defer()
    try:
        reply = await ai_function(prompt)
        await send_long_message(interaction, reply, is_followup=True)
    except Exception as e:
        await interaction.followup.send(f"ğŸ¤– {bot_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

BASE_MODELS_FOR_ALL = {
    "GPT": ask_gpt_base,
    "Gemini": ask_gemini_base,
    "Mistral": ask_mistral_base,
    "Claude": ask_claude,
    "Llama": ask_llama,
    "Grok": ask_grok
}
# â–²â–²â–² ã“ã“ã¾ã§ â–²â–²â–²

@tree.command(name="gpt", description="GPT(gpt-3.5-turbo)ã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def gpt_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_gpt_base, "GPT-3.5-Turbo")

@tree.command(name="gemini", description="Gemini(1.5-flash)ã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def gemini_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_gemini_base, "Gemini-1.5-Flash")

@tree.command(name="mistral", description="Mistral(medium)ã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def mistral_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_mistral_base, "Mistral-Medium")

@tree.command(name="claude", description="Claude(3.5 Sonnet)ã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def claude_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_claude, "Claude-3.5-Sonnet")

@tree.command(name="llama", description="Llama(3.3 70b)ã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def llama_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_llama, "Llama-3.3-70B")

@tree.command(name="grok", description="Grokã¨çŸ­æœŸè¨˜æ†¶ã§å¯¾è©±ã—ã¾ã™")
async def grok_command(interaction: discord.Interaction, prompt: str):
    await simple_ai_command_runner(interaction, prompt, ask_grok, "Grok")

@tree.command(name="gpt-4o", description="GPT-4oã‚’å˜ä½“ã§å‘¼ã³å‡ºã—ã¾ã™ã€‚")
async def gpt4o_command(interaction: discord.Interaction, prompt: str):
    await advanced_ai_simple_runner(interaction, prompt, ask_gpt4o, "GPT-4o")

@tree.command(name="gemini-2-5-flash", description="Gemini 2.5 Flashã‚’å˜ä½“ã§å‘¼ã³å‡ºã—ã¾ã™ã€‚")
async def gemini_2_5_flash_command(interaction: discord.Interaction, prompt: str, attachment: discord.Attachment = None):
    await interaction.response.defer()
    attachment_parts = []
    if attachment:
        attachment_parts = [{'mime_type': attachment.content_type, 'data': await attachment.read()}]
    reply = await ask_minerva(prompt, attachment_parts=attachment_parts)
    await send_long_message(interaction, reply, is_followup=True)

@tree.command(name="perplexity", description="Perplexityã‚’å˜ä½“ã§å‘¼ã³å‡ºã—ã¾ã™ã€‚")
async def perplexity_command(interaction: discord.Interaction, prompt: str):
    await interaction.response.defer()
    try:
        reply = await ask_rekus(prompt)
        await send_long_message(interaction, reply, is_followup=True)
    except Exception as e:
        await interaction.followup.send(f" Perplexity Sonar ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@tree.command(name="gpt5", description="GPT-5ã‚’å˜ä½“ã§å‘¼ã³å‡ºã—ã¾ã™ã€‚")
async def gpt5_command(interaction: discord.Interaction, prompt: str):
    await advanced_ai_simple_runner(interaction, prompt, ask_gpt5, "gpt-5")

@tree.command(name="gemini-2-5-pro", description="Gemini 2.5 Proã‚’å˜ä½“ã§å‘¼ã³å‡ºã—ã¾ã™ã€‚")
async def gemini_pro_1_5_command(interaction: discord.Interaction, prompt: str):
    await advanced_ai_simple_runner(interaction, prompt, ask_gemini_2_5_pro, "Gemini 2.5 Pro")

@tree.command(name="notion", description="ç¾åœ¨ã®Notionãƒšãƒ¼ã‚¸ã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã—ã¾ã™")
@app_commands.describe(query="Notionãƒšãƒ¼ã‚¸ã«é–¢ã™ã‚‹è³ªå•")
async def notion_command(interaction: discord.Interaction, query: str):
    await interaction.response.defer()
    try:
        async def core_logic():
            target_page_id = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not target_page_id:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return
            
            notion_context = await get_notion_context(interaction, target_page_id, query, model_choice="gpt")
            if not notion_context:
                await interaction.edit_original_response(content="âŒ Notionã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            prompt_with_context = (f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{notion_context}")
            await interaction.edit_original_response(content="â³ gpt-5ãŒæœ€çµ‚å›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™...")
            reply = await ask_gpt5(prompt_with_context)
            await send_long_message(interaction, f"** æœ€çµ‚å›ç­” (by gpt-5):**\n{reply}", is_followup=False)
            if str(interaction.user.id) == ADMIN_USER_ID:
                await log_response(target_page_id, reply, "gpt-5 (Notionå‚ç…§)")
        await asyncio.wait_for(core_logic(), timeout=240)
    except Exception as e:
        safe_log("ğŸš¨ /notion ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
        await interaction.edit_original_response(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@tree.command(name="minna", description="6ä½“ã®ãƒ™ãƒ¼ã‚¹AIãŒè­°é¡Œã«åŒæ™‚ã«æ„è¦‹ã‚’å‡ºã—ã¾ã™ã€‚")
@app_commands.describe(prompt="AIã«å°‹ã­ã‚‹è­°é¡Œ")
async def minna_command(interaction: discord.Interaction, prompt: str):
    await interaction.response.defer()
    user_id = str(interaction.user.id)
    await interaction.followup.send("ğŸ”¬ 6ä½“ã®ãƒ™ãƒ¼ã‚¹AIãŒæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
    tasks = {name: func(user_id, prompt) for name, func in BASE_MODELS_FOR_ALL.items()}
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
    for (name, result) in zip(tasks.keys(), results):
        display_text = f"ã‚¨ãƒ©ãƒ¼: {result}" if isinstance(result, Exception) else result
        await interaction.followup.send(f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{display_text}")

ADVANCED_MODELS_FOR_ALL = {"gpt-4o": (ask_gpt4o, get_full_response_and_summary), "Gemini 2.5 Flash": (ask_minerva, get_full_response_and_summary), "Perplexity": (ask_rekus, get_full_response_and_summary), "Gemini 2.5 Pro": (ask_gemini_2_5_pro, get_full_response_and_summary), "gpt-5": (ask_gpt5, get_full_response_and_summary)}


@tree.command(name="all", description="9ä½“ã®AIï¼ˆãƒ™ãƒ¼ã‚¹6ä½“+é«˜æ©Ÿèƒ½3ä½“ï¼‰ãŒè­°é¡Œã«åŒæ™‚ã«æ„è¦‹ã‚’å‡ºã—ã¾ã™ã€‚")
@app_commands.describe(prompt="AIã«å°‹ã­ã‚‹è­°é¡Œ", attachment="è£œè¶³è³‡æ–™ã¨ã—ã¦ç”»åƒã‚’æ·»ä»˜")
async def all_command(interaction: discord.Interaction, prompt: str, attachment: discord.Attachment = None):
    await interaction.response.defer()
    final_query = prompt
    if attachment: 
        await interaction.edit_original_response(content="ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™â€¦")
        final_query += await analyze_attachment_for_gpt5(attachment)
    
    user_id = str(interaction.user.id)
    await interaction.edit_original_response(content="ğŸ”¬ 9ä½“ã®AIãŒåˆæœŸæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
    
    tasks = {name: func(user_id, final_query) for name, func in BASE_MODELS_FOR_ALL.items()}
    adv_models_to_run = {
        "gpt-4o": ADVANCED_MODELS_FOR_ALL["gpt-4o"][0],
        "Gemini 2.5 Flash": ADVANCED_MODELS_FOR_ALL["Gemini 2.5 Flash"][0],
        "Perplexity": ADVANCED_MODELS_FOR_ALL["Perplexity"][0]
    }
    for name, func in adv_models_to_run.items():
        tasks[name] = func(final_query)

    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
    
    first_name = list(tasks.keys())[0]
    first_result = results[0]
    first_display_text = f"**ğŸ”¹ {first_name}ã®æ„è¦‹:**\n{first_result if not isinstance(first_result, Exception) else f'ã‚¨ãƒ©ãƒ¼: {first_result}'}"
    await interaction.edit_original_response(content=first_display_text[:2000]) 

    for name, result in list(zip(tasks.keys(), results))[1:]:
        display_text = f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{result if not isinstance(result, Exception) else f'ã‚¨ãƒ©ãƒ¼: {result}'}"
        await send_long_message(interaction, display_text, is_followup=True)

@tree.command(name="chain", description="è¤‡æ•°AIãŒãƒªãƒ¬ãƒ¼å½¢å¼ã§æ„è¦‹ã‚’ç¶™ç¶šã—ã¦ã„ãã¾ã™")
@app_commands.describe(topic="é€£é–ã•ã›ãŸã„è­°é¡Œ")
async def chain_command(interaction: discord.Interaction, topic: str):
    await interaction.response.defer()
    ai_order = [
        ("GPT", ask_gpt_base),
        ("Gemini", ask_gemini_base),
        ("Mistral", ask_mistral_base),
        ("Claude", ask_claude),
        ("Llama", ask_llama),
        ("Grok", ask_grok)
    ]
    user_id = str(interaction.user.id)
    previous_opinion = f"ã€è­°é¡Œã€‘\n{topic}"
    chain_results = []
    for name, ai_func in ai_order:
        prompt = f"{previous_opinion}\n\nã‚ãªãŸã¯{name}ã§ã™ã€‚å‰ã®AIã®æ„è¦‹ã‚’å‚è€ƒã«ã€ã•ã‚‰ã«æ·±ã‚ã¦ãã ã•ã„ã€‚"
        try:
            opinion = await ai_func(user_id, prompt)
        except Exception as e:
            opinion = f"{name}ã‚¨ãƒ©ãƒ¼: {e}"
        chain_results.append(f"â—† {name}ã®æ„è¦‹:\n{opinion}")
        previous_opinion = opinion  
    await send_long_message(interaction, "\n\n".join(chain_results), is_followup=True)

@tree.command(name="critical", description="Notionæƒ…å ±ã‚’å…ƒã«å…¨AIã§è­°è«–ã—ã€å¤šè§’çš„ãªçµè«–ã‚’å°ãã¾ã™ã€‚")
@app_commands.describe(topic="è­°è«–ã—ãŸã„è­°é¡Œ")
async def critical_command(interaction: discord.Interaction, topic: str):
    await interaction.response.defer()
    try:
        async def core_logic():
            target_page_id = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not target_page_id:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return
            
            context = await get_notion_context(interaction, target_page_id, topic, model_choice="gemini")

            if not context: return
            await interaction.edit_original_response(content=" 11ä½“ã®AIãŒåˆæœŸæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
            prompt_with_context = f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{topic}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{context}"
            user_id = str(interaction.user.id)
            tasks = {name: func(user_id, prompt_with_context) for name, func in BASE_MODELS_FOR_ALL.items()}
            for name, (func, wrapper) in ADVANCED_MODELS_FOR_ALL.items():
                if name == "Perplexity": tasks[name] = wrapper(func, topic, notion_context=context)
                else: tasks[name] = wrapper(func, prompt_with_context)
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)
            synthesis_material = "ä»¥ä¸‹ã®AIç¾¤ã®æ„è¦‹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n"
            full_text_results = ""
            for (name, result) in zip(tasks.keys(), results):
                full_response, summary = (result if isinstance(result, tuple) else (None, None))
                display_text = f"ã‚¨ãƒ©ãƒ¼: {result}" if isinstance(result, Exception) else (summary or full_response or result)
                full_text_results += f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{display_text}\n\n"
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{full_response or display_text}\n\n"
            await send_long_message(interaction, full_text_results, is_followup=False)
            await interaction.followup.send(" gpt-5ãŒä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™â€¦")
            intermediate_report = await ask_gpt5(synthesis_material, system_prompt="ä»¥ä¸‹ã®æ„è¦‹ã®è¦ç‚¹ã ã‘ã‚’æŠ½å‡ºã—ã€çŸ­ã„ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            await interaction.followup.send(" Mistral LargeãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
            final_report = await ask_lalah(intermediate_report, system_prompt="ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚æ¸¡ã•ã‚ŒãŸä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’å…ƒã«ã€æœ€çµ‚çš„ãªçµè«–ã‚’500æ–‡å­—ä»¥å†…ã§ãƒ¬ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
            await interaction.followup.send(f"** Mistral Large (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")
        await asyncio.wait_for(core_logic(), timeout=600)
    except Exception as e:
        safe_log("ğŸš¨ /critical ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
        await interaction.followup.send(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", ephemeral=True)

@tree.command(name="logical", description="Notionæƒ…å ±ã‚’å…ƒã«AIãŒè¨è«–ã—ã€è«–ç†çš„ãªçµè«–ã‚’å°ãã¾ã™ã€‚")
@app_commands.describe(topic="è¨è«–ã—ãŸã„è­°é¡Œ")
async def logical_command(interaction: discord.Interaction, topic: str):
    await interaction.response.defer()
    try:
        async def core_logic():
            target_page_id = NOTION_PAGE_MAP.get(str(interaction.channel.id))
            if not target_page_id:
                await interaction.edit_original_response(content="âŒ ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯Notionãƒšãƒ¼ã‚¸ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return

            context = await get_notion_context(interaction, target_page_id, topic, model_choice="gemini")
            if not context:
                # get_notion_contextå†…ã§ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é€ä¿¡æ¸ˆã¿
                return

            await interaction.edit_original_response(content="âš–ï¸ å†…éƒ¨è¨è«–ã¨å¤–éƒ¨èª¿æŸ»ã‚’ä¸¦åˆ—ã§é–‹å§‹ã—ã¾ã™â€¦")
            prompt_with_context = (f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
                                   f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{topic}\n\n"
                                   f"ã€å‚è€ƒæƒ…å ±ã€‘\n{context}")

            user_id = str(interaction.user.id)
            tasks = {
                "è‚¯å®šè«–è€…(gpt-4o)": get_full_response_and_summary(
                    ask_gpt4o,
                    prompt_with_context,
                    system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€è‚¯å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã‚’æ¨é€²ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªè«–æ‹ ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
                "å¦å®šè«–è€…(Grok)": ask_grok(
                    user_id,
                    f"{prompt_with_context}\n\nä¸Šè¨˜ã‚’è¸ã¾ãˆã€ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€å¦å®šè«–è€…ã€‘ã¨ã—ã¦ã€è­°é¡Œã«åå¯¾ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªåè«–ã‚’ã€å¸¸è­˜ã«ã¨ã‚‰ã‚ã‚Œãšæç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
                "ä¸­ç«‹åˆ†æå®˜(Gemini 2.5 Flash)": get_full_response_and_summary(
                    ask_minerva,
                    prompt_with_context,
                    system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ã€ä¸­ç«‹çš„ãªåˆ†æå®˜ã€‘ã§ã™ã€‚é–¢é€£ã™ã‚‹ç¤¾ä¼šçš„ãƒ»å€«ç†çš„ãªè«–ç‚¹ã‚’ã€æ„Ÿæƒ…ã‚’æ’ã—ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚"
                ),
                "å¤–éƒ¨èª¿æŸ»(Perplexity)": get_full_response_and_summary(
                    ask_rekus,
                    topic,
                    notion_context=context
                )
            }

            results = await asyncio.gather(*tasks.values(), return_exceptions=True)

            synthesis_material = "ä»¥ä¸‹ã®æƒ…å ±ã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
            results_text = ""
            for (name, result) in zip(tasks.keys(), results):
                if isinstance(result, Exception):
                    display_text = f"ã‚¨ãƒ©ãƒ¼: {result}"
                    full_response = display_text
                
                elif name == "å¦å®šè«–è€…(Grok)":
                    display_text = result
                    full_response = result
                
                else:
                    full_response, summary = result
                    display_text = summary or full_response

                results_text += f"**{name}:**\n{display_text}\n\n"
                synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{full_response}\n\n"

            await send_long_message(interaction, results_text, is_followup=False)

            await interaction.followup.send(" gpt-5ãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
            final_report = await ask_gpt5(
                synthesis_material,
                system_prompt="ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚æ¸¡ã•ã‚ŒãŸæƒ…å ±ã‚’å®¢è¦³çš„ã«çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
            )
            await interaction.followup.send(f"** gpt-5 (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")

        await asyncio.wait_for(core_logic(), timeout=600)

    except Exception as e:
        safe_log("ğŸš¨ /logical ã‚³ãƒãƒ³ãƒ‰ã§ã‚¨ãƒ©ãƒ¼:", e)
        try:
            await interaction.followup.send(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", ephemeral=True)
        except discord.errors.InteractionResponded:
            pass

@tree.command(name="sync", description="ç®¡ç†è€…å°‚ç”¨ï¼šã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚µãƒ¼ãƒãƒ¼ã«åŒæœŸã—ã¾ã™ã€‚")
async def sync_command(interaction: discord.Interaction):
    if str(interaction.user.id) != ADMIN_USER_ID:
        await interaction.response.send_message("ã“ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", ephemeral=True)
        return
    await interaction.response.defer(ephemeral=True)
    try:
        guild_obj = discord.Object(id=int(GUILD_ID)) if GUILD_ID else None
        tree.clear_commands(guild=guild_obj)
        await tree.sync(guild=guild_obj)
        tree.copy_global_to(guild=guild_obj)
        synced_commands = await tree.sync(guild=guild_obj)
        await interaction.followup.send(f"âœ… ã‚³ãƒãƒ³ãƒ‰ã®åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚åŒæœŸæ•°: {len(synced_commands)}ä»¶", ephemeral=True)
    except Exception as e:
        await interaction.followup.send(f"âŒ åŒæœŸä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n```{e}```", ephemeral=True)

@client.event
async def on_ready():
    print(f"âœ… Login successful: {client.user}")
    try:
        if GUILD_ID:
            guild_obj = discord.Object(id=int(GUILD_ID))
            tree.copy_global_to(guild=guild_obj)
            cmds = await tree.sync(guild=guild_obj)
            print(f"âœ… Synced {len(cmds)} guild commands to {GUILD_ID}")
        else:
            cmds = await tree.sync()
            print(f"âœ… Synced {len(cmds)} global commands")
    except Exception as e:
        print(f"ğŸš¨ FATAL ERROR on command sync: {e}")


@client.event
async def on_message(message):
    if message.author.bot or message.content.startswith("/"):
        return

    if message.content.startswith("!"):
        await message.channel.send("ğŸ’¡ `!`ã‚³ãƒãƒ³ãƒ‰ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚ä»Šå¾Œã¯`/`ã§å§‹ã¾ã‚‹ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        return

    channel_name = message.channel.name.lower()
    
    # "genius" ãƒãƒ£ãƒ³ãƒãƒ«ã®å‡¦ç†
    if channel_name.startswith("genius"):
        thread_id = str(message.channel.id)

        if thread_id in processing_channels:
            await message.channel.send("â³ ç¾åœ¨ã€å‰ã®å‡¦ç†ã‚’å®Ÿè¡Œä¸­ã§ã™ã€‚å®Œäº†ã¾ã§ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚", delete_after=10)
            return

        try:
            prompt = message.content
            is_admin = str(message.author.id) == ADMIN_USER_ID
            target_page_id = NOTION_PAGE_MAP.get(thread_id, NOTION_MAIN_PAGE_ID)

            if message.attachments:
                await message.channel.send(" æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™â€¦")
                prompt += "\n\n" + await analyze_attachment_for_gpt5(message.attachments[0])

            if is_admin and target_page_id:
                await log_to_notion(target_page_id, [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {message.author.display_name}:\n{prompt}"}}]}}])

            # å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹ç›´å‰ã«ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ãƒ­ãƒƒã‚¯
            processing_channels.add(thread_id)
            asyncio.create_task(run_genius_channel_task(message, prompt, target_page_id))
            return
            
            
            if not initial_summary:
                await channel.send("âŒ åˆå›è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return


        except Exception as e:
            safe_log("ğŸš¨ on_message (genius)ã§ã‚¨ãƒ©ãƒ¼:", e)
            await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ```{str(e)[:1800]}```")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚ãƒ­ãƒƒã‚¯ã‚’è§£é™¤
            if thread_id in processing_channels:
                processing_channels.remove(thread_id)
            return

    # "claudeéƒ¨å±‹" ã‚’å«ã‚€å„å°‚ç”¨éƒ¨å±‹ã®å‡¦ç†
    if not (channel_name.startswith("gpt") or channel_name.startswith("gemini") or channel_name.startswith("perplexity") or channel_name.startswith("claude")):
        return
        
    try:
        prompt = message.content
        thread_id = str(message.channel.id)
        is_admin = str(message.author.id) == ADMIN_USER_ID
        target_page_id = NOTION_PAGE_MAP.get(thread_id, NOTION_MAIN_PAGE_ID)

        if message.attachments:
            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯Claudeéƒ¨å±‹ã§ã¯ä¸€æ—¦ç„¡è¦–ã™ã‚‹ã‹ã€åˆ¥é€”å‡¦ç†ã‚’å®šç¾©
            if not channel_name.startswith("claude"):
                 await message.channel.send("ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã„ã¾ã™â€¦")
                 prompt += "\n\n" + await analyze_attachment_for_gpt5(message.attachments[0])

        # --- "Claudeéƒ¨å±‹" ã®å°‚ç”¨ãƒ­ã‚¸ãƒƒã‚¯ ---
        if channel_name.startswith("claude"):
            # é€²æ—ã‚’å‡ºã•ãšã«Notionã‚’èª­ã¿è¾¼ã‚€
            notion_raw_text = await get_notion_page_text(target_page_id)
            if notion_raw_text.startswith("ERROR:") or not notion_raw_text.strip():
                await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            
            # ç®¡ç†è€…ã®å ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’Notionã«è¨˜éŒ²
            if is_admin and target_page_id:
                await log_to_notion(target_page_id, [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {message.author.display_name}:\n{prompt}"}}]}}])

            full_prompt = (
                f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
                f"ã€å‚è€ƒæƒ…å ±ã€‘\n{notion_raw_text}\n\n"
                f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{prompt}"
            )
            
            # Botã«ã€Œè€ƒãˆä¸­ã€ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤ºã•ã›ã‚‹
            async with message.channel.typing():
                reply = await ask_claude("claude_user", full_prompt, history=[])
                await send_long_message(message.channel, reply)

            # ç®¡ç†è€…ã®å ´åˆã€Botã®è¿”ç­”ã‚’Notionã«è¨˜éŒ²
            if is_admin and target_page_id:
                await log_response(target_page_id, reply, "Claude (å°‚ç”¨éƒ¨å±‹)")
            return
        
        # --- ã“ã“ã¾ã§ãŒClaudeéƒ¨å±‹ã®å‡¦ç† ---

        # ä»¥ä¸‹ã€æ—¢å­˜ã®gpt, gemini, perplexityéƒ¨å±‹ã®å‡¦ç†
        is_memory_on = await get_memory_flag_from_notion(thread_id)

        if channel_name.startswith("gpt"):
            summary_model_to_use = "perplexity"
        elif channel_name.startswith("gemini"):
            summary_model_to_use = "gpt"
        else: # perplexity
            summary_model_to_use = "gemini_2_5_pro"

        notion_context = await get_notion_context_for_message(message, target_page_id, prompt, model_choice=summary_model_to_use)
        if notion_context is None:
            await message.channel.send("âš ï¸ Notionã®å‚ç…§ã«å¤±æ•—ã—ãŸãŸã‚ã€ä¼šè©±å±¥æ­´ã®ã¿ã§å¿œç­”ã—ã¾ã™ã€‚")

        if channel_name.startswith("gpt"):
            history = gpt_thread_memory.get(thread_id, []) if is_memory_on else []
            history_text = "\n".join([f"{m['role']}: {m['content']}" for m in history])
            full_prompt = f"ã€Notionãƒšãƒ¼ã‚¸ã®è¦ç´„ã€‘\n{notion_context or 'å‚ç…§ãªã—'}\n\nã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n{history_text or 'ãªã—'}\n\nã€ä»Šå›ã®è³ªå•ã€‘\n{prompt}"
            await message.channel.send(" å—ä»˜å®Œäº†ã€‚gpt-5ãŒæ€è€ƒã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            asyncio.create_task(run_long_gpt5_task(message, prompt, full_prompt, is_admin, target_page_id, thread_id))

        elif channel_name.startswith("gemini"):
            await message.channel.send(" Gemini 2.5 ProãŒæ€è€ƒã‚’é–‹å§‹ã—ã¾ã™â€¦")
            history = gemini_thread_memory.get(thread_id, []) if is_memory_on else []
            history_text = "\n".join([f"{m['role']}: {m['content']}" for m in history])
            if is_admin and target_page_id:
                await log_to_notion(target_page_id, [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {message.author.display_name}:\n{prompt}"}}]}}])
            full_prompt = f"ã€Notionãƒšãƒ¼ã‚¸ã®è¦ç´„ã€‘\n{notion_context or 'å‚ç…§ãªã—'}\n\nã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n{history_text or 'ãªã—'}\n\nã€ä»Šå›ã®è³ªå•ã€‘\nuser: {prompt}"
            
            reply = await ask_gemini_2_5_pro(full_prompt)
            
            await send_long_message(message.channel, reply)
            if is_admin and target_page_id:
                await log_response(target_page_id, reply, "Gemini 2.5 Pro")
            if is_memory_on and "ã‚¨ãƒ©ãƒ¼" not in reply:
                history.extend([{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}])
                gemini_thread_memory[thread_id] = history[-10:]

        elif channel_name.startswith("perplexity"):
            await message.channel.send(" Perplexity SonarãŒæ€è€ƒã‚’é–‹å§‹ã—ã¾ã™â€¦")
            history = perplexity_thread_memory.get(thread_id, []) if is_memory_on else []
            history_text = "\n".join([f"{m['role']}: {m['content']}" for m in history])
            if is_admin and target_page_id:
                await log_to_notion(target_page_id, [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {message.author.display_name}:\n{prompt}"}}]}}])
            
            rekus_prompt = f"ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n{history_text or 'ãªã—'}\n\nã€ä»Šå›ã®è³ªå•ã€‘\n{prompt}"
            
            reply = await ask_rekus(rekus_prompt, notion_context=notion_context)
            
            await send_long_message(message.channel, reply)
            if is_admin and target_page_id:
                await log_response(target_page_id, reply, "Perplexity Sonar")
            if is_memory_on and "ã‚¨ãƒ©ãƒ¼" not in str(reply):
                history.extend([{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}])
                perplexity_thread_memory[thread_id] = history[-10:]

    except Exception as e:
        safe_log("ğŸš¨ on_messageã§ã‚¨ãƒ©ãƒ¼:", e)
        await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ```{str(e)[:1800]}```")
            
@app.on_event("startup")
async def startup_event():
    """ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã«Botã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•ã™ã‚‹"""
    global openai_client, mistral_client, notion, llama_model_for_vertex
    try:
        print("ğŸ¤– Initializing API clients...")
        openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)
        notion = Client(auth=NOTION_API_KEY)
        genai.configure(api_key=GEMINI_API_KEY)
        try:
            print("ğŸ¤– Initializing Vertex AI...")
            vertexai.init(project="stunning-agency-469102-b5", location="us-central1")
            llama_model_for_vertex = GenerativeModel("publishers/meta/models/llama-3.3-70b-instruct-maas")
            
            # â–¼â–¼â–¼ã€è¿½åŠ ã€‘ã“ã“ã‹ã‚‰ â–¼â–¼â–¼
            # åˆæœŸåŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ai_clients.pyã«æ¸¡ã™
            set_llama_model(llama_model_for_vertex)
            print("âœ… Vertex AI initialized successfully and passed to clients.")
            # â–²â–²â–²ã€è¿½åŠ ã€‘ã“ã“ã¾ã§ â–²â–²â–²

        except Exception as e:
            print(f"ğŸš¨ Vertex AI init failed (continue without it): {e}")
        
        async def start_bot():
            await client.login(DISCORD_TOKEN)
            await client.connect()

        asyncio.create_task(start_bot())

        print("âœ… Discord Bot startup task has been created.")
    except Exception as e:
        print(f"ğŸš¨ğŸš¨ğŸš¨ FATAL ERROR during startup event: {e} ğŸš¨ğŸš¨ğŸš¨")

@app.get("/")
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok", "bot_is_connected": client.is_ready()}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", "8080"))
    uvicorn.run(app, host="0.0.0.0", port=port)
