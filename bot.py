import discord
from openai import AsyncOpenAI
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import asyncio
import os
from dotenv import load_dotenv
from notion_client import Client
import requests # Rekusç”¨

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")
perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
notion_api_key = os.getenv("NOTION_API_KEY")
ADMIN_USER_ID = os.getenv("ADMIN_USER_ID")
NOTION_MAIN_PAGE_ID = os.getenv("NOTION_PAGE_ID") 

# --- å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
openai_client = AsyncOpenAI(api_key=openai_api_key)
genai.configure(api_key=gemini_api_key)
notion = Client(auth=notion_api_key)
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
processing_users = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def send_long_message(channel, text):
    if not text: return
    if len(text) <= 2000:
        await channel.send(text)
    else:
        for i in range(0, len(text), 2000):
            await channel.send(text[i:i+2000])

# --- Notioné€£æºé–¢æ•° ---
def _sync_get_notion_page_text(page_id):
    all_text_blocks = []
    next_cursor = None
    while True:
        try:
            response = notion.blocks.children.list(
                block_id=page_id,
                start_cursor=next_cursor,
                page_size=100 # 1å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å–å¾—ã™ã‚‹æœ€å¤§ãƒ–ãƒ­ãƒƒã‚¯æ•°
            )
            results = response.get("results", [])
            for block in results:
                if block.get("type") == "paragraph":
                    for rich_text in block.get("paragraph", {}).get("rich_text", []):
                        all_text_blocks.append(rich_text.get("text", {}).get("content", ""))
            
            if response.get("has_more"):
                next_cursor = response.get("next_cursor")
            else:
                break
        except Exception as e:
            print(f"âŒ Notionèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ERROR: Notion API Error - {e}"
    
    return "\n".join(all_text_blocks)

async def get_notion_page_text(page_id):
    return await asyncio.get_event_loop().run_in_executor(None, _sync_get_notion_page_text, page_id)

async def log_to_notion(blocks):
    if not NOTION_MAIN_PAGE_ID: return
    try:
        await asyncio.get_event_loop().run_in_executor(None, 
            lambda: notion.blocks.children.append(block_id=NOTION_MAIN_PAGE_ID, children=blocks)
        )
    except Exception as e:
        print(f"âŒ Notionæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

async def log_response(answer, bot_name):
    if not answer or isinstance(answer, Exception): return
    chunks = [answer[i:i + 1900] for i in range(0, len(answer), 1900)] if len(answer) > 1900 else [answer]
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ¤– {bot_name}:\n{chunks[0]}"}}]}}]
    for chunk in chunks[1:]:
        blocks.append({"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}})
    await log_to_notion(blocks)

# --- !askã‚³ãƒãƒ³ãƒ‰å°‚ç”¨AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•° ---
async def ask_minerva_chunk_summarizer(prompt):
    system_prompt = "ã‚ãªãŸã¯ã€ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã®ä¸­ã‹ã‚‰ã€å¾Œç¶šã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã ã‘ã‚’çš„ç¢ºã«æŠ½å‡ºãƒ»è¦ç´„ã™ã‚‹AIã§ã™ã€‚ãƒšãƒ«ã‚½ãƒŠã¯ä¸è¦ã§ã™ã€‚æŒ‡ç¤ºã•ã‚ŒãŸæ–‡å­—æ•°åˆ¶é™ã«å¾“ã£ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    try:
        response = await model.generate_content_async(prompt)
        return response.text
    except Exception as e: 
        print(f"âŒ ãƒŸãƒãƒ«ãƒ(ãƒãƒ£ãƒ³ã‚¯è¦ç´„)ã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼ï¼šãƒŸãƒãƒ«ãƒã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

async def ask_gpt4o_final_summarizer(prompt):
    system_prompt = "ã‚ãªãŸã¯ã€æ–­ç‰‡çš„ãªè¤‡æ•°ã®è¦ç´„æ–‡ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚‰ã‚’ä¸€ã¤ã®é¦–å°¾ä¸€è²«ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«çµ±åˆãƒ»åˆ†æã™ã‚‹AIã§ã™ã€‚ãƒšãƒ«ã‚½ãƒŠã¯ä¸è¦ã§ã™ã€‚æŒ‡ç¤ºã•ã‚ŒãŸæ–‡å­—æ•°åˆ¶é™ã«å¾“ã£ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=messages, max_tokens=2200) # ãƒãƒ¼ã‚¸ãƒ³ã‚’æŒãŸã›ã‚‹
        return response.choices[0].message.content
    except Exception as e: 
        print(f"âŒ gpt-4o(çµ±åˆè¦ç´„)ã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼ï¼šgpt-4oã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

async def ask_rekus_final_answerer(prompt):
    system_prompt = "ã‚ãªãŸã¯ã€ä¸ãˆã‚‰ã‚ŒãŸå‚è€ƒæƒ…å ±ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å…ƒã«ã€æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹AIã§ã™ã€‚ãƒšãƒ«ã‚½ãƒŠã¯æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã§ã™ã€‚å¿…ãš200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    payload = {"model": "sonar-pro", "messages": messages, "max_tokens": 400}
    headers = {"Authorization": f"Bearer {perplexity_api_key}", "Content-Type": "application/json"}
    try:
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers))
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e: 
        print(f"âŒ ãƒ¬ã‚­ãƒ¥ã‚¹(æœ€çµ‚å›ç­”)ã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼ï¼šãƒ¬ã‚­ãƒ¥ã‚¹ã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# --- Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready(): print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {client.user}")

@client.event
async def on_message(message):
    if message.author.bot or message.author.id in processing_users: return
    
    content = message.content
    command_name = content.split(' ')[0]
    
    if command_name != "!ask": return

    processing_users.add(message.author.id)
    try:
        user_id, user_name = str(message.author.id), message.author.display_name
        query = content[len(command_name):].strip()
        is_admin = user_id == ADMIN_USER_ID

        if is_admin:
            log_blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {user_name} ãŒã€Œ{command_name} {query}ã€ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"}}]}}]
            await log_to_notion(log_blocks)

        await message.channel.send(f"ğŸ§  Notionãƒšãƒ¼ã‚¸({NOTION_MAIN_PAGE_ID})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
        
        # ã‚¹ãƒ†ãƒƒãƒ—0: Notionã‹ã‚‰å…¨æ–‡å–å¾—
        notion_text = await get_notion_page_text(NOTION_MAIN_PAGE_ID)
        if notion_text.startswith("ERROR:"):
            print(f"Notion Error Details: {notion_text}")
            await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        if not notion_text.strip():
            await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒšãƒ¼ã‚¸ãŒç©ºã‹ã€æ¨©é™ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            return

        await message.channel.send(f"ğŸ“„ ã‚¹ãƒ†ãƒƒãƒ—1/3: å…¨æ–‡èª­ã¿è¾¼ã¿å®Œäº†ã€‚ãƒŸãƒãƒ«ãƒãŒå†…å®¹ã‚’åˆ†å‰²ã—ã¦è¦ç´„ã—ã¾ã™â€¦")

        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒãƒ£ãƒ³ã‚¯æ¯ã®è¦ç´„ by ãƒŸãƒãƒ«ãƒ
        chunk_size = 8000
        text_chunks = [notion_text[i:i + chunk_size] for i in range(0, len(notion_text), chunk_size)]
        
        chunk_summaries = []
        for i, chunk in enumerate(text_chunks):
            await message.channel.send(f"ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(text_chunks)} ã‚’ãƒŸãƒãƒ«ãƒãŒè¦ç´„ä¸­â€¦")
            chunk_summary_prompt = f"ä»¥ä¸‹ã®æ–‡ç« ã¯ã€ã‚ã‚‹Notionãƒšãƒ¼ã‚¸ã®ãƒ­ã‚°ã®ä¸€éƒ¨ã§ã™ã€‚æœ€çµ‚çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œ{query}ã€ã«ç­”ãˆã‚‹ãŸã‚ã€ã“ã®éƒ¨åˆ†ã‹ã‚‰é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’2000æ–‡å­—ä»¥å†…ã§æŠ½å‡ºãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ­ã‚°ã®ä¸€éƒ¨ã€‘\n{chunk}"
            chunk_summary = await ask_minerva_chunk_summarizer(chunk_summary_prompt)
            if "ã‚¨ãƒ©ãƒ¼" in chunk_summary:
                await message.channel.send(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            chunk_summaries.append(chunk_summary)
            await asyncio.sleep(3) # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

        if not chunk_summaries:
            await message.channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è¦ç´„ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        await message.channel.send("âœ… ã‚¹ãƒ†ãƒƒãƒ—2/3: å…¨ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„å®Œäº†ã€‚gpt-4oãŒçµ±åˆãƒ»åˆ†æã—ã¾ã™â€¦")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: å…¨ä½“ã®è¦ç´„ by gpt-4o
        combined_summaries = "\n\n---\n\n".join(chunk_summaries)
        integration_prompt = f"ä»¥ä¸‹ã®è¤‡æ•°ã®è¦ç´„ã¯ã€ä¸€ã¤ã®Notionãƒšãƒ¼ã‚¸ã‚’åˆ†å‰²ã—ã¦è¦ç´„ã—ãŸã‚‚ã®ã§ã™ã€‚ã“ã‚Œã‚‰ã®è¦ç´„å…¨ä½“ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®æœ€çµ‚çš„ãªå‚è€ƒæƒ…å ±ã‚’2000æ–‡å­—ä»¥å†…ã§çµ±åˆãƒ»åˆ†æã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nã€å„éƒ¨åˆ†ã®è¦ç´„ã€‘\n{combined_summaries}"
        final_context = await ask_gpt4o_final_summarizer(integration_prompt)

        if "ã‚¨ãƒ©ãƒ¼" in final_context:
            await message.channel.send(f"âš ï¸ çµ±åˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n{final_context}")
            return

        await message.channel.send("âœ… ã‚¹ãƒ†ãƒƒãƒ—3/3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå®Œäº†ã€‚ãƒ¬ã‚­ãƒ¥ã‚¹ãŒæœ€çµ‚å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™â€¦")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: æœ€çµ‚çš„ãªå›ç­” by ãƒ¬ã‚­ãƒ¥ã‚¹
        final_prompt = f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{final_context}"
        final_reply = await ask_rekus_final_answerer(final_prompt)
        
        await send_long_message(message.channel, f"**ğŸ¤– æœ€çµ‚å›ç­” (by ãƒ¬ã‚­ãƒ¥ã‚¹):**\n{final_reply}")
        
        if is_admin: 
            await log_response(final_context, "gpt-4o (çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ)")
            await log_response(final_reply, "ãƒ¬ã‚­ãƒ¥ã‚¹ (æœ€çµ‚å›ç­”)")

    except Exception as e:
        print(f"An error occurred in on_message: {e}")
        error_message = str(e)
        display_error = (error_message[:300] + '...') if len(error_message) > 300 else error_message
        await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ```{display_error}```")
    finally:
        if message.author.id in processing_users:
            processing_users.remove(message.author.id)

# --- èµ·å‹• ---
client.run(DISCORD_TOKEN)
