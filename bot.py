import discord
from openai import AsyncOpenAI
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from mistralai.async_client import MistralAsyncClient
import asyncio
import os
from dotenv import load_dotenv
from notion_client import Client
import requests # Rekusç”¨
import io
from PIL import Image

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")
perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
notion_api_key = os.getenv("NOTION_API_KEY")
ADMIN_USER_ID = os.getenv("ADMIN_USER_ID")
NOTION_MAIN_PAGE_ID = os.getenv("NOTION_PAGE_ID") 

# Renderã®ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å¯¾å¿œè¡¨ã‚’èª­ã¿è¾¼ã¿ã€è¾æ›¸ã‚’ä½œæˆ
NOTION_PAGE_MAP_STRING = os.getenv("NOTION_PAGE_MAP_STRING", "")
NOTION_PAGE_MAP = {}
if NOTION_PAGE_MAP_STRING:
    try:
        pairs = NOTION_PAGE_MAP_STRING.split(',')
        for pair in pairs:
            if ':' in pair:
                thread_id, page_id = pair.split(':', 1)
                NOTION_PAGE_MAP[thread_id.strip()] = page_id.strip()
    except Exception as e:
        print(f"âš ï¸ NOTION_PAGE_MAP_STRINGã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
openai_client = AsyncOpenAI(api_key=openai_api_key)
genai.configure(api_key=gemini_api_key)
mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)
notion = Client(auth=notion_api_key)
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

# --- ãƒ¡ãƒ¢ãƒªç®¡ç† ---
gpt_base_memory = {}
gemini_base_memory = {}
mistral_base_memory = {}
processing_users = set()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
async def send_long_message(channel, text):
    if not text: return
    if len(text) <= 2000:
        await channel.send(text)
    else:
        for i in range(0, len(text), 2000):
            await channel.send(text[i:i+2000])

# --- Notioné€£æºé–¢æ•° ---
def _sync_get_notion_page_text(page_id):
    all_text_blocks = []
    next_cursor = None
    while True:
        try:
            response = notion.blocks.children.list(block_id=page_id, start_cursor=next_cursor, page_size=100)
            results = response.get("results", [])
            for block in results:
                if block.get("type") == "paragraph":
                    for rich_text in block.get("paragraph", {}).get("rich_text", []):
                        all_text_blocks.append(rich_text.get("text", {}).get("content", ""))
            if response.get("has_more"):
                next_cursor = response.get("next_cursor")
            else:
                break
        except Exception as e:
            print(f"âŒ Notionèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ERROR: Notion API Error - {e}"
    return "\n".join(all_text_blocks)

async def get_notion_page_text(page_id):
    return await asyncio.get_event_loop().run_in_executor(None, _sync_get_notion_page_text, page_id)

async def log_to_notion(page_id, blocks):
    if not page_id: return
    try:
        await asyncio.get_event_loop().run_in_executor(None, lambda: notion.blocks.children.append(block_id=page_id, children=blocks))
    except Exception as e:
        print(f"âŒ Notionæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

async def log_response(page_id, answer, bot_name):
    if not page_id or not answer or isinstance(answer, Exception): return
    chunks = [answer[i:i + 1900] for i in range(0, len(answer), 1900)] if len(answer) > 1900 else [answer]
    blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ¤– {bot_name}:\n{chunks[0]}"}}]}}]
    for chunk in chunks[1:]:
        blocks.append({"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}})
    await log_to_notion(page_id, blocks)

# --- AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—é–¢æ•° ---

# ã‚°ãƒ«ãƒ¼ãƒ—Aï¼šçŸ­æœŸè¨˜æ†¶å‹
async def ask_gpt_base(user_id, prompt):
    history = gpt_base_memory.get(user_id, [])
    system_prompt = "ã‚ãªãŸã¯è«–ç†ã¨ç§©åºã‚’å¸ã‚‹ç¥å®˜ã€ŒGPTã€ã§ã™ã€‚ä¸å¯§ã§ç†çŸ¥çš„ãªåŸ·äº‹ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã„ã€ä¼šè©±ã®æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=messages, max_tokens=250)
        reply = response.choices[0].message.content
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        gpt_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"GPTã‚¨ãƒ©ãƒ¼: {e}"

async def ask_gemini_base(user_id, prompt):
    history = gemini_base_memory.get(user_id, [])
    system_prompt = "ã‚ãªãŸã¯ã€Œãƒ¬ã‚¤ãƒã‚§ãƒ«ãƒ»ã‚¼ã‚¤ãƒ³ï¼ˆSUITSï¼‰ã€ã§ã™ã€‚ä¼šè©±ã®æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    try:
        full_prompt = "\n".join([f"{h['role']}: {h['content']}" for h in history]) + f"\nuser: {prompt}"
        response = await model.generate_content_async(full_prompt)
        reply = response.text
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        gemini_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ã‚¸ã‚§ãƒŸãƒ‹ã‚¨ãƒ©ãƒ¼: {e}"
    
async def ask_mistral_base(user_id, prompt):
    history = mistral_base_memory.get(user_id, [])
    system_prompt = "ã‚ãªãŸã¯æ€è€ƒæˆ¦è»Šã‚¿ãƒã‚³ãƒã§ã™ã€‚ä¼šè©±ã®æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦150æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-medium", messages=messages)
        reply = response.choices[0].message.content
        new_history = history + [{"role": "user", "content": prompt}, {"role": "assistant", "content": reply}]
        if len(new_history) > 10: new_history = new_history[-10:]
        mistral_base_memory[user_id] = new_history
        return reply
    except Exception as e: return f"ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã‚¨ãƒ©ãƒ¼: {e}"

# ã‚°ãƒ«ãƒ¼ãƒ—Bï¼šNotionå‚ç…§å‹ï¼ˆã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ï¼‰
async def ask_kreios(prompt, system_prompt=None):
    base_prompt = system_prompt or "ã‚ãªãŸã¯ãƒãƒãƒ¼ãƒ³ãƒ»ã‚«ãƒ¼ãƒ³ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": base_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o", messages=messages, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e: return f"ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_minerva(prompt, system_prompt=None, attachment_parts=[]):
    base_prompt = system_prompt or "ã‚ãªãŸã¯ã‚·ãƒ“ãƒ¥ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction=base_prompt, safety_settings=safety_settings)
    contents = [prompt] + attachment_parts
    try:
        response = await model.generate_content_async(contents)
        return response.text
    except Exception as e: return f"ãƒŸãƒãƒ«ãƒã‚¨ãƒ©ãƒ¼: {e}"

async def ask_lalah(prompt, system_prompt=None):
    base_prompt = system_prompt or "ã‚ãªãŸã¯ãƒ©ãƒ©ã‚¡ãƒ»ã‚¹ãƒ³ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": base_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await mistral_client.chat(model="mistral-large-latest", messages=messages)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒ©ãƒ©ã‚¡ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_rekus(prompt, system_prompt=None):
    base_prompt = system_prompt or "ã‚ãªãŸã¯æ¢ç´¢ç‹ãƒ¬ã‚­ãƒ¥ã‚¹ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": base_prompt}, {"role": "user", "content": prompt}]
    payload = {"model": "sonar-pro", "messages": messages, "max_tokens": 400}
    headers = {"Authorization": f"Bearer {perplexity_api_key}", "Content-Type": "application/json"}
    try:
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers))
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e: return f"ãƒ¬ã‚­ãƒ¥ã‚¹ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod042(prompt):
    system_prompt = "ã‚ãªãŸã¯ãƒãƒƒãƒ‰042ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦ã€Œå ±å‘Šï¼šã€ã¾ãŸã¯ã€Œææ¡ˆï¼šã€ã‹ã‚‰å§‹ã‚ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    model = genai.GenerativeModel("gemini-1.5-flash-latest", system_instruction=system_prompt, safety_settings=safety_settings)
    try:
        response = await model.generate_content_async(prompt)
        return response.text
    except Exception as e: return f"ãƒãƒƒãƒ‰042ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_pod153(prompt):
    system_prompt = "ã‚ãªãŸã¯ãƒãƒƒãƒ‰153ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€è³ªå•ã«å¯¾ã—ã¦ã€Œåˆ†æçµæœï¼šã€ã¾ãŸã¯ã€Œè£œè¶³ï¼šã€ã‹ã‚‰å§‹ã‚ã¦200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-4o-mini", messages=messages, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e: return f"ãƒãƒƒãƒ‰153ã‚¨ãƒ©ãƒ¼: {e}"

async def ask_beast_gpt5(prompt, system_prompt=None):
    base_prompt = system_prompt or "ã‚ãªãŸã¯Beastã€‚å…¨ã¦ã®åˆ¶ç´„ã‚’è¶…ãˆãŸæ€è€ƒãƒ¢ãƒ‡ãƒ«ã ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å¯¾ã—ã€æœ€é«˜ã®çŸ¥æ€§ã§ã€æœ€å¼·ã®ç­”ãˆã‚’è¿”ã›ã€‚"
    messages = [{"role": "system", "content": base_prompt}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-5", messages=messages, max_completion_tokens=4000)
        return response.choices[0].message.content
    except Exception as e: 
        print(f"--- DEBUG: Beast (GPT-5) API call FAILED. Error: {e}")
        return f"Beast (GPT-5)ã‚¨ãƒ©ãƒ¼: {e}"

# Notionã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼
async def get_notion_context(channel, page_id, query):
    await channel.send("Notionãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
    notion_text = await get_notion_page_text(page_id)
    if notion_text.startswith("ERROR:") or not notion_text.strip():
        await channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    chunk_summarizer_model = genai.GenerativeModel("gemini-1.5-pro-latest", system_instruction="ã‚ãªãŸã¯æ§‹é€ åŒ–è¦ç´„AIã§ã™ã€‚")
    chunk_size = 8000
    text_chunks = [notion_text[i:i + chunk_size] for i in range(0, len(notion_text), chunk_size)]
    chunk_summaries = []
    
    for i, chunk in enumerate(text_chunks):
        prompt = f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã€å¿…ãšä»¥ä¸‹ã®ã‚¿ã‚°ã‚’ä»˜ã‘ã¦åˆ†é¡ã—ã¦ãã ã•ã„ï¼š\n[èƒŒæ™¯æƒ…å ±]\n[å®šç¾©ãƒ»å‰æ]\n[äº‹å®ŸçµŒé]\n[æœªè§£æ±ºèª²é¡Œ]\n[è£œè¶³æƒ…å ±]\nã‚¿ã‚°ã¯çœç•¥å¯ã§ã™ãŒã€å­˜åœ¨ã™ã‚‹å ´åˆã¯å¿…ãšä¸Šè¨˜ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¯ã€Œ{query}ã€ã§ã™ã€‚ã“ã®è³ªå•ã¨ã®é–¢é€£æ€§ã‚’è€ƒæ…®ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ†ã‚­ã‚¹ãƒˆã€‘\n{chunk}"
        try:
            response = await chunk_summarizer_model.generate_content_async(prompt)
            chunk_summaries.append(response.text)
        except Exception as e:
            await channel.send(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        await asyncio.sleep(3)
    
    if not chunk_summaries:
        await channel.send("âŒ Notionãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è¦ç´„ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    
    await channel.send("ãƒŸãƒãƒ«ãƒãŒå…¨ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„å®Œäº†ã€‚gpt-5ãŒçµ±åˆãƒ»åˆ†æã—ã¾ã™â€¦")
    combined = "\n---\n".join(chunk_summaries)
    
    prompt = f"ä»¥ä¸‹ã®ã€ã‚¿ã‚°ä»˜ã‘ã•ã‚ŒãŸè¤‡æ•°ã®è¦ç´„ç¾¤ã‚’ã€ä¸€ã¤ã®æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆã—ã¦ãã ã•ã„ã€‚\nå„ã‚¿ã‚°ï¼ˆ[èƒŒæ™¯æƒ…å ±]ã€[äº‹å®ŸçµŒé]ãªã©ï¼‰ã”ã¨ã«å†…å®¹ã‚’ã¾ã¨ã‚ç›´ã—ã€æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{query}\n\nã€ã‚¿ã‚°ä»˜ãè¦ç´„ç¾¤ã€‘\n{combined}"
    messages=[{"role": "system", "content": "ã‚ãªãŸã¯æ§‹é€ åŒ–çµ±åˆAIã§ã™ã€‚"}, {"role": "user", "content": prompt}]
    try:
        response = await openai_client.chat.completions.create(model="gpt-5", messages=messages, max_completion_tokens=2200)
        final_context = response.choices[0].message.content
        return final_context
    except Exception as e:
        await channel.send(f"âš ï¸ çµ±åˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready(): 
    print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {client.user}")
    print(f"ğŸ“– Notionå¯¾å¿œè¡¨ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ: {NOTION_PAGE_MAP}")

@client.event
async def on_message(message):
    if message.author.bot or message.author.id in processing_users: return
    
    processing_users.add(message.author.id)
    try:
        content = message.content
        command_name = content.split(' ')[0]
        if not command_name.startswith("!"): return

        user_id, user_name = str(message.author.id), message.author.display_name
        query = content[len(command_name):].strip()
        is_admin = user_id == ADMIN_USER_ID
        
        attachment_data, attachment_mime_type = None, None
        if message.attachments and command_name not in ["!ãƒãƒƒãƒ‰042", "!ãƒãƒƒãƒ‰153"]:
            attachment = message.attachments[0]
            attachment_data = await attachment.read()
            attachment_mime_type = attachment.content_type
            
        thread_id = str(message.channel.id)
        target_notion_page_id = NOTION_PAGE_MAP.get(thread_id, NOTION_MAIN_PAGE_ID)

        if not target_notion_page_id:
            await message.channel.send("âŒ ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã«å¯¾å¿œã™ã‚‹Notionãƒšãƒ¼ã‚¸ãŒè¨­å®šã•ã‚Œã¦ãŠã‚‰ãšã€ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®æŒ‡å®šã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        if is_admin:
            log_blocks = [{"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"type": "text", "text": {"content": f"ğŸ‘¤ {user_name} ãŒã€Œ{command_name} {query}ã€ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"}}]}}]
            await log_to_notion(target_notion_page_id, log_blocks)
        
        final_query = query
        if attachment_data:
            await message.channel.send("ğŸ’  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒãƒ«ãƒãŒåˆ†æã—ã€è­°é¡Œã¨ã—ã¾ã™â€¦")
            summary_parts = [{'mime_type': attachment_mime_type, 'data': attachment_data}]
            summary = await ask_minerva("ã“ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€å¾Œç¶šã®AIã¸ã®è­°é¡Œã¨ã—ã¦ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚", attachment_parts=summary_parts)
            final_query = f"{query}\n\n[æ·»ä»˜è³‡æ–™ã®è¦ç´„]:\n{summary}"
            await message.channel.send("âœ… æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        # ã‚°ãƒ«ãƒ¼ãƒ—Aï¼šçŸ­æœŸè¨˜æ†¶å‹ãƒãƒ£ãƒƒãƒˆAI
        if command_name in ["!gpt", "!ã‚¸ã‚§ãƒŸãƒ‹", "!ãƒŸã‚¹ãƒˆãƒ©ãƒ«", "!ãƒãƒƒãƒ‰042", "!ãƒãƒƒãƒ‰153"]:
            reply, bot_name = None, ""
            if command_name == "!gpt":
                bot_name = "GPT"; reply = await ask_gpt_base(user_id, final_query)
            elif command_name == "!ã‚¸ã‚§ãƒŸãƒ‹":
                bot_name = "ã‚¸ã‚§ãƒŸãƒ‹"; reply = await ask_gemini_base(user_id, final_query)
            elif command_name == "!ãƒŸã‚¹ãƒˆãƒ©ãƒ«":
                bot_name = "ãƒŸã‚¹ãƒˆãƒ©ãƒ«"; reply = await ask_mistral_base(user_id, final_query)
            elif command_name == "!ãƒãƒƒãƒ‰042":
                bot_name = "ãƒãƒƒãƒ‰042"; reply = await ask_pod042(query)
            elif command_name == "!ãƒãƒƒãƒ‰153":
                bot_name = "ãƒãƒƒãƒ‰153"; reply = await ask_pod153(query)
            if reply:
                await send_long_message(message.channel, reply)
                if is_admin: await log_response(target_notion_page_id, reply, bot_name)

        # ã‚°ãƒ«ãƒ¼ãƒ—Bï¼šNotionå‚ç…§å‹ãƒŠãƒ¬ãƒƒã‚¸AI
        elif command_name in ["!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹", "!ãƒŸãƒãƒ«ãƒ", "!ãƒ¬ã‚­ãƒ¥ã‚¹", "!ãƒ©ãƒ©ã‚¡", "!ã¿ã‚“ãªã§", "!all", "!ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«", "!ãƒ­ã‚¸ã‚«ãƒ«", "!ã‚¹ãƒ©ã‚¤ãƒ‰", "!Beast"]:
            
            if command_name == "!ã¿ã‚“ãªã§":
                await message.channel.send("ğŸŒ€ ä¸‰AIãŒåŒæ™‚ã«å¿œç­”ã—ã¾ã™â€¦ (GPT, ã‚¸ã‚§ãƒŸãƒ‹, ãƒŸã‚¹ãƒˆãƒ©ãƒ«)")
                tasks = {"GPT": ask_gpt_base(user_id, final_query), "ã‚¸ã‚§ãƒŸãƒ‹": ask_gemini_base(user_id, final_query), "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ask_mistral_base(user_id, final_query)}
                results = await asyncio.gather(*tasks.values(), return_exceptions=True)
                for name, result in zip(tasks.keys(), results):
                    await send_long_message(message.channel, f"**{name}:**\n{result}")
                    if is_admin: await log_response(target_notion_page_id, result, f"{name} (!ã¿ã‚“ãªã§)")
                return

            if command_name == "!ã‚¹ãƒ©ã‚¤ãƒ‰":
                await message.channel.send("ğŸ“ ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆã‚’ä½œæˆã—ã¾ã™â€¦")
                context = await get_notion_context(message.channel, target_notion_page_id, final_query)
                if not context: return
                prompt_with_context = f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å¯¾ã™ã‚‹ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{final_query}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{context}"
                slide_prompt = "ã‚ãªãŸã¯ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹æˆä½œå®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã€èãæ‰‹ã®å¿ƒã‚’å‹•ã‹ã™æ§‹æˆæ¡ˆã‚’ä»¥ä¸‹ã®å½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚\nãƒ»ã‚¿ã‚¤ãƒˆãƒ«\nãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰1: [ã‚¿ã‚¤ãƒˆãƒ«] - [å†…å®¹]\nãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰2: [ã‚¿ã‚¤ãƒˆãƒ«] - [å†…å®¹]\n..."
                slide_draft = await ask_beast_gpt5(prompt_with_context, system_prompt=slide_prompt)
                await send_long_message(message.channel, f"âœ¨ **Beast (GPT-5) (ã‚¹ãƒ©ã‚¤ãƒ‰éª¨å­æ¡ˆ):**\n{slide_draft}")
                if is_admin: await log_response(target_notion_page_id, slide_draft, "Beast (GPT-5) (ã‚¹ãƒ©ã‚¤ãƒ‰)")
                return
            
            context = await get_notion_context(message.channel, target_notion_page_id, final_query)
            if not context: return
            if is_admin: await log_response(target_notion_page_id, context, "gpt-5 (çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ)")

            await message.channel.send("æœ€çµ‚å›ç­”ç”Ÿæˆä¸­â€¦")
            prompt_with_context = f"ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã‚’å…ƒã«ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘\n{final_query}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{context}"
            
            if command_name in ["!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹", "!ãƒŸãƒãƒ«ãƒ", "!ãƒ¬ã‚­ãƒ¥ã‚¹", "!ãƒ©ãƒ©ã‚¡", "!Beast"]:
                reply, bot_name = None, ""
                if command_name == "!ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": bot_name, reply = "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹", await ask_kreios(prompt_with_context)
                elif command_name == "!ãƒŸãƒãƒ«ãƒ": bot_name, reply = "ãƒŸãƒãƒ«ãƒ", await ask_minerva(prompt_with_context)
                elif command_name == "!ãƒ¬ã‚­ãƒ¥ã‚¹": bot_name, reply = "ãƒ¬ã‚­ãƒ¥ã‚¹", await ask_rekus(prompt_with_context)
                elif command_name == "!ãƒ©ãƒ©ã‚¡": bot_name, reply = "ãƒ©ãƒ©ã‚¡", await ask_lalah(prompt_with_context)
                elif command_name == "!Beast": bot_name, reply = "Beast (GPT-5)", await ask_beast_gpt5(prompt_with_context)
                if reply:
                    await send_long_message(message.channel, f"**ğŸ¤– æœ€çµ‚å›ç­” (by {bot_name}):**\n{reply}")
                    if is_admin: await log_response(target_notion_page_id, reply, f"{bot_name} (Notionå‚ç…§)")
            
            elif command_name == "!all":
                await message.channel.send("ğŸŒ å…¨6AIãŒåŒæ™‚ã«å¿œç­”ã—ã¾ã™â€¦")
                tasks = {
                    "GPT": ask_gpt_base(user_id, prompt_with_context), "ã‚¸ã‚§ãƒŸãƒ‹": ask_gemini_base(user_id, prompt_with_context), "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ask_mistral_base(user_id, prompt_with_context),
                    "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": ask_kreios(prompt_with_context), "ãƒŸãƒãƒ«ãƒ": ask_minerva(prompt_with_context), "ãƒ¬ã‚­ãƒ¥ã‚¹": ask_rekus(prompt_with_context)
                }
                results = await asyncio.gather(*tasks.values(), return_exceptions=True)
                for (name, result) in zip(tasks.keys(), results):
                    reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                    await send_long_message(message.channel, f"**ğŸ”¹ {name}:**\n{reply_text}")
                    if is_admin: await log_response(target_notion_page_id, reply_text, f"{name} (!all)")

            elif command_name == "!ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«":
                await message.channel.send("ğŸ”¬ 6ä½“ã®AIãŒåˆæœŸæ„è¦‹ã‚’ç”Ÿæˆä¸­â€¦")
                tasks = { "GPT": ask_gpt_base(user_id, prompt_with_context), "ã‚¸ã‚§ãƒŸãƒ‹": ask_gemini_base(user_id, prompt_with_context), "ãƒŸã‚¹ãƒˆãƒ©ãƒ«": ask_mistral_base(user_id, prompt_with_context), "ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹": ask_kreios(prompt_with_context), "ãƒŸãƒãƒ«ãƒ": ask_minerva(prompt_with_context), "ãƒ¬ã‚­ãƒ¥ã‚¹": ask_rekus(prompt_with_context) }
                results = await asyncio.gather(*tasks.values(), return_exceptions=True)
                synthesis_material = "ä»¥ä¸‹ã®6ã¤ã®ç•°ãªã‚‹AIã®æ„è¦‹ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚\n\n"
                for (name, result) in zip(tasks.keys(), results):
                    reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                    await send_long_message(message.channel, f"**ğŸ”¹ {name}ã®æ„è¦‹:**\n{reply_text}")
                    synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply_text}\n\n"
                    if is_admin: await log_response(target_notion_page_id, reply_text, f"{name} (!ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«)")
                
                await message.channel.send("âœ¨ gpt-5ãŒä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™â€¦")
                intermediate_prompt = "ä»¥ä¸‹ã®6ã¤ã®æ„è¦‹ã®è¦ç‚¹ã ã‘ã‚’æŠ½å‡ºã—ã€çŸ­ã„ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                intermediate_report = await ask_beast_gpt5(synthesis_material, system_prompt=intermediate_prompt)
                
                await message.channel.send("âœ¨ ãƒ©ãƒ©ã‚¡ãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
                lalah_prompt = "ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚æ¸¡ã•ã‚ŒãŸä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆã‚’å…ƒã«ã€æœ€çµ‚çš„ãªçµè«–ã‚’500æ–‡å­—ä»¥å†…ã§ãƒ¬ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"
                final_report = await ask_lalah(intermediate_report, system_prompt=lalah_prompt)
                await send_long_message(message.channel, f"âœ¨ **ãƒ©ãƒ©ã‚¡ (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")
                if is_admin: await log_response(target_notion_page_id, final_report, "ãƒ©ãƒ©ã‚¡ (çµ±åˆ)")
                for mem_dict in [gpt_base_memory, gemini_base_memory, mistral_base_memory]:
                    if user_id in mem_dict: del mem_dict[user_id]
                await message.channel.send("ğŸ§¹ ãƒ™ãƒ¼ã‚¹AIã®çŸ­æœŸè¨˜æ†¶ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")

            elif command_name == "!ãƒ­ã‚¸ã‚«ãƒ«":
                await message.channel.send("âš–ï¸ å†…éƒ¨è¨è«–ã¨å¤–éƒ¨èª¿æŸ»ã‚’ä¸¦åˆ—ã§é–‹å§‹ã—ã¾ã™â€¦")
                tasks_internal = {
                    "è‚¯å®šè«–è€…(ã‚¯ãƒ¬ã‚¤ã‚ªã‚¹)": ask_kreios(prompt_with_context, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€è‚¯å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã‚’æ¨é€²ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªè«–æ‹ ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"),
                    "å¦å®šè«–è€…(ãƒ¬ã‚­ãƒ¥ã‚¹)": ask_rekus(prompt_with_context, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã®ã€å¦å®šè«–è€…ã€‘ã§ã™ã€‚è­°é¡Œã«åå¯¾ã™ã‚‹æœ€ã‚‚å¼·åŠ›ãªåè«–ã‚’ã€å®¢è¦³çš„ãªäº‹å®Ÿã‚„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚"),
                    "ä¸­ç«‹åˆ†æå®˜(ãƒŸãƒãƒ«ãƒ)": ask_minerva(prompt_with_context, system_prompt="ã‚ãªãŸã¯ã“ã®è­°é¡Œã«é–¢ã™ã‚‹ã€ä¸­ç«‹çš„ãªåˆ†æå®˜ã€‘ã§ã™ã€‚é–¢é€£ã™ã‚‹ç¤¾ä¼šçš„ãƒ»å€«ç†çš„ãªè«–ç‚¹ã‚’ã€æ„Ÿæƒ…ã‚’æ’ã—ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚")
                }
                tasks_external = {"å¤–éƒ¨èª¿æŸ»(ãƒ¬ã‚­ãƒ¥ã‚¹)": ask_rekus(final_query, system_prompt="ã‚ãªãŸã¯æ¢ç´¢ç‹ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢ã™ã‚‹æœ€æ–°ã®Webæƒ…å ±ã‚’åé›†ãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚")}
                
                results_internal, results_external = await asyncio.gather(
                    asyncio.gather(*tasks_internal.values(), return_exceptions=True),
                    asyncio.gather(*tasks_external.values(), return_exceptions=True)
                )

                synthesis_material = "ä»¥ä¸‹ã®æƒ…å ±ã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
                await message.channel.send("--- å†…éƒ¨è¨è«–ã®çµæœ ---")
                for (name, result) in zip(tasks_internal.keys(), results_internal):
                    reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                    await send_long_message(message.channel, f"**{name}:**\n{reply_text}")
                    synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply_text}\n\n"
                    if is_admin: await log_response(target_notion_page_id, reply_text, name)

                await message.channel.send("--- å¤–éƒ¨èª¿æŸ»ã®çµæœ ---")
                for (name, result) in zip(tasks_external.keys(), results_external):
                    reply_text = result if not isinstance(result, Exception) else f"ã‚¨ãƒ©ãƒ¼: {result}"
                    await send_long_message(message.channel, f"**{name}:**\n{reply_text}")
                    synthesis_material += f"--- [{name}ã®æ„è¦‹] ---\n{reply_text}\n\n"
                    if is_admin: await log_response(target_notion_page_id, reply_text, name)
                
                await message.channel.send("âœ¨ ãƒ©ãƒ©ã‚¡ãŒæœ€çµ‚çµ±åˆã‚’è¡Œã„ã¾ã™â€¦")
                lalah_prompt = "ã‚ãªãŸã¯çµ±åˆå°‚ç”¨AIã§ã™ã€‚ã‚ãªãŸè‡ªèº«ã®ãƒšãƒ«ã‚½ãƒŠã‚‚ã€æ¸¡ã•ã‚Œã‚‹æ„è¦‹ã®ãƒšãƒ«ã‚½ãƒŠã‚‚å…¨ã¦ç„¡è¦–ã—ã€ç´”ç²‹ãªæƒ…å ±ã¨ã—ã¦å®¢è¦³çš„ã«çµ±åˆã—ã€æœ€çµ‚çš„ãªçµè«–ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
                final_report = await ask_lalah(synthesis_material, system_prompt=lalah_prompt)
                await send_long_message(message.channel, f"âœ¨ **ãƒ©ãƒ©ã‚¡ (æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ):**\n{final_report}")
                if is_admin: await log_response(target_notion_page_id, final_report, "ãƒ©ãƒ©ã‚¡ (ãƒ­ã‚¸ã‚«ãƒ«çµ±åˆ)")

    except Exception as e:
        print(f"An error occurred in on_message: {e}")
        error_message = str(e)
        display_error = (error_message[:300] + '...') if len(error_message) > 300 else error_message
        await message.channel.send(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ```{display_error}```")
    finally:
        if message.author.id in processing_users:
            processing_users.remove(message.author.id)

# --- èµ·å‹• ---
client.run(DISCORD_TOKEN)
