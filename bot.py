from dotenv import load_dotenv
load_dotenv()

# --- æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
import asyncio
import os
import sys
import io

# --- å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from fastapi import FastAPI, Request
import uvicorn
import discord
from discord.ext import commands
import google.generativeai as genai
from mistralai.async_client import MistralAsyncClient
from notion_client import Client
from openai import AsyncOpenAI
import vertexai
# ä¿®æ­£: æ­£ã—ã„ã‚¯ãƒ©ã‚¹åã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from vertexai.generative_models import GenerativeModel
from google.cloud import secretmanager

# --- è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ---
import utils
import notion_utils
from config import get_config
from enhanced_memory_manager import get_enhanced_memory_manager

# --- åˆæœŸè¨­å®š ---
os.environ.setdefault("LANG", "C.UTF-8")

# Secret Manager ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
def load_secret(secret_name: str, project_id: str = "stunning-agency-469102-b5") -> str:
    """Google Secret Manager ã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    try:
        client = secretmanager.SecretManagerServiceClient()
        name = f"projects/{project_id}/secrets/{secret_name}/versions/latest"
        response = client.access_secret_version(request={"name": name})
        return response.payload.data.decode("UTF-8")
    except Exception as e:
        print(f"Error loading secret {secret_name}: {e}")
        return os.environ.get(secret_name, "")

# ç’°å¢ƒå¤‰æ•°ã‚’Secret Managerã‹ã‚‰èª­ã¿è¾¼ã¿
def load_environment_variables():
    """Secret Manager ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å¿…è¦ãªå€¤ã‚’èª­ã¿è¾¼ã¿"""
    secrets = [
        "DISCORD_BOT_TOKEN",
        "OPENAI_API_KEY",
        "GEMINI_API_KEY",
        "PERPLEXITY_API_KEY",
        "MISTRAL_API_KEY"
    ]

    for secret in secrets:
        if not os.environ.get(secret):
            secret_value = load_secret(secret)
            if secret_value:
                os.environ[secret] = secret_value
                print(f"âœ… Loaded {secret} from Secret Manager")
            else:
                print(f"âš ï¸  Could not load {secret}")

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_environment_variables()

# --- è¨­å®šèª­ã¿è¾¼ã¿ ---
print("ğŸ”§ Botè¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
config = get_config()

# APIã‚­ãƒ¼ã®å–å¾—ï¼ˆæ–°ã—ã„è¨­å®šã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
DISCORD_TOKEN = config.get_required("DISCORD_TOKEN")
OPENAI_API_KEY = config.get_required("OPENAI_API_KEY")
GEMINI_API_KEY = config.get_required("GEMINI_API_KEY")
PERPLEXITY_API_KEY = config.get_required("PERPLEXITY_API_KEY")
MISTRAL_API_KEY = config.get_required("MISTRAL_API_KEY")
NOTION_API_KEY = config.get_required("NOTION_API_KEY")
GROK_API_KEY = config.get_required("GROK_API_KEY")
OPENROUTER_API_KEY = config.get_required("OPENROUTER_API_KEY")
ADMIN_USER_ID = config.get_required("ADMIN_USER_ID")

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
GUILD_ID = config.get("GUILD_ID", "")

# --- FastAPIã¨Discord Botã®æº–å‚™ ---
app = FastAPI()

# Cloud Runç”¨ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def health_check():
    return {"status": "ok", "service": "discord-genius-bot"}

@app.get("/health")
async def detailed_health():
    return {
        "status": "healthy",
        "service": "discord-genius-bot",
        "version": "4.0",
        "features": ["plugin-system", "unified-task-engine", "ai-council"]
    }

intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix=None, intents=intents)

# å‹•çš„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£è¨­å®šç”¨ã®æ‹¡å¼µã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰
def _setup_legacy_memory_properties(self):
    """å¾“æ¥ãƒ¡ãƒ¢ãƒªå¤‰æ•°ã‚’å‹•çš„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ã—ã¦è¨­å®š"""
    from enhanced_memory_manager import LegacyMemoryMapping

    # å‹•çš„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã§çµ±ä¸€ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    for memory_type in LegacyMemoryMapping.base_memory_types:
        prop_name = f"{memory_type}_base_memory"
        setattr(self.__class__, prop_name,
               property(
                   lambda self, mt=memory_type: self.memory_manager.get_legacy_memory(mt, "base"),
                   lambda self, value, mt=memory_type: self.memory_manager.update_legacy_memory(mt, "__dict_update__", list(value.items()) if isinstance(value, dict) else value, "base")
               ))

    for memory_type in LegacyMemoryMapping.thread_memory_types:
        prop_name = f"{memory_type}_thread_memory"
        setattr(self.__class__, prop_name,
               property(
                   lambda self, mt=memory_type: self.memory_manager.get_legacy_memory(mt, "thread"),
                   lambda self, value, mt=memory_type: self.memory_manager.update_legacy_memory(mt, "__dict_update__", list(value.items()) if isinstance(value, dict) else value, "thread")
               ))

    # processing_channels ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    setattr(self.__class__, 'processing_channels',
           property(
               lambda self: self.memory_manager.get_processing_channels(),
               lambda self, value: None  # æ›¸ãè¾¼ã¿ã¯ç„¡è¦–ï¼ˆãƒ¡ã‚½ãƒƒãƒ‰çµŒç”±ã§æ“ä½œï¼‰
           ))

# Botã‚¯ãƒ©ã‚¹ã«ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‹•çš„è¿½åŠ 
commands.Bot._setup_legacy_memory_properties = _setup_legacy_memory_properties

# --- FastAPIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.get("/")
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆè¨­å®šæƒ…å ±ä»˜ãï¼‰"""
    return {
        "status": "ok",
        "bot_is_connected": bot.is_ready(),
        "config_summary": config.get_config_summary(),
        "features": {}
    }

@app.get("/config")
def config_status():
    """è¨­å®šçŠ¶æ³ç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "config_summary": config.get_config_summary()
    }

@app.get("/memory")
def memory_status():
    """ãƒ¡ãƒ¢ãƒªçŠ¶æ³ç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        memory_manager = get_memory_manager()
        return {
            "status": "ok",
            "memory_stats": memory_manager.get_detailed_stats()
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

@app.post("/memory/clear")
def clear_memory(ai_type: str = None, channel_id: str = None):
    """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        memory_manager = get_memory_manager()

        if ai_type and channel_id:
            cleared = memory_manager.clear_channel_memory(ai_type, channel_id)
            return {"status": "ok", "cleared_entries": cleared, "scope": f"{ai_type}#{channel_id}"}
        elif ai_type:
            cleared = memory_manager.clear_ai_memory(ai_type)
            return {"status": "ok", "cleared_entries": cleared, "scope": ai_type}
        else:
            cleared = memory_manager.clear_all_memory()
            return {"status": "ok", "cleared_entries": cleared, "scope": "all"}
    except Exception as e:
        return {"status": "error", "error": str(e)}

@app.get("/performance")
def performance_stats():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        from async_optimizer import get_global_optimization_stats
        from ai_manager import get_ai_manager

        stats = {
            "async_optimization": get_global_optimization_stats(),
            "memory_stats": get_memory_manager().get_memory_stats(),
        }

        # AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒåˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯çµ±è¨ˆã‚’è¿½åŠ 
        ai_manager = get_ai_manager()
        if ai_manager.initialized:
            stats["ai_stats"] = ai_manager.get_all_stats()

        return {
            "status": "ok",
            "performance": stats
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

@app.get("/rate-limits")
def rate_limit_status():
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ³ç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        from rate_limiter import get_rate_limiter

        rate_limiter = get_rate_limiter()
        return {
            "status": "ok",
            "rate_limits": rate_limiter.get_all_stats(),
            "service_health": rate_limiter.get_service_health()
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

@app.post("/rate-limits/reset")
def reset_rate_limits(service_name: str = None):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒªã‚»ãƒƒãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç®¡ç†è€…ç”¨ï¼‰"""
    try:
        from rate_limiter import get_rate_limiter

        rate_limiter = get_rate_limiter()

        if service_name:
            import asyncio
            result = asyncio.run(rate_limiter.reset_service_limits(service_name))
            return {
                "status": "ok" if result else "not_found",
                "message": f"Service '{service_name}' rate limits reset" if result else f"Service '{service_name}' not found"
            }
        else:
            # å…¨ã‚µãƒ¼ãƒ“ã‚¹ãƒªã‚»ãƒƒãƒˆ
            reset_count = 0
            for service in list(rate_limiter.buckets.keys()):
                import asyncio
                if asyncio.run(rate_limiter.reset_service_limits(service)):
                    reset_count += 1

            return {
                "status": "ok",
                "message": f"{reset_count} services reset"
            }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }


# --- Botã®èµ·å‹•ã¨cogsã®èª­ã¿è¾¼ã¿ ---
@bot.event
async def on_ready():
    print(f"âœ… Login successful: {bot.user} (PID: {os.getpid()})")
    print(f"ğŸ” Bot instance ID: {id(bot)}")
    try:
        for filename in os.listdir("./cogs"):
            if filename.endswith(".py") and not filename.startswith("_"):
                await bot.load_extension(f"cogs.{filename[:-3]}")
                print(f"âœ… Cog loaded: {filename}")

        if GUILD_ID:
            guild_obj = discord.Object(id=int(GUILD_ID))
            bot.tree.copy_global_to(guild=guild_obj)
            cmds = await bot.tree.sync(guild=guild_obj)
            print(f"âœ… Synced {len(cmds)} guild commands to {GUILD_ID}")
        else:
            cmds = await bot.tree.sync()
            print(f"âœ… Synced {len(cmds)} global commands")
            
        # é‡è¤‡é˜²æ­¢æ©Ÿèƒ½ã®å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
        # try:
        #     from channel_tasks import start_periodic_cleanup
        #     asyncio.create_task(start_periodic_cleanup())
        #     print("âœ… å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¿ã‚¹ã‚¯é–‹å§‹")
        # except Exception as cleanup_error:
        #     print(f"âš ï¸ å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®é–‹å§‹ã«å¤±æ•—: {cleanup_error}")
        print("â„¹ï¸ å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")

        # AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        try:
            from ai_manager import get_ai_manager
            ai_manager = get_ai_manager()
            ai_manager.initialize(bot)
            print("âœ… AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†")
        except Exception as ai_init_error:
            print(f"âš ï¸ AIãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—: {ai_init_error}")
            
    except Exception as e:
        print(f"ğŸš¨ FATAL ERROR on ready/sync: {e}")
        import traceback
        traceback.print_exc()

@app.on_event("startup")
async def startup_event():
    print("ğŸ¤– Initializing API clients and bot state...")
    try:
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚­ãƒ¼ã‚’botã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«æ ¼ç´
        # httpxã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§å¯¾å¿œ
        import httpx
        http_client = httpx.AsyncClient()
        bot.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, http_client=http_client)
        bot.mistral_client = MistralAsyncClient(api_key=MISTRAL_API_KEY)
        notion_utils.notion = Client(auth=NOTION_API_KEY)
        genai.configure(api_key=GEMINI_API_KEY)
        bot.perplexity_api_key = PERPLEXITY_API_KEY
        bot.openrouter_api_key = OPENROUTER_API_KEY
        bot.grok_api_key = GROK_API_KEY

        # æ‹¡å¼µçµ±ä¸€ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
        bot.memory_manager = get_enhanced_memory_manager()

        # å¾“æ¥ã®ãƒ¡ãƒ¢ãƒªå¤‰æ•°ã‚’å‹•çš„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ã—ã¦è¨­å®šï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›æ€§ï¼‰
        bot._setup_legacy_memory_properties()

        print("âœ… æ‹¡å¼µçµ±ä¸€ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æº–å‚™å®Œäº†")
        
        # å®šæ•°ã‚‚botã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«æ ¼ç´
        bot.ADMIN_USER_ID = ADMIN_USER_ID
        bot.GUILD_ID = GUILD_ID

        # Llamaãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        bot.llama_model = None
        try:
            vertexai.init(project="stunning-agency-469102-b5", location="us-central1")
            bot.llama_model = GenerativeModel("llama-3.3-70b-instruct-maas")
            print("âœ… Vertex AI initialized successfully.")
        except Exception as e:
            print(f"ğŸš¨ Vertex AI init failed: {e}")

        asyncio.create_task(bot.start(DISCORD_TOKEN))
        print("âœ… Discord Bot startup task has been created.")

    except Exception as e:
        print(f"ğŸš¨ğŸš¨ğŸš¨ FATAL ERROR during startup event: {e} ğŸš¨ğŸš¨ğŸš¨")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    port = int(os.environ.get("PORT", "8080"))
    uvicorn.run(app, host="0.0.0.0", port=port)