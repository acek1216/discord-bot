# -*- coding: utf-8 -*-
"""
æ‹¡å¼µçµ±ä¸€ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
å¾“æ¥ã®åˆ†æ•£ã—ãŸçŠ¶æ…‹ç®¡ç†ã‚’å®Œå…¨çµ±åˆ
"""

import time
import threading
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, field
from collections import defaultdict, deque

from memory_manager import UnifiedMemoryManager, MemoryEntry, MemoryStats
from utils import safe_log

@dataclass
class ProcessingState:
    """å‡¦ç†çŠ¶æ…‹ã®ç®¡ç†"""
    processing_channels: Set[str] = field(default_factory=set)
    processing_messages: Set[str] = field(default_factory=set)
    processed_messages: Dict[str, float] = field(default_factory=dict)
    global_state: Dict[str, Any] = field(default_factory=dict)

@dataclass
class LegacyMemoryMapping:
    """å¾“æ¥ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ã¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©"""
    base_memory_types = [
        'gpt', 'gemini', 'mistral', 'claude', 'llama', 'grok'
    ]

    thread_memory_types = [
        'gpt', 'gemini', 'perplexity', 'gpt4o', 'gpt5'
    ]

class EnhancedMemoryManager(UnifiedMemoryManager):
    """æ‹¡å¼µçµ±ä¸€ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ - å…¨çŠ¶æ…‹ã‚’çµ±åˆç®¡ç†"""

    def __init__(self, default_max_history: int = 10, cleanup_interval: int = 3600):
        super().__init__(default_max_history, cleanup_interval)

        # å‡¦ç†çŠ¶æ…‹ç®¡ç†
        self.processing_state = ProcessingState()

        # å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãŸã‚ã®è¾æ›¸ï¼ˆå‹•çš„ç”Ÿæˆï¼‰
        self._legacy_memory_cache = {}
        self._legacy_cache_last_update = {}

        # é‡è¤‡å‡¦ç†é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ 
        self.duplication_cleanup_interval = 600
        self.last_duplication_cleanup = time.time()

        safe_log("âœ… æ‹¡å¼µãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†", "")

    # === å‡¦ç†çŠ¶æ…‹ç®¡ç† ===

    def add_processing_channel(self, channel_id: str) -> bool:
        """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«ã‚’è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
        with self.lock:
            if channel_id in self.processing_state.processing_channels:
                return False  # æ—¢ã«å‡¦ç†ä¸­

            self.processing_state.processing_channels.add(channel_id)
            safe_log("ğŸ”„ ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†é–‹å§‹: ", channel_id)
            return True

    def remove_processing_channel(self, channel_id: str) -> bool:
        """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å‰Šé™¤"""
        with self.lock:
            if channel_id in self.processing_state.processing_channels:
                self.processing_state.processing_channels.discard(channel_id)
                safe_log("âœ… ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†å®Œäº†: ", channel_id)
                return True
            return False

    def is_channel_processing(self, channel_id: str) -> bool:
        """ãƒãƒ£ãƒ³ãƒãƒ«ãŒå‡¦ç†ä¸­ã‹ãƒã‚§ãƒƒã‚¯"""
        return channel_id in self.processing_state.processing_channels

    def get_processing_channels(self) -> Set[str]:
        """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return self.processing_state.processing_channels.copy()

    # === ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é‡è¤‡å‡¦ç†é˜²æ­¢ ===

    def start_message_processing(self, message_id: str) -> bool:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†é–‹å§‹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰"""
        with self.lock:
            current_time = time.time()

            # å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if current_time - self.last_duplication_cleanup > self.duplication_cleanup_interval:
                self._cleanup_old_processed_messages(current_time)
                self.last_duplication_cleanup = current_time

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if (message_id in self.processing_state.processing_messages or
                message_id in self.processing_state.processed_messages):
                return False

            self.processing_state.processing_messages.add(message_id)
            return True

    def finish_message_processing(self, message_id: str, success: bool = True):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†å®Œäº†"""
        with self.lock:
            self.processing_state.processing_messages.discard(message_id)
            if success:
                self.processing_state.processed_messages[message_id] = time.time()

    def _cleanup_old_processed_messages(self, current_time: float):
        """å¤ã„å‡¦ç†æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cutoff_time = current_time - 3600  # 1æ™‚é–“å‰ã¾ã§
        old_messages = [
            msg_id for msg_id, timestamp in self.processing_state.processed_messages.items()
            if timestamp < cutoff_time
        ]

        for msg_id in old_messages:
            del self.processing_state.processed_messages[msg_id]

        if old_messages:
            safe_log("ğŸ§¹ å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†è¨˜éŒ²ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: ", f"{len(old_messages)}ä»¶å‰Šé™¤")

    # === ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç† ===

    def set_global_state(self, key: str, value: Any):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’è¨­å®š"""
        with self.lock:
            self.processing_state.global_state[key] = value

    def get_global_state(self, key: str, default: Any = None) -> Any:
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’å–å¾—"""
        return self.processing_state.global_state.get(key, default)

    def remove_global_state(self, key: str) -> bool:
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’å‰Šé™¤"""
        with self.lock:
            if key in self.processing_state.global_state:
                del self.processing_state.global_state[key]
                return True
            return False

    # === å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ ===

    def get_legacy_memory(self, memory_type: str, memory_category: str = "base") -> Dict[str, Any]:
        """å¾“æ¥ã®ãƒ¡ãƒ¢ãƒªå½¢å¼ã§å–å¾—ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰

        Args:
            memory_type: 'gpt', 'gemini', 'mistral', etc.
            memory_category: 'base' or 'thread'
        """
        cache_key = f"{memory_type}_{memory_category}"
        current_time = time.time()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ–°ã—ã„å ´åˆã¯ãã‚Œã‚’è¿”ã™
        if (cache_key in self._legacy_cache_last_update and
            current_time - self._legacy_cache_last_update[cache_key] < 1.0):
            return self._legacy_memory_cache.get(cache_key, {})

        with self.lock:
            # çµ±ä¸€ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å¾“æ¥å½¢å¼ã«å¤‰æ›
            legacy_memory = {}

            if memory_type in self.memories:
                for channel_id, memory in self.memories[memory_type].items():
                    if memory.entries:
                        # OpenAIå½¢å¼ã®historyã«å¤‰æ›
                        legacy_memory[channel_id] = memory.get_history(include_metadata=False)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._legacy_memory_cache[cache_key] = legacy_memory
            self._legacy_cache_last_update[cache_key] = current_time

            return legacy_memory

    def update_legacy_memory(self, memory_type: str, channel_id: str,
                           history: List[Dict[str, str]], memory_category: str = "base"):
        """å¾“æ¥å½¢å¼ã§ãƒ¡ãƒ¢ãƒªã‚’æ›´æ–°ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰"""
        if not history:
            return

        with self.lock:
            # å¾“æ¥å½¢å¼ã‹ã‚‰çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã«å¤‰æ›
            # historyã¯ [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}] å½¢å¼

            # ãƒšã‚¢ã§ã‚„ã‚Šå–ã‚Šã‚’å‡¦ç†
            for i in range(0, len(history) - 1, 2):
                if (i + 1 < len(history) and
                    history[i].get("role") == "user" and
                    history[i + 1].get("role") == "assistant"):

                    user_content = history[i].get("content", "")
                    ai_content = history[i + 1].get("content", "")

                    if user_content and ai_content:
                        self.add_interaction(
                            ai_type=memory_type,
                            channel_id=channel_id,
                            user_content=user_content,
                            ai_response=ai_content,
                            metadata={
                                "legacy_import": True,
                                "memory_category": memory_category,
                                "timestamp": time.time()
                            }
                        )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
            cache_key = f"{memory_type}_{memory_category}"
            if cache_key in self._legacy_cache_last_update:
                del self._legacy_cache_last_update[cache_key]

    # === çµ±è¨ˆã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° ===

    def get_enhanced_stats(self) -> Dict[str, Any]:
        """æ‹¡å¼µçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        base_stats = self.get_detailed_stats()

        with self.lock:
            processing_info = {
                "processing_channels": len(self.processing_state.processing_channels),
                "processing_messages": len(self.processing_state.processing_messages),
                "processed_messages_count": len(self.processing_state.processed_messages),
                "global_state_keys": len(self.processing_state.global_state),
                "legacy_cache_entries": len(self._legacy_memory_cache)
            }

            return {
                **base_stats,
                "processing_state": processing_info,
                "system_info": {
                    "enhanced_manager": True,
                    "version": "2.0",
                    "features": [
                        "unified_memory", "processing_state", "message_deduplication",
                        "legacy_compatibility", "global_state", "auto_cleanup"
                    ]
                }
            }

    def health_check(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        with self.lock:
            current_time = time.time()

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
            total_entries = sum(len(channels) for channels in self.memories.values())
            memory_pressure = "high" if total_entries > 1000 else "normal" if total_entries > 100 else "low"

            # å‡¦ç†çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            long_processing_channels = [
                ch_id for ch_id in self.processing_state.processing_channels
                # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã¯è¿½è·¡ã—ã¦ã„ãªã„ãŸã‚ã€å˜ç´”ã«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            ]

            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çŠ¶æ…‹
            cleanup_overdue = (current_time - self.last_cleanup) > (self.cleanup_interval * 2)

            return {
                "status": "healthy",
                "memory_pressure": memory_pressure,
                "total_memory_entries": total_entries,
                "processing_channels_count": len(self.processing_state.processing_channels),
                "long_processing_channels": long_processing_channels,
                "cleanup_overdue": cleanup_overdue,
                "last_cleanup_ago_seconds": int(current_time - self.last_cleanup),
                "recommendations": self._get_health_recommendations(memory_pressure, cleanup_overdue)
            }

    def _get_health_recommendations(self, memory_pressure: str, cleanup_overdue: bool) -> List[str]:
        """ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹ã«åŸºã¥ãæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        recommendations = []

        if memory_pressure == "high":
            recommendations.append("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ãŸã‚ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’æ¨å¥¨")

        if cleanup_overdue:
            recommendations.append("è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒé…å»¶ä¸­ã€æ‰‹å‹•å®Ÿè¡Œã‚’æ¨å¥¨")

        if len(self.processing_state.processing_channels) > 10:
            recommendations.append("åŒæ™‚å‡¦ç†ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒå¤šã„ã€è² è·åˆ†æ•£ã‚’æ¨å¥¨")

        return recommendations

    # === ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ ===

    def force_cleanup(self) -> Dict[str, int]:
        """å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        with self.lock:
            current_time = time.time()

            # é€šå¸¸ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_expired_memories()

            # é‡è¤‡å‡¦ç†é˜²æ­¢ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            old_processed_count = len(self.processing_state.processed_messages)
            self._cleanup_old_processed_messages(current_time)
            cleaned_messages = old_processed_count - len(self.processing_state.processed_messages)

            # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
            cache_entries = len(self._legacy_memory_cache)
            self._legacy_memory_cache.clear()
            self._legacy_cache_last_update.clear()

            return {
                "expired_memories": 0,  # _cleanup_expired_memories ã®æˆ»ã‚Šå€¤ãŒãªã„ãŸã‚
                "old_messages": cleaned_messages,
                "cache_entries": cache_entries
            }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_enhanced_memory_manager: Optional[EnhancedMemoryManager] = None

def get_enhanced_memory_manager() -> EnhancedMemoryManager:
    """æ‹¡å¼µãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _enhanced_memory_manager
    if _enhanced_memory_manager is None:
        _enhanced_memory_manager = EnhancedMemoryManager()
        safe_log("âœ… æ‹¡å¼µçµ±ä¸€ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆå®Œäº†", "")
    return _enhanced_memory_manager

def reset_enhanced_memory_manager():
    """æ‹¡å¼µãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    global _enhanced_memory_manager
    _enhanced_memory_manager = None

# ä¾¿åˆ©é–¢æ•°ï¼ˆå¾“æ¥ã‚·ã‚¹ãƒ†ãƒ äº’æ›ï¼‰
def get_processing_channels() -> Set[str]:
    """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«å–å¾—"""
    return get_enhanced_memory_manager().get_processing_channels()

def add_processing_channel(channel_id: str) -> bool:
    """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«è¿½åŠ """
    return get_enhanced_memory_manager().add_processing_channel(channel_id)

def remove_processing_channel(channel_id: str) -> bool:
    """å‡¦ç†ä¸­ãƒãƒ£ãƒ³ãƒãƒ«å‰Šé™¤"""
    return get_enhanced_memory_manager().remove_processing_channel(channel_id)

def is_channel_processing(channel_id: str) -> bool:
    """ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†ä¸­ãƒã‚§ãƒƒã‚¯"""
    return get_enhanced_memory_manager().is_channel_processing(channel_id)

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=== Enhanced Memory Manager Test ===")

    manager = EnhancedMemoryManager()

    # å‡¦ç†çŠ¶æ…‹ãƒ†ã‚¹ãƒˆ
    print("1. Processing State Test...")
    assert manager.add_processing_channel("test_channel_1") == True
    assert manager.add_processing_channel("test_channel_1") == False  # é‡è¤‡
    assert manager.is_channel_processing("test_channel_1") == True
    assert manager.remove_processing_channel("test_channel_1") == True
    print("   âœ… Processing state management OK")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é‡è¤‡é˜²æ­¢ãƒ†ã‚¹ãƒˆ
    print("2. Message Deduplication Test...")
    assert manager.start_message_processing("msg_001") == True
    assert manager.start_message_processing("msg_001") == False  # é‡è¤‡
    manager.finish_message_processing("msg_001", success=True)
    assert manager.start_message_processing("msg_001") == False  # å‡¦ç†æ¸ˆã¿
    print("   âœ… Message deduplication OK")

    # ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ
    print("3. Memory Management Test...")
    manager.add_interaction("gpt5", "channel_123", "Hello", "Hi there!")
    history = manager.get_history("gpt5", "channel_123")
    assert len(history) == 2
    print("   âœ… Memory management OK")

    # ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›æ€§ãƒ†ã‚¹ãƒˆ
    print("4. Legacy Compatibility Test...")
    legacy_memory = manager.get_legacy_memory("gpt5", "base")
    assert "channel_123" in legacy_memory
    print("   âœ… Legacy compatibility OK")

    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    print("5. Health Check Test...")
    health = manager.health_check()
    assert health["status"] == "healthy"
    print("   âœ… Health check OK")

    print("\nğŸ‰ All tests passed! Enhanced Memory Manager is ready.")

    # çµ±è¨ˆè¡¨ç¤º
    stats = manager.get_enhanced_stats()
    print(f"\nStats: {stats['summary']['total_entries']} entries across {stats['summary']['total_ais']} AI types")